{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of \"Generating 3 qubit quantum circuits with neural networks\"\n",
    "\n",
    "Chris Ferrie\n",
    "\n",
    "This is an open peer review of arxiv:1703.10743, [Generating 3 qubit quantum circuits with neural networks](https://arxiv.org/abs/1703.10743) by Michael Swaddle *et al*.\n",
    "\n",
    "**TO JOURNAL EDITORS:** You are free to use the contents of the [repository](https://github.com/csferrie/openreviews) as you see fit.\n",
    "\n",
    "**DISCLAIMER:** A referee necessarily spends *far* less time than the authors on the paper. As such, this report surely contains errors. I would love for you to point them out so I can correct them. Otherwise, this report is provided without warranty of any kind, including its suitability as a resource for making decisions affecting the career of the authors of the paper.\n",
    "\n",
    "## Tweetable summary of my report\n",
    "\n",
    "Highly recommended read for its accessibility and reproducibility, but lacks the analysis to live up to its claims. #workinprogress\n",
    "\n",
    "### Summary of claims and results\n",
    "\n",
    "The authors seem to define quantum compilation the same way I would define *quantum control*. Namely, given a set of control Hamiltonians, design the interaction strength to generate a target unitary. The standard approach—as far as I understand—is a numerical gradient-based optimization using classical simulation to evaluate the objective function. The authors propose the following two-step alternative:\n",
    "* First break up the path from the the initial gate to the target into sequence of unitaries which approximate a geodesic curve in $SU(d)$;\n",
    "* Second, for each of those unitaries, find the set of controls to achieve those, with the idea that—given they are \"close\" together—it should be easier than traditional approaches.\n",
    "\n",
    "The authors achieve this to some extend by training a neural network with simulated trajectories. Though, as I outline below, much more analysis is required to warrant suggesting this as a viable alternative to traditional methods. Though they did *not* emphasize it, I see the provided code and data as the most valuable research output.\n",
    "\n",
    "### Correctness\n",
    "\n",
    "Given I was able to reproduce the results, I have no doubt the results obtained are correct. I do have some concerns, though, in the relevance of the result to quantum control:\n",
    "* The authors seem to truncate the unitaries to the real part of each entry. Are two unitaries that are close in their real part actually close? I don't think they are.\n",
    "* The training data for the second stage control problem does not use the the gates generated from the first part. They simply generate random controls to define a target. It would be far more convincing if the gates used in the first stage where used in the second stage. After all, this is how it would necessarily be done in practice.\n",
    "\n",
    "### Accessibility\n",
    "\n",
    "The paper is quite short, but not necessarily dense. I am neither an expert in geometric quantum nor the architecture of neural networks—yet, I was able to quickly grasp the main idea of the paper. That being said, there were a few points which I got hung up on. \n",
    "* The discussion of the problem of quantum compilation, or control, lacks context. It attempts to be broad, but would leave a non-expert thinking: a good approximation to $U$ is of course $U$. It should be discussed earlier—and made explicit—hat the basis for the sub-algebra is somehow an experimental constraint or set of available controls. \n",
    "* The crucial part of the geodesic equation seems to be the projection onto the sub-algebra. This should be explicitly defined.\n",
    "* The network design is lacking everything but a bare description—why this rather than something else? Is there some intuition at least?\n",
    "* Fidelity is the standard metric used in quantum control (and something like diamond norm is the ultimate figure of merit for quantum gate comparisons). The real part of the individual entries seems to be quite difficult to justify from an operational perspective. Such choices need to be explained and defended.\n",
    "\n",
    "### Reproducibility\n",
    "\n",
    "Relative to other research in quantum information theory, this work gets top marks for reproducibility. However... given the author's eagerness to go above and beyond what is expected in a physics paper, I'm going to make some further suggestions for improvement in the hopes that the reproducibility aspect is more transparent.\n",
    "\n",
    "The code is not well organized or documented. Since it is quite minimal and I had some basic knowledge in the software used, I was able to figure out how it works. But, I doubt most of the target audience of this paper could make use of it. Indeed, I immediately ran into errors when attempting to run the code, making the saved trained model useless to me. To be fair, I did not attempt to contact the authors about this since—as the authors themselves point out—the model can be trained quite quickly on a reasonable GPU (as you will see below).\n",
    "\n",
    "The data was generated with separate software—Mathematica. I do not have a Mathematica license so did not attempt to reproduce the data. Given the authors were already using numpy, it would have been straightforward to generate the data in python as well.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "I think here is where the paper falls short. The analysis of the results of the network training are not subjected to any anaylsis beyond plotting the results. Crucially(!):\n",
    "* How does this method compare to existing methods for:\n",
    "    * The geodesic approach?\n",
    "    * The local decomposition?\n",
    "* Further to that, does the claim that the lack of redundancy using the geodesic provides an effective alternative hold up to numerical tests? (It would be straightforward given the infrastructure the authors have build to test the claims of their own paper!)\n",
    "* (Even for the small examples) How do the results depend on the parameters of the neural network?\n",
    "\n",
    "### Final verdict\n",
    "\n",
    "The authors provided the code to generate the data, the data themselves, the code to train the network, and the trained network!  Indeed, if I was so inclined, I could immediately build on their work without any uncertainty and this is far more than I can say for anything else I've read recently on [quant-ph]([https://arxiv.org/list/quant-ph/recent). This is an immensely impressive effort in a field which neither rewards or encourages it. The standard approach to publishing is to obscure your result to the point of either not being about to reproduce it, or give yourself plausible deniability should it be wrong. I applaud the authors for their bravery in exposing their work for detailed criticism. \n",
    "\n",
    "I see this as a (very useful!) set of lab notes rather than a complete scientific result because of the lack of comparisons to existing methods and variations in the proposed method. More analysis and discussion of the results is required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility analysis\n",
    "\n",
    "The code here is derived from the source provided by the authors at https://github.com/Swaddle/nnQcompiler.\n",
    "\n",
    "I have also used the data provided by the authors at https://github.com/Swaddle/nnQcompiler.\n",
    "\n",
    "I had a bit of trouble with various versions and their respective compatability under Python 3:\n",
    "```\n",
    "Python 3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
    "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\n",
    "```\n",
    "With the Anaconda distribution above, I download Keras version 1.2.2 and ran:\n",
    "```\n",
    "pip install tensorflow\n",
    "pip install Keras-1.2.2.tar.gz\n",
    "```\n",
    "\n",
    "I hacked up some minimal changes and moved most of the code into this single notebook for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from data_utils import load_data_lstm, load_data_ss\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import ZeroPadding1D\n",
    "from keras.callbacks import CSVLogger\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors use the squared error as an objective. While standard in many network training problems, it is unclear what it's operational meaning is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_objective(y_true, y_pred):\n",
    "    tensor = y_true - y_pred \n",
    "    squares = tf.square(tensor)\n",
    "    norm = tf.reduce_sum(squares)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors already nicely split the training and validation data, so we just load that up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data_path = 'data/lstm_data_training.csv'\n",
    "valid_data_path = 'data/lstm_data_valid.csv'\n",
    "\n",
    "train_input, train_output = load_data_lstm(training_data_path)\n",
    "valid_input, valid_output = load_data_lstm(valid_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like black magic to me and is worth playing with, but it defines the architecture of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(80, return_sequences=True, input_shape=(8,8)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(80, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(80, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(80, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(80, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(80, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(input_dim=640,output_dim=640))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train that sucker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "1000/1000 [==============================] - 1s - loss: 1655.0847 - val_loss: 34.2073\n",
      "Epoch 2/1000\n",
      "1000/1000 [==============================] - 0s - loss: 316.0393 - val_loss: 18.3714\n",
      "Epoch 3/1000\n",
      "1000/1000 [==============================] - 0s - loss: 169.6186 - val_loss: 16.4331\n",
      "Epoch 4/1000\n",
      "1000/1000 [==============================] - 0s - loss: 93.3592 - val_loss: 10.5343\n",
      "Epoch 5/1000\n",
      "1000/1000 [==============================] - 0s - loss: 108.5998 - val_loss: 11.2147\n",
      "Epoch 6/1000\n",
      "1000/1000 [==============================] - 0s - loss: 62.0827 - val_loss: 10.4611\n",
      "Epoch 7/1000\n",
      "1000/1000 [==============================] - 0s - loss: 52.4477 - val_loss: 9.0723\n",
      "Epoch 8/1000\n",
      "1000/1000 [==============================] - 0s - loss: 77.2306 - val_loss: 12.8944\n",
      "Epoch 9/1000\n",
      "1000/1000 [==============================] - 0s - loss: 42.5482 - val_loss: 8.8110\n",
      "Epoch 10/1000\n",
      "1000/1000 [==============================] - 0s - loss: 45.2898 - val_loss: 9.0821\n",
      "Epoch 11/1000\n",
      "1000/1000 [==============================] - 0s - loss: 35.5967 - val_loss: 8.2457\n",
      "Epoch 12/1000\n",
      "1000/1000 [==============================] - 0s - loss: 46.2576 - val_loss: 8.5135\n",
      "Epoch 13/1000\n",
      "1000/1000 [==============================] - 0s - loss: 31.4348 - val_loss: 8.2321\n",
      "Epoch 14/1000\n",
      "1000/1000 [==============================] - 0s - loss: 28.9892 - val_loss: 8.0690\n",
      "Epoch 15/1000\n",
      "1000/1000 [==============================] - 0s - loss: 29.3194 - val_loss: 8.7529\n",
      "Epoch 16/1000\n",
      "1000/1000 [==============================] - 0s - loss: 26.0391 - val_loss: 7.7710\n",
      "Epoch 17/1000\n",
      "1000/1000 [==============================] - 0s - loss: 25.8025 - val_loss: 8.8804\n",
      "Epoch 18/1000\n",
      "1000/1000 [==============================] - 0s - loss: 51.3100 - val_loss: 7.3290\n",
      "Epoch 19/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.0907 - val_loss: 7.4554\n",
      "Epoch 20/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.8436 - val_loss: 6.9894\n",
      "Epoch 21/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.8127 - val_loss: 7.3371\n",
      "Epoch 22/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.6293 - val_loss: 7.0844\n",
      "Epoch 23/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.2581 - val_loss: 7.1833\n",
      "Epoch 24/1000\n",
      "1000/1000 [==============================] - 0s - loss: 21.8342 - val_loss: 7.2273\n",
      "Epoch 25/1000\n",
      "1000/1000 [==============================] - 0s - loss: 23.4267 - val_loss: 7.1940\n",
      "Epoch 26/1000\n",
      "1000/1000 [==============================] - 0s - loss: 24.7397 - val_loss: 6.7745\n",
      "Epoch 27/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.8136 - val_loss: 6.6896\n",
      "Epoch 28/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.7745 - val_loss: 6.5086\n",
      "Epoch 29/1000\n",
      "1000/1000 [==============================] - 0s - loss: 17.7195 - val_loss: 6.2366\n",
      "Epoch 30/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.8222 - val_loss: 6.3709\n",
      "Epoch 31/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.8897 - val_loss: 6.5695\n",
      "Epoch 32/1000\n",
      "1000/1000 [==============================] - 0s - loss: 18.6408 - val_loss: 6.4200\n",
      "Epoch 33/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.2138 - val_loss: 6.0732\n",
      "Epoch 34/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.6626 - val_loss: 5.9461\n",
      "Epoch 35/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.1931 - val_loss: 6.1901\n",
      "Epoch 36/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.7903 - val_loss: 6.0741\n",
      "Epoch 37/1000\n",
      "1000/1000 [==============================] - 0s - loss: 19.6402 - val_loss: 5.9941\n",
      "Epoch 38/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.7746 - val_loss: 5.8172\n",
      "Epoch 39/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.3934 - val_loss: 5.7385\n",
      "Epoch 40/1000\n",
      "1000/1000 [==============================] - 0s - loss: 20.1974 - val_loss: 6.0071\n",
      "Epoch 41/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.9444 - val_loss: 6.2999\n",
      "Epoch 42/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.6593 - val_loss: 5.6227\n",
      "Epoch 43/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.2644 - val_loss: 5.7975\n",
      "Epoch 44/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.8589 - val_loss: 6.4562\n",
      "Epoch 45/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.7538 - val_loss: 5.5583\n",
      "Epoch 46/1000\n",
      "1000/1000 [==============================] - 0s - loss: 16.9502 - val_loss: 6.1578\n",
      "Epoch 47/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3041 - val_loss: 5.3534\n",
      "Epoch 48/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.2560 - val_loss: 5.6836\n",
      "Epoch 49/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.5695 - val_loss: 5.2710\n",
      "Epoch 50/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.0860 - val_loss: 5.2635\n",
      "Epoch 51/1000\n",
      "1000/1000 [==============================] - 0s - loss: 15.1462 - val_loss: 5.2328\n",
      "Epoch 52/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.6565 - val_loss: 5.3323\n",
      "Epoch 53/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.1215 - val_loss: 5.1675\n",
      "Epoch 54/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.0265 - val_loss: 4.9756\n",
      "Epoch 55/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.4859 - val_loss: 5.0503\n",
      "Epoch 56/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.9864 - val_loss: 4.9412\n",
      "Epoch 57/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.7923 - val_loss: 4.9105\n",
      "Epoch 58/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.6661 - val_loss: 4.8659\n",
      "Epoch 59/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8572 - val_loss: 4.9905\n",
      "Epoch 60/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.1981 - val_loss: 5.1625\n",
      "Epoch 61/1000\n",
      "1000/1000 [==============================] - 0s - loss: 14.4236 - val_loss: 4.9859\n",
      "Epoch 62/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.4187 - val_loss: 5.0602\n",
      "Epoch 63/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.2030 - val_loss: 4.8664\n",
      "Epoch 64/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3580 - val_loss: 4.7044\n",
      "Epoch 65/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.7380 - val_loss: 4.5651\n",
      "Epoch 66/1000\n",
      "1000/1000 [==============================] - 0s - loss: 13.3998 - val_loss: 4.8031\n",
      "Epoch 67/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.8522 - val_loss: 4.5214\n",
      "Epoch 68/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7382 - val_loss: 4.5601\n",
      "Epoch 69/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.3455 - val_loss: 4.5410\n",
      "Epoch 70/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.8252 - val_loss: 4.5446\n",
      "Epoch 71/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.1937 - val_loss: 4.5946\n",
      "Epoch 72/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.6099 - val_loss: 4.5330\n",
      "Epoch 73/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8846 - val_loss: 4.4979\n",
      "Epoch 74/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.4041 - val_loss: 4.4830\n",
      "Epoch 75/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.5117 - val_loss: 4.5468\n",
      "Epoch 76/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3887 - val_loss: 4.8771\n",
      "Epoch 77/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.8172 - val_loss: 5.7137\n",
      "Epoch 78/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.7837 - val_loss: 4.1909\n",
      "Epoch 79/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.2569 - val_loss: 5.9973\n",
      "Epoch 80/1000\n",
      "1000/1000 [==============================] - 0s - loss: 12.9323 - val_loss: 4.3936\n",
      "Epoch 81/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.2098 - val_loss: 4.1748\n",
      "Epoch 82/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.3625 - val_loss: 4.2554\n",
      "Epoch 83/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0963 - val_loss: 4.2596\n",
      "Epoch 84/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0053 - val_loss: 4.1061\n",
      "Epoch 85/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0152 - val_loss: 4.5238\n",
      "Epoch 86/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.0763 - val_loss: 3.9531\n",
      "Epoch 87/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.9096 - val_loss: 4.1221\n",
      "Epoch 88/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.2488 - val_loss: 3.9117\n",
      "Epoch 89/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.5618 - val_loss: 3.9093\n",
      "Epoch 90/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.1431 - val_loss: 4.1418\n",
      "Epoch 91/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0329 - val_loss: 3.8906\n",
      "Epoch 92/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6519 - val_loss: 4.2325\n",
      "Epoch 93/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8501 - val_loss: 3.8506\n",
      "Epoch 94/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.5886 - val_loss: 4.0437\n",
      "Epoch 95/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.4563 - val_loss: 3.9303\n",
      "Epoch 96/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.4780 - val_loss: 3.7307\n",
      "Epoch 97/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.3165 - val_loss: 3.7491\n",
      "Epoch 98/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.4377 - val_loss: 3.7697\n",
      "Epoch 99/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6351 - val_loss: 3.8461\n",
      "Epoch 100/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.9137 - val_loss: 3.6934\n",
      "Epoch 101/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.4236 - val_loss: 3.9148\n",
      "Epoch 102/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.3758 - val_loss: 3.5260\n",
      "Epoch 103/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.9851 - val_loss: 3.6144\n",
      "Epoch 104/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8013 - val_loss: 3.7855\n",
      "Epoch 105/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.5989 - val_loss: 3.5723\n",
      "Epoch 106/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.4604 - val_loss: 3.4867\n",
      "Epoch 107/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.1778 - val_loss: 3.5283\n",
      "Epoch 108/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.8627 - val_loss: 3.5240\n",
      "Epoch 109/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.8417 - val_loss: 3.4189\n",
      "Epoch 110/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6607 - val_loss: 3.5599\n",
      "Epoch 111/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.0176 - val_loss: 3.2983\n",
      "Epoch 112/1000\n",
      "1000/1000 [==============================] - 0s - loss: 11.3471 - val_loss: 3.2506\n",
      "Epoch 113/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.5091 - val_loss: 3.6389\n",
      "Epoch 114/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.9849 - val_loss: 3.2931\n",
      "Epoch 115/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.2165 - val_loss: 3.2461\n",
      "Epoch 116/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.1490 - val_loss: 3.2328\n",
      "Epoch 117/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.7013 - val_loss: 3.2242\n",
      "Epoch 118/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.1500 - val_loss: 3.2025\n",
      "Epoch 119/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.6589 - val_loss: 3.1866\n",
      "Epoch 120/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.0517 - val_loss: 3.2678\n",
      "Epoch 121/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.9382 - val_loss: 3.0484\n",
      "Epoch 122/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.1925 - val_loss: 3.6015\n",
      "Epoch 123/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.8880 - val_loss: 3.0268\n",
      "Epoch 124/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.7847 - val_loss: 2.9976\n",
      "Epoch 125/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.0426 - val_loss: 3.0957\n",
      "Epoch 126/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.6018 - val_loss: 3.3405\n",
      "Epoch 127/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0551 - val_loss: 2.9933\n",
      "Epoch 128/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.9692 - val_loss: 3.0649\n",
      "Epoch 129/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.8450 - val_loss: 3.2537\n",
      "Epoch 130/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.8751 - val_loss: 3.0356\n",
      "Epoch 131/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.7737 - val_loss: 2.8974\n",
      "Epoch 132/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.4117 - val_loss: 3.0712\n",
      "Epoch 133/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.4516 - val_loss: 2.8255\n",
      "Epoch 134/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.3018 - val_loss: 2.7697\n",
      "Epoch 135/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.1295 - val_loss: 2.8746\n",
      "Epoch 136/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.3559 - val_loss: 3.1144\n",
      "Epoch 137/1000\n",
      "1000/1000 [==============================] - 0s - loss: 10.0260 - val_loss: 2.7372\n",
      "Epoch 138/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.3145 - val_loss: 2.7843\n",
      "Epoch 139/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.2526 - val_loss: 2.7655\n",
      "Epoch 140/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.5104 - val_loss: 3.1060\n",
      "Epoch 141/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.8544 - val_loss: 2.8281\n",
      "Epoch 142/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.0390 - val_loss: 3.1103\n",
      "Epoch 143/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.3997 - val_loss: 2.7757\n",
      "Epoch 144/1000\n",
      "1000/1000 [==============================] - 0s - loss: 9.0054 - val_loss: 2.6026\n",
      "Epoch 145/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.8805 - val_loss: 2.6176\n",
      "Epoch 146/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.4475 - val_loss: 2.6153\n",
      "Epoch 147/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.5694 - val_loss: 2.6343\n",
      "Epoch 148/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.4845 - val_loss: 2.9744\n",
      "Epoch 149/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.7331 - val_loss: 3.3107\n",
      "Epoch 150/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.8300 - val_loss: 2.5236\n",
      "Epoch 151/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.9689 - val_loss: 2.7710\n",
      "Epoch 152/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.3094 - val_loss: 2.5098\n",
      "Epoch 153/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.0811 - val_loss: 2.4889\n",
      "Epoch 154/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.2483 - val_loss: 2.9621\n",
      "Epoch 155/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.5195 - val_loss: 2.6031\n",
      "Epoch 156/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.8160 - val_loss: 2.6751\n",
      "Epoch 157/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.1482 - val_loss: 2.4909\n",
      "Epoch 158/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.8342 - val_loss: 2.4545\n",
      "Epoch 159/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.6638 - val_loss: 2.7457\n",
      "Epoch 160/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.6214 - val_loss: 2.4069\n",
      "Epoch 161/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.9068 - val_loss: 2.4132\n",
      "Epoch 162/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.1494 - val_loss: 2.5891\n",
      "Epoch 163/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.0298 - val_loss: 2.4025\n",
      "Epoch 164/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.5123 - val_loss: 2.4034\n",
      "Epoch 165/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.0316 - val_loss: 2.4386\n",
      "Epoch 166/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.7394 - val_loss: 2.4985\n",
      "Epoch 167/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.5645 - val_loss: 2.6433\n",
      "Epoch 168/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.3952 - val_loss: 2.3639\n",
      "Epoch 169/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.1023 - val_loss: 2.3782\n",
      "Epoch 170/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.2586 - val_loss: 2.3079\n",
      "Epoch 171/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.2499 - val_loss: 2.3738\n",
      "Epoch 172/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.4738 - val_loss: 2.3307\n",
      "Epoch 173/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.8482 - val_loss: 2.2793\n",
      "Epoch 174/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.6046 - val_loss: 2.3429\n",
      "Epoch 175/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.7245 - val_loss: 2.5309\n",
      "Epoch 176/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.8677 - val_loss: 2.5061\n",
      "Epoch 177/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.6059 - val_loss: 2.4307\n",
      "Epoch 178/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.4489 - val_loss: 2.3128\n",
      "Epoch 179/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.5029 - val_loss: 2.2662\n",
      "Epoch 180/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.8496 - val_loss: 2.2336\n",
      "Epoch 181/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.1255 - val_loss: 2.4665\n",
      "Epoch 182/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.3895 - val_loss: 2.3385\n",
      "Epoch 183/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.3442 - val_loss: 2.1800\n",
      "Epoch 184/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.0593 - val_loss: 2.3639\n",
      "Epoch 185/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.3882 - val_loss: 2.4444\n",
      "Epoch 186/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.0669 - val_loss: 2.1786\n",
      "Epoch 187/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.0835 - val_loss: 2.2344\n",
      "Epoch 188/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.2458 - val_loss: 2.2061\n",
      "Epoch 189/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.3769 - val_loss: 2.1706\n",
      "Epoch 190/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.2216 - val_loss: 2.3522\n",
      "Epoch 191/1000\n",
      "1000/1000 [==============================] - 0s - loss: 8.3435 - val_loss: 2.1435\n",
      "Epoch 192/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.4731 - val_loss: 2.1934\n",
      "Epoch 193/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.5095 - val_loss: 2.1055\n",
      "Epoch 194/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.1363 - val_loss: 2.1520\n",
      "Epoch 195/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.5666 - val_loss: 2.0857\n",
      "Epoch 196/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.3837 - val_loss: 2.1154\n",
      "Epoch 197/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.2844 - val_loss: 2.1702\n",
      "Epoch 198/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.1259 - val_loss: 2.1339\n",
      "Epoch 199/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.1919 - val_loss: 2.4377\n",
      "Epoch 200/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.9413 - val_loss: 2.1181\n",
      "Epoch 201/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.0681 - val_loss: 2.0634\n",
      "Epoch 202/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.6244 - val_loss: 2.1205\n",
      "Epoch 203/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.9179 - val_loss: 2.0735\n",
      "Epoch 204/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6048 - val_loss: 2.0652\n",
      "Epoch 205/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.7305 - val_loss: 2.2187\n",
      "Epoch 206/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6804 - val_loss: 2.2179\n",
      "Epoch 207/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.6614 - val_loss: 1.9880\n",
      "Epoch 208/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.8762 - val_loss: 2.0525\n",
      "Epoch 209/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.6974 - val_loss: 2.3841\n",
      "Epoch 210/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.9831 - val_loss: 2.0043\n",
      "Epoch 211/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6536 - val_loss: 2.0169\n",
      "Epoch 212/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6771 - val_loss: 2.0057\n",
      "Epoch 213/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6785 - val_loss: 2.0814\n",
      "Epoch 214/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.7123 - val_loss: 2.0297\n",
      "Epoch 215/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6266 - val_loss: 1.9371\n",
      "Epoch 216/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.7549 - val_loss: 2.1114\n",
      "Epoch 217/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.2603 - val_loss: 2.1500\n",
      "Epoch 218/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.2277 - val_loss: 2.1217\n",
      "Epoch 219/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.1739 - val_loss: 2.0610\n",
      "Epoch 220/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.7409 - val_loss: 1.9607\n",
      "Epoch 221/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.9125 - val_loss: 2.0878\n",
      "Epoch 222/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.8615 - val_loss: 1.8960\n",
      "Epoch 223/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6380 - val_loss: 1.9474\n",
      "Epoch 224/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.3909 - val_loss: 2.0236\n",
      "Epoch 225/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.2307 - val_loss: 2.0363\n",
      "Epoch 226/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.5323 - val_loss: 1.9243\n",
      "Epoch 227/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.2446 - val_loss: 2.0454\n",
      "Epoch 228/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.2465 - val_loss: 1.9682\n",
      "Epoch 229/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6833 - val_loss: 1.9508\n",
      "Epoch 230/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6755 - val_loss: 1.9418\n",
      "Epoch 231/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.2985 - val_loss: 1.8312\n",
      "Epoch 232/1000\n",
      "1000/1000 [==============================] - 0s - loss: 6.3471 - val_loss: 2.1082\n",
      "Epoch 233/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.5699 - val_loss: 2.1104\n",
      "Epoch 234/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.5562 - val_loss: 1.9223\n",
      "Epoch 235/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.9781 - val_loss: 1.9168\n",
      "Epoch 236/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6107 - val_loss: 1.9031\n",
      "Epoch 237/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.3896 - val_loss: 1.9107\n",
      "Epoch 238/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6402 - val_loss: 1.8551\n",
      "Epoch 239/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.1569 - val_loss: 1.7963\n",
      "Epoch 240/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.7049 - val_loss: 2.1162\n",
      "Epoch 241/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.1619 - val_loss: 1.9521\n",
      "Epoch 242/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.2456 - val_loss: 2.0414\n",
      "Epoch 243/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.9072 - val_loss: 2.0580\n",
      "Epoch 244/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.1494 - val_loss: 2.0610\n",
      "Epoch 245/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.0562 - val_loss: 1.8547\n",
      "Epoch 246/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.8364 - val_loss: 1.8358\n",
      "Epoch 247/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.9335 - val_loss: 1.8223\n",
      "Epoch 248/1000\n",
      "1000/1000 [==============================] - 0s - loss: 7.4502 - val_loss: 1.9656\n",
      "Epoch 249/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.8748 - val_loss: 1.7496\n",
      "Epoch 250/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.8132 - val_loss: 1.8237\n",
      "Epoch 251/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.9389 - val_loss: 1.7756\n",
      "Epoch 252/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.1955 - val_loss: 1.8212\n",
      "Epoch 253/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.0690 - val_loss: 1.8822\n",
      "Epoch 254/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.8552 - val_loss: 1.7645\n",
      "Epoch 255/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.2078 - val_loss: 1.7511\n",
      "Epoch 256/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.8711 - val_loss: 1.8794\n",
      "Epoch 257/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.6251 - val_loss: 1.9501\n",
      "Epoch 258/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.8966 - val_loss: 1.8802\n",
      "Epoch 259/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.1593 - val_loss: 1.8005\n",
      "Epoch 260/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.7745 - val_loss: 1.8009\n",
      "Epoch 261/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.0862 - val_loss: 1.7933\n",
      "Epoch 262/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.0474 - val_loss: 1.8494\n",
      "Epoch 263/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.7612 - val_loss: 1.6773\n",
      "Epoch 264/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.7505 - val_loss: 1.7475\n",
      "Epoch 265/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.3794 - val_loss: 1.6749\n",
      "Epoch 266/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.0416 - val_loss: 1.7070\n",
      "Epoch 267/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.4166 - val_loss: 1.6760\n",
      "Epoch 268/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.9895 - val_loss: 1.7043\n",
      "Epoch 269/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.0753 - val_loss: 1.6818\n",
      "Epoch 270/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.9247 - val_loss: 1.6460\n",
      "Epoch 271/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.4932 - val_loss: 1.6879\n",
      "Epoch 272/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.9594 - val_loss: 1.7169\n",
      "Epoch 273/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.1647 - val_loss: 1.7414\n",
      "Epoch 274/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.7437 - val_loss: 1.7012\n",
      "Epoch 275/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.6980 - val_loss: 1.7774\n",
      "Epoch 276/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.7067 - val_loss: 1.6650\n",
      "Epoch 277/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.5052 - val_loss: 1.6868\n",
      "Epoch 278/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.3209 - val_loss: 1.7320\n",
      "Epoch 279/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.7842 - val_loss: 1.8526\n",
      "Epoch 280/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.1266 - val_loss: 1.6980\n",
      "Epoch 281/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.8226 - val_loss: 1.7242\n",
      "Epoch 282/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.7843 - val_loss: 2.1063\n",
      "Epoch 283/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.7163 - val_loss: 1.6538\n",
      "Epoch 284/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.6420 - val_loss: 1.6615\n",
      "Epoch 285/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.3938 - val_loss: 1.6032\n",
      "Epoch 286/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.3345 - val_loss: 1.7813\n",
      "Epoch 287/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.2474 - val_loss: 1.5851\n",
      "Epoch 288/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.3427 - val_loss: 1.5918\n",
      "Epoch 289/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.6263 - val_loss: 1.6451\n",
      "Epoch 290/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.4756 - val_loss: 1.6702\n",
      "Epoch 291/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.5055 - val_loss: 1.6083\n",
      "Epoch 292/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.2342 - val_loss: 1.5477\n",
      "Epoch 293/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.5968 - val_loss: 1.6296\n",
      "Epoch 294/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.2356 - val_loss: 1.5457\n",
      "Epoch 295/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.3566 - val_loss: 1.6291\n",
      "Epoch 296/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.4404 - val_loss: 1.5963\n",
      "Epoch 297/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.8631 - val_loss: 1.5646\n",
      "Epoch 298/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.2691 - val_loss: 1.5692\n",
      "Epoch 299/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.3184 - val_loss: 1.5635\n",
      "Epoch 300/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.4139 - val_loss: 1.5934\n",
      "Epoch 301/1000\n",
      "1000/1000 [==============================] - 0s - loss: 5.1752 - val_loss: 1.7112\n",
      "Epoch 302/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.4361 - val_loss: 1.5276\n",
      "Epoch 303/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.4239 - val_loss: 1.6038\n",
      "Epoch 304/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.4984 - val_loss: 1.6551\n",
      "Epoch 305/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.5287 - val_loss: 1.5866\n",
      "Epoch 306/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.3814 - val_loss: 1.5505\n",
      "Epoch 307/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.4361 - val_loss: 1.5174\n",
      "Epoch 308/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.2072 - val_loss: 1.6701\n",
      "Epoch 309/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.5587 - val_loss: 1.8835\n",
      "Epoch 310/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.2399 - val_loss: 1.5188\n",
      "Epoch 311/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.2844 - val_loss: 1.5002\n",
      "Epoch 312/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.1416 - val_loss: 1.4664\n",
      "Epoch 313/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.0652 - val_loss: 1.4843\n",
      "Epoch 314/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.0993 - val_loss: 1.4815\n",
      "Epoch 315/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.6183 - val_loss: 1.5138\n",
      "Epoch 316/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.2764 - val_loss: 1.5214\n",
      "Epoch 317/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.1352 - val_loss: 1.5135\n",
      "Epoch 318/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.3088 - val_loss: 1.4791\n",
      "Epoch 319/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.3150 - val_loss: 1.4450\n",
      "Epoch 320/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.3982 - val_loss: 1.4721\n",
      "Epoch 321/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.4248 - val_loss: 1.4721\n",
      "Epoch 322/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.0368 - val_loss: 1.5449\n",
      "Epoch 323/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.5626 - val_loss: 1.4728\n",
      "Epoch 324/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.4107 - val_loss: 1.5371\n",
      "Epoch 325/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9914 - val_loss: 1.6037\n",
      "Epoch 326/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.2241 - val_loss: 1.4403\n",
      "Epoch 327/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9380 - val_loss: 1.4779\n",
      "Epoch 328/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9654 - val_loss: 1.5436\n",
      "Epoch 329/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.0526 - val_loss: 1.4452\n",
      "Epoch 330/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.5945 - val_loss: 1.4740\n",
      "Epoch 331/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.0486 - val_loss: 1.4581\n",
      "Epoch 332/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.0772 - val_loss: 1.4331\n",
      "Epoch 333/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.1690 - val_loss: 1.4559\n",
      "Epoch 334/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9304 - val_loss: 1.5141\n",
      "Epoch 335/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9179 - val_loss: 1.4685\n",
      "Epoch 336/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9820 - val_loss: 1.4568\n",
      "Epoch 337/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9058 - val_loss: 1.4708\n",
      "Epoch 338/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9854 - val_loss: 1.5246\n",
      "Epoch 339/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9531 - val_loss: 1.4273\n",
      "Epoch 340/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.1978 - val_loss: 1.4683\n",
      "Epoch 341/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7256 - val_loss: 1.4025\n",
      "Epoch 342/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7908 - val_loss: 1.6222\n",
      "Epoch 343/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8527 - val_loss: 1.3715\n",
      "Epoch 344/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8249 - val_loss: 1.4248\n",
      "Epoch 345/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.0525 - val_loss: 1.5124\n",
      "Epoch 346/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.0610 - val_loss: 1.4030\n",
      "Epoch 347/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8029 - val_loss: 1.3972\n",
      "Epoch 348/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8701 - val_loss: 1.3936\n",
      "Epoch 349/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8329 - val_loss: 1.4767\n",
      "Epoch 350/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.6555 - val_loss: 1.4410\n",
      "Epoch 351/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7998 - val_loss: 1.4086\n",
      "Epoch 352/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7985 - val_loss: 1.5960\n",
      "Epoch 353/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8635 - val_loss: 1.4156\n",
      "Epoch 354/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.6989 - val_loss: 1.5499\n",
      "Epoch 355/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7531 - val_loss: 1.4220\n",
      "Epoch 356/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7418 - val_loss: 1.4860\n",
      "Epoch 357/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.0641 - val_loss: 1.3936\n",
      "Epoch 358/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8017 - val_loss: 1.4165\n",
      "Epoch 359/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9504 - val_loss: 1.4143\n",
      "Epoch 360/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.9387 - val_loss: 1.4019\n",
      "Epoch 361/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7198 - val_loss: 1.3621\n",
      "Epoch 362/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5907 - val_loss: 1.4138\n",
      "Epoch 363/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8930 - val_loss: 1.3453\n",
      "Epoch 364/1000\n",
      "1000/1000 [==============================] - 0s - loss: 4.1985 - val_loss: 1.3463\n",
      "Epoch 365/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.6845 - val_loss: 1.4281\n",
      "Epoch 366/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5891 - val_loss: 1.3461\n",
      "Epoch 367/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7422 - val_loss: 1.3962\n",
      "Epoch 368/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8173 - val_loss: 1.3250\n",
      "Epoch 369/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7576 - val_loss: 1.4080\n",
      "Epoch 370/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.6743 - val_loss: 1.3031\n",
      "Epoch 371/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5999 - val_loss: 1.3520\n",
      "Epoch 372/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7122 - val_loss: 1.3753\n",
      "Epoch 373/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5977 - val_loss: 1.3434\n",
      "Epoch 374/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3632 - val_loss: 1.3463\n",
      "Epoch 375/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.6891 - val_loss: 1.3544\n",
      "Epoch 376/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.8055 - val_loss: 1.4010\n",
      "Epoch 377/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5171 - val_loss: 1.3423\n",
      "Epoch 378/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5057 - val_loss: 1.3340\n",
      "Epoch 379/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5141 - val_loss: 1.3199\n",
      "Epoch 380/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3356 - val_loss: 1.2895\n",
      "Epoch 381/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4462 - val_loss: 1.3746\n",
      "Epoch 382/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7217 - val_loss: 1.3450\n",
      "Epoch 383/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3330 - val_loss: 1.2722\n",
      "Epoch 384/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4329 - val_loss: 1.3198\n",
      "Epoch 385/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4734 - val_loss: 1.4865\n",
      "Epoch 386/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3372 - val_loss: 1.3577\n",
      "Epoch 387/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3525 - val_loss: 1.2888\n",
      "Epoch 388/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.6556 - val_loss: 1.3492\n",
      "Epoch 389/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5405 - val_loss: 1.4373\n",
      "Epoch 390/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4748 - val_loss: 1.2724\n",
      "Epoch 391/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4686 - val_loss: 1.3646\n",
      "Epoch 392/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3313 - val_loss: 1.3004\n",
      "Epoch 393/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4369 - val_loss: 1.2942\n",
      "Epoch 394/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4265 - val_loss: 1.3331\n",
      "Epoch 395/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.7890 - val_loss: 1.3160\n",
      "Epoch 396/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3242 - val_loss: 1.3032\n",
      "Epoch 397/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3978 - val_loss: 1.2830\n",
      "Epoch 398/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.2636 - val_loss: 1.3109\n",
      "Epoch 399/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4246 - val_loss: 1.3103\n",
      "Epoch 400/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4630 - val_loss: 1.2256\n",
      "Epoch 401/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1528 - val_loss: 1.5458\n",
      "Epoch 402/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5376 - val_loss: 1.3038\n",
      "Epoch 403/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1854 - val_loss: 1.3035\n",
      "Epoch 404/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4468 - val_loss: 1.3616\n",
      "Epoch 405/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1716 - val_loss: 1.2360\n",
      "Epoch 406/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1606 - val_loss: 1.2405\n",
      "Epoch 407/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.2123 - val_loss: 1.3198\n",
      "Epoch 408/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.5628 - val_loss: 1.2907\n",
      "Epoch 409/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1516 - val_loss: 1.2468\n",
      "Epoch 410/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.2502 - val_loss: 1.2643\n",
      "Epoch 411/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4081 - val_loss: 1.3621\n",
      "Epoch 412/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1152 - val_loss: 1.2514\n",
      "Epoch 413/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1616 - val_loss: 1.2453\n",
      "Epoch 414/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1605 - val_loss: 1.3045\n",
      "Epoch 415/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3035 - val_loss: 1.2320\n",
      "Epoch 416/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1016 - val_loss: 1.2576\n",
      "Epoch 417/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.3995 - val_loss: 1.2330\n",
      "Epoch 418/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1856 - val_loss: 1.2254\n",
      "Epoch 419/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1210 - val_loss: 1.2400\n",
      "Epoch 420/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0865 - val_loss: 1.2711\n",
      "Epoch 421/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0854 - val_loss: 1.2306\n",
      "Epoch 422/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0749 - val_loss: 1.2509\n",
      "Epoch 423/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9816 - val_loss: 1.2313\n",
      "Epoch 424/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1901 - val_loss: 1.2360\n",
      "Epoch 425/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0176 - val_loss: 1.2494\n",
      "Epoch 426/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1368 - val_loss: 1.3387\n",
      "Epoch 427/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.4224 - val_loss: 1.2553\n",
      "Epoch 428/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1288 - val_loss: 1.3322\n",
      "Epoch 429/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0693 - val_loss: 1.2097\n",
      "Epoch 430/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0662 - val_loss: 1.2320\n",
      "Epoch 431/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0169 - val_loss: 1.2011\n",
      "Epoch 432/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9856 - val_loss: 1.2156\n",
      "Epoch 433/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0965 - val_loss: 1.2015\n",
      "Epoch 434/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1524 - val_loss: 1.1974\n",
      "Epoch 435/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8962 - val_loss: 1.3365\n",
      "Epoch 436/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0729 - val_loss: 1.2129\n",
      "Epoch 437/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0742 - val_loss: 1.1555\n",
      "Epoch 438/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1804 - val_loss: 1.1451\n",
      "Epoch 439/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0216 - val_loss: 1.1788\n",
      "Epoch 440/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1646 - val_loss: 1.1765\n",
      "Epoch 441/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9585 - val_loss: 1.1860\n",
      "Epoch 442/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9413 - val_loss: 1.1641\n",
      "Epoch 443/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0217 - val_loss: 1.2214\n",
      "Epoch 444/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9857 - val_loss: 1.1852\n",
      "Epoch 445/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9178 - val_loss: 1.1918\n",
      "Epoch 446/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8830 - val_loss: 1.1650\n",
      "Epoch 447/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9957 - val_loss: 1.2156\n",
      "Epoch 448/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9591 - val_loss: 1.2448\n",
      "Epoch 449/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8875 - val_loss: 1.2241\n",
      "Epoch 450/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.1132 - val_loss: 1.1950\n",
      "Epoch 451/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9023 - val_loss: 1.2047\n",
      "Epoch 452/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0850 - val_loss: 1.1992\n",
      "Epoch 453/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8020 - val_loss: 1.1576\n",
      "Epoch 454/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9174 - val_loss: 1.1966\n",
      "Epoch 455/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8493 - val_loss: 1.2833\n",
      "Epoch 456/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9748 - val_loss: 1.1772\n",
      "Epoch 457/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8099 - val_loss: 1.1516\n",
      "Epoch 458/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8399 - val_loss: 1.1386\n",
      "Epoch 459/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7897 - val_loss: 1.1393\n",
      "Epoch 460/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7688 - val_loss: 1.2351\n",
      "Epoch 461/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8065 - val_loss: 1.2175\n",
      "Epoch 462/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7956 - val_loss: 1.2051\n",
      "Epoch 463/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8266 - val_loss: 1.1439\n",
      "Epoch 464/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7337 - val_loss: 1.1556\n",
      "Epoch 465/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7019 - val_loss: 1.1301\n",
      "Epoch 466/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8598 - val_loss: 1.1581\n",
      "Epoch 467/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.9306 - val_loss: 1.1465\n",
      "Epoch 468/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7184 - val_loss: 1.1159\n",
      "Epoch 469/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8028 - val_loss: 1.1306\n",
      "Epoch 470/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8081 - val_loss: 1.1470\n",
      "Epoch 471/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7909 - val_loss: 1.1723\n",
      "Epoch 472/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7085 - val_loss: 1.1230\n",
      "Epoch 473/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7357 - val_loss: 1.2527\n",
      "Epoch 474/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6820 - val_loss: 1.1513\n",
      "Epoch 475/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7039 - val_loss: 1.2557\n",
      "Epoch 476/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6805 - val_loss: 1.1363\n",
      "Epoch 477/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6377 - val_loss: 1.1292\n",
      "Epoch 478/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6816 - val_loss: 1.1742\n",
      "Epoch 479/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6793 - val_loss: 1.1378\n",
      "Epoch 480/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5900 - val_loss: 1.1523\n",
      "Epoch 481/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6551 - val_loss: 1.2817\n",
      "Epoch 482/1000\n",
      "1000/1000 [==============================] - 0s - loss: 3.0076 - val_loss: 1.1451\n",
      "Epoch 483/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5452 - val_loss: 1.1119\n",
      "Epoch 484/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5741 - val_loss: 1.1191\n",
      "Epoch 485/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5944 - val_loss: 1.1668\n",
      "Epoch 486/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6158 - val_loss: 1.1653\n",
      "Epoch 487/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5927 - val_loss: 1.1492\n",
      "Epoch 488/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5905 - val_loss: 1.1450\n",
      "Epoch 489/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7158 - val_loss: 1.1482\n",
      "Epoch 490/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5416 - val_loss: 1.1397\n",
      "Epoch 491/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6483 - val_loss: 1.1114\n",
      "Epoch 492/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5876 - val_loss: 1.1885\n",
      "Epoch 493/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.4975 - val_loss: 1.1736\n",
      "Epoch 494/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.7264 - val_loss: 1.1034\n",
      "Epoch 495/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6085 - val_loss: 1.1054\n",
      "Epoch 496/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5812 - val_loss: 1.0697\n",
      "Epoch 497/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5497 - val_loss: 1.0949\n",
      "Epoch 498/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5118 - val_loss: 1.1316\n",
      "Epoch 499/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5126 - val_loss: 1.1171\n",
      "Epoch 500/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5302 - val_loss: 1.1454\n",
      "Epoch 501/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6670 - val_loss: 1.1368\n",
      "Epoch 502/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5230 - val_loss: 1.0802\n",
      "Epoch 503/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5407 - val_loss: 1.1406\n",
      "Epoch 504/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5033 - val_loss: 1.1063\n",
      "Epoch 505/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.4372 - val_loss: 1.0746\n",
      "Epoch 506/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.8048 - val_loss: 1.1215\n",
      "Epoch 507/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5310 - val_loss: 1.1476\n",
      "Epoch 508/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6959 - val_loss: 1.1008\n",
      "Epoch 509/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.4694 - val_loss: 1.1173\n",
      "Epoch 510/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.4363 - val_loss: 1.1139\n",
      "Epoch 511/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.4304 - val_loss: 1.0867\n",
      "Epoch 512/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.5050 - val_loss: 1.0961\n",
      "Epoch 513/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.6045 - val_loss: 1.0606\n",
      "Epoch 514/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.4590 - val_loss: 1.1199\n",
      "Epoch 515/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.4577 - val_loss: 1.0537\n",
      "Epoch 516/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.4802 - val_loss: 1.0955\n",
      "Epoch 517/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3618 - val_loss: 1.0565\n",
      "Epoch 518/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3547 - val_loss: 1.0874\n",
      "Epoch 519/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3889 - val_loss: 1.0919\n",
      "Epoch 520/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3782 - val_loss: 1.0548\n",
      "Epoch 521/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3856 - val_loss: 1.0751\n",
      "Epoch 522/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3699 - val_loss: 1.0703\n",
      "Epoch 523/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3018 - val_loss: 1.0697\n",
      "Epoch 524/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3426 - val_loss: 1.0832\n",
      "Epoch 525/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3445 - val_loss: 1.1067\n",
      "Epoch 526/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.4015 - val_loss: 1.0699\n",
      "Epoch 527/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3245 - val_loss: 1.0796\n",
      "Epoch 528/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3811 - val_loss: 1.0650\n",
      "Epoch 529/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3500 - val_loss: 1.0867\n",
      "Epoch 530/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2619 - val_loss: 1.0673\n",
      "Epoch 531/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3369 - val_loss: 1.0956\n",
      "Epoch 532/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2610 - val_loss: 1.0784\n",
      "Epoch 533/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3140 - val_loss: 1.0765\n",
      "Epoch 534/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3029 - val_loss: 1.0812\n",
      "Epoch 535/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3277 - val_loss: 1.0800\n",
      "Epoch 536/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3304 - val_loss: 1.0620\n",
      "Epoch 537/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3067 - val_loss: 1.0624\n",
      "Epoch 538/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3246 - val_loss: 1.1249\n",
      "Epoch 539/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2427 - val_loss: 1.0140\n",
      "Epoch 540/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2458 - val_loss: 1.0500\n",
      "Epoch 541/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2777 - val_loss: 1.1070\n",
      "Epoch 542/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2328 - val_loss: 1.0822\n",
      "Epoch 543/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2284 - val_loss: 1.0575\n",
      "Epoch 544/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.3304 - val_loss: 1.1047\n",
      "Epoch 545/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2135 - val_loss: 1.0404\n",
      "Epoch 546/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2131 - val_loss: 1.1252\n",
      "Epoch 547/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2372 - val_loss: 1.0617\n",
      "Epoch 548/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2139 - val_loss: 1.0418\n",
      "Epoch 549/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2034 - val_loss: 1.0868\n",
      "Epoch 550/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2416 - val_loss: 1.0971\n",
      "Epoch 551/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1991 - val_loss: 1.0807\n",
      "Epoch 552/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.2303 - val_loss: 1.0338\n",
      "Epoch 553/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1963 - val_loss: 1.0546\n",
      "Epoch 554/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1680 - val_loss: 1.0571\n",
      "Epoch 555/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1757 - val_loss: 1.0145\n",
      "Epoch 556/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1041 - val_loss: 1.0709\n",
      "Epoch 557/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1484 - val_loss: 1.0529\n",
      "Epoch 558/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1420 - val_loss: 1.0439\n",
      "Epoch 559/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1781 - val_loss: 1.0379\n",
      "Epoch 560/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1409 - val_loss: 1.0377\n",
      "Epoch 561/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1260 - val_loss: 1.0656\n",
      "Epoch 562/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1483 - val_loss: 1.0372\n",
      "Epoch 563/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1488 - val_loss: 1.1455\n",
      "Epoch 564/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1697 - val_loss: 1.0341\n",
      "Epoch 565/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1633 - val_loss: 1.0140\n",
      "Epoch 566/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0734 - val_loss: 1.0411\n",
      "Epoch 567/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1073 - val_loss: 1.0327\n",
      "Epoch 568/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1147 - val_loss: 1.0674\n",
      "Epoch 569/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1226 - val_loss: 1.0694\n",
      "Epoch 570/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1035 - val_loss: 1.0311\n",
      "Epoch 571/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0905 - val_loss: 1.0627\n",
      "Epoch 572/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1011 - val_loss: 1.0454\n",
      "Epoch 573/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.1024 - val_loss: 1.0497\n",
      "Epoch 574/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0798 - val_loss: 1.0207\n",
      "Epoch 575/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0158 - val_loss: 1.0562\n",
      "Epoch 576/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0750 - val_loss: 1.0354\n",
      "Epoch 577/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0301 - val_loss: 1.0176\n",
      "Epoch 578/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0393 - val_loss: 1.0354\n",
      "Epoch 579/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0453 - val_loss: 1.0520\n",
      "Epoch 580/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0574 - val_loss: 1.0388\n",
      "Epoch 581/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9956 - val_loss: 1.0173\n",
      "Epoch 582/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9903 - val_loss: 1.0204\n",
      "Epoch 583/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9995 - val_loss: 1.0449\n",
      "Epoch 584/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9998 - val_loss: 1.0081\n",
      "Epoch 585/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0703 - val_loss: 1.0106\n",
      "Epoch 586/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0180 - val_loss: 1.0404\n",
      "Epoch 587/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0087 - val_loss: 1.0387\n",
      "Epoch 588/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9972 - val_loss: 1.0420\n",
      "Epoch 589/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0276 - val_loss: 1.0096\n",
      "Epoch 590/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9768 - val_loss: 1.0235\n",
      "Epoch 591/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9792 - val_loss: 0.9913\n",
      "Epoch 592/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9667 - val_loss: 1.0316\n",
      "Epoch 593/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9429 - val_loss: 0.9999\n",
      "Epoch 594/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9983 - val_loss: 1.0042\n",
      "Epoch 595/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9688 - val_loss: 1.0139\n",
      "Epoch 596/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9244 - val_loss: 1.0140\n",
      "Epoch 597/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9763 - val_loss: 0.9972\n",
      "Epoch 598/1000\n",
      "1000/1000 [==============================] - 0s - loss: 2.0020 - val_loss: 0.9985\n",
      "Epoch 599/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9658 - val_loss: 1.0136\n",
      "Epoch 600/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9730 - val_loss: 1.0554\n",
      "Epoch 601/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9558 - val_loss: 1.0230\n",
      "Epoch 602/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9409 - val_loss: 1.0121\n",
      "Epoch 603/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9591 - val_loss: 1.0160\n",
      "Epoch 604/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9264 - val_loss: 0.9973\n",
      "Epoch 605/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8868 - val_loss: 1.0220\n",
      "Epoch 606/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8714 - val_loss: 1.0012\n",
      "Epoch 607/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9089 - val_loss: 1.0358\n",
      "Epoch 608/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9080 - val_loss: 1.0182\n",
      "Epoch 609/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8659 - val_loss: 1.0170\n",
      "Epoch 610/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8979 - val_loss: 1.0024\n",
      "Epoch 611/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8584 - val_loss: 1.0346\n",
      "Epoch 612/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.9113 - val_loss: 0.9852\n",
      "Epoch 613/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8779 - val_loss: 0.9722\n",
      "Epoch 614/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8638 - val_loss: 1.0219\n",
      "Epoch 615/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8655 - val_loss: 1.0039\n",
      "Epoch 616/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8953 - val_loss: 1.0224\n",
      "Epoch 617/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8269 - val_loss: 0.9912\n",
      "Epoch 618/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8578 - val_loss: 1.0184\n",
      "Epoch 619/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8590 - val_loss: 0.9922\n",
      "Epoch 620/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8310 - val_loss: 1.0156\n",
      "Epoch 621/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8498 - val_loss: 0.9779\n",
      "Epoch 622/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8453 - val_loss: 0.9875\n",
      "Epoch 623/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8414 - val_loss: 0.9779\n",
      "Epoch 624/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8414 - val_loss: 1.0015\n",
      "Epoch 625/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8278 - val_loss: 1.0190\n",
      "Epoch 626/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8070 - val_loss: 0.9867\n",
      "Epoch 627/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8107 - val_loss: 0.9868\n",
      "Epoch 628/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8100 - val_loss: 0.9647\n",
      "Epoch 629/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7913 - val_loss: 0.9887\n",
      "Epoch 630/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8140 - val_loss: 1.0041\n",
      "Epoch 631/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7628 - val_loss: 0.9987\n",
      "Epoch 632/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.8529 - val_loss: 0.9623\n",
      "Epoch 633/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7716 - val_loss: 0.9811\n",
      "Epoch 634/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7625 - val_loss: 0.9896\n",
      "Epoch 635/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7857 - val_loss: 0.9788\n",
      "Epoch 636/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7422 - val_loss: 0.9909\n",
      "Epoch 637/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7459 - val_loss: 0.9865\n",
      "Epoch 638/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7683 - val_loss: 0.9919\n",
      "Epoch 639/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7794 - val_loss: 0.9671\n",
      "Epoch 640/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7514 - val_loss: 1.0198\n",
      "Epoch 641/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7370 - val_loss: 0.9751\n",
      "Epoch 642/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7237 - val_loss: 1.0063\n",
      "Epoch 643/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7309 - val_loss: 1.0039\n",
      "Epoch 644/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7135 - val_loss: 1.0007\n",
      "Epoch 645/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7335 - val_loss: 0.9707\n",
      "Epoch 646/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7401 - val_loss: 1.0034\n",
      "Epoch 647/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7044 - val_loss: 0.9977\n",
      "Epoch 648/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7322 - val_loss: 1.0234\n",
      "Epoch 649/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7104 - val_loss: 0.9989\n",
      "Epoch 650/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7333 - val_loss: 0.9960\n",
      "Epoch 651/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7204 - val_loss: 0.9672\n",
      "Epoch 652/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7204 - val_loss: 0.9729\n",
      "Epoch 653/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.7149 - val_loss: 0.9828\n",
      "Epoch 654/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6889 - val_loss: 0.9728\n",
      "Epoch 655/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6887 - val_loss: 0.9522\n",
      "Epoch 656/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6883 - val_loss: 0.9790\n",
      "Epoch 657/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6747 - val_loss: 1.0013\n",
      "Epoch 658/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6666 - val_loss: 0.9945\n",
      "Epoch 659/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6913 - val_loss: 1.0010\n",
      "Epoch 660/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6768 - val_loss: 0.9871\n",
      "Epoch 661/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6638 - val_loss: 0.9700\n",
      "Epoch 662/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6747 - val_loss: 0.9677\n",
      "Epoch 663/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6466 - val_loss: 0.9523\n",
      "Epoch 664/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6839 - val_loss: 0.9745\n",
      "Epoch 665/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6386 - val_loss: 1.0013\n",
      "Epoch 666/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6618 - val_loss: 0.9561\n",
      "Epoch 667/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6378 - val_loss: 0.9678\n",
      "Epoch 668/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6251 - val_loss: 0.9817\n",
      "Epoch 669/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6573 - val_loss: 0.9811\n",
      "Epoch 670/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6330 - val_loss: 1.0016\n",
      "Epoch 671/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6594 - val_loss: 0.9494\n",
      "Epoch 672/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5964 - val_loss: 0.9608\n",
      "Epoch 673/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6279 - val_loss: 0.9732\n",
      "Epoch 674/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6385 - val_loss: 0.9121\n",
      "Epoch 675/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6088 - val_loss: 0.9732\n",
      "Epoch 676/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5953 - val_loss: 0.9693\n",
      "Epoch 677/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5956 - val_loss: 0.9729\n",
      "Epoch 678/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6139 - val_loss: 0.9883\n",
      "Epoch 679/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5953 - val_loss: 0.9570\n",
      "Epoch 680/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6172 - val_loss: 0.9936\n",
      "Epoch 681/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.6145 - val_loss: 0.9695\n",
      "Epoch 682/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5989 - val_loss: 0.9675\n",
      "Epoch 683/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5980 - val_loss: 0.9522\n",
      "Epoch 684/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5935 - val_loss: 0.9448\n",
      "Epoch 685/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5834 - val_loss: 0.9738\n",
      "Epoch 686/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5949 - val_loss: 0.9813\n",
      "Epoch 687/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5625 - val_loss: 0.9761\n",
      "Epoch 688/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5909 - val_loss: 0.9546\n",
      "Epoch 689/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5741 - val_loss: 0.9712\n",
      "Epoch 690/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5515 - val_loss: 0.9655\n",
      "Epoch 691/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5700 - val_loss: 0.9581\n",
      "Epoch 692/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5775 - val_loss: 0.9728\n",
      "Epoch 693/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5517 - val_loss: 0.9923\n",
      "Epoch 694/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5772 - val_loss: 0.9755\n",
      "Epoch 695/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5371 - val_loss: 0.9441\n",
      "Epoch 696/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5574 - val_loss: 0.9604\n",
      "Epoch 697/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5552 - val_loss: 0.9474\n",
      "Epoch 698/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5636 - val_loss: 0.9910\n",
      "Epoch 699/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5357 - val_loss: 0.9849\n",
      "Epoch 700/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5412 - val_loss: 0.9549\n",
      "Epoch 701/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5316 - val_loss: 0.9680\n",
      "Epoch 702/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5424 - val_loss: 0.9904\n",
      "Epoch 703/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5219 - val_loss: 0.9570\n",
      "Epoch 704/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5114 - val_loss: 0.9453\n",
      "Epoch 705/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5206 - val_loss: 0.9490\n",
      "Epoch 706/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5325 - val_loss: 0.9617\n",
      "Epoch 707/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5324 - val_loss: 0.9737\n",
      "Epoch 708/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5176 - val_loss: 0.9383\n",
      "Epoch 709/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5298 - val_loss: 0.9487\n",
      "Epoch 710/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5068 - val_loss: 0.9379\n",
      "Epoch 711/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5169 - val_loss: 0.9691\n",
      "Epoch 712/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5185 - val_loss: 0.9618\n",
      "Epoch 713/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5073 - val_loss: 0.9630\n",
      "Epoch 714/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5108 - val_loss: 0.9291\n",
      "Epoch 715/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5210 - val_loss: 0.9812\n",
      "Epoch 716/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5182 - val_loss: 0.9459\n",
      "Epoch 717/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5216 - val_loss: 0.9493\n",
      "Epoch 718/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.5155 - val_loss: 0.9693\n",
      "Epoch 719/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4846 - val_loss: 0.9523\n",
      "Epoch 720/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4783 - val_loss: 0.9827\n",
      "Epoch 721/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4876 - val_loss: 0.9554\n",
      "Epoch 722/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4972 - val_loss: 0.9545\n",
      "Epoch 723/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4830 - val_loss: 0.9816\n",
      "Epoch 724/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4942 - val_loss: 0.9471\n",
      "Epoch 725/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4775 - val_loss: 0.9413\n",
      "Epoch 726/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4624 - val_loss: 0.9542\n",
      "Epoch 727/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4730 - val_loss: 0.9640\n",
      "Epoch 728/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4833 - val_loss: 0.9788\n",
      "Epoch 729/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4506 - val_loss: 0.9429\n",
      "Epoch 730/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4458 - val_loss: 0.9435\n",
      "Epoch 731/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4539 - val_loss: 0.9713\n",
      "Epoch 732/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4712 - val_loss: 0.9612\n",
      "Epoch 733/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4311 - val_loss: 0.9410\n",
      "Epoch 734/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4381 - val_loss: 0.9885\n",
      "Epoch 735/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4679 - val_loss: 0.9641\n",
      "Epoch 736/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4495 - val_loss: 0.9617\n",
      "Epoch 737/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4629 - val_loss: 0.9306\n",
      "Epoch 738/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4739 - val_loss: 0.9895\n",
      "Epoch 739/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4836 - val_loss: 0.9594\n",
      "Epoch 740/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4549 - val_loss: 0.9531\n",
      "Epoch 741/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4531 - val_loss: 0.9359\n",
      "Epoch 742/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4539 - val_loss: 0.9618\n",
      "Epoch 743/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4553 - val_loss: 0.9521\n",
      "Epoch 744/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4298 - val_loss: 0.9887\n",
      "Epoch 745/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4420 - val_loss: 0.9660\n",
      "Epoch 746/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4485 - val_loss: 0.9537\n",
      "Epoch 747/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4499 - val_loss: 0.9795\n",
      "Epoch 748/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4200 - val_loss: 0.9649\n",
      "Epoch 749/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4411 - val_loss: 0.9784\n",
      "Epoch 750/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4192 - val_loss: 0.9829\n",
      "Epoch 751/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4382 - val_loss: 0.9574\n",
      "Epoch 752/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4221 - val_loss: 0.9807\n",
      "Epoch 753/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4175 - val_loss: 0.9441\n",
      "Epoch 754/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4355 - val_loss: 0.9460\n",
      "Epoch 755/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4324 - val_loss: 0.9713\n",
      "Epoch 756/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4377 - val_loss: 0.9322\n",
      "Epoch 757/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3978 - val_loss: 0.9591\n",
      "Epoch 758/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3998 - val_loss: 0.9542\n",
      "Epoch 759/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4101 - val_loss: 0.9495\n",
      "Epoch 760/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3990 - val_loss: 0.9512\n",
      "Epoch 761/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4126 - val_loss: 0.9483\n",
      "Epoch 762/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4103 - val_loss: 0.9598\n",
      "Epoch 763/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4000 - val_loss: 0.9705\n",
      "Epoch 764/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4129 - val_loss: 0.9633\n",
      "Epoch 765/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4307 - val_loss: 0.9930\n",
      "Epoch 766/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4202 - val_loss: 0.9403\n",
      "Epoch 767/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4161 - val_loss: 0.9454\n",
      "Epoch 768/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3996 - val_loss: 0.9266\n",
      "Epoch 769/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4259 - val_loss: 0.9398\n",
      "Epoch 770/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4021 - val_loss: 0.9346\n",
      "Epoch 771/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4384 - val_loss: 0.9384\n",
      "Epoch 772/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4179 - val_loss: 0.9336\n",
      "Epoch 773/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4100 - val_loss: 0.9760\n",
      "Epoch 774/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4006 - val_loss: 0.9285\n",
      "Epoch 775/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3949 - val_loss: 0.9250\n",
      "Epoch 776/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4114 - val_loss: 0.9666\n",
      "Epoch 777/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3779 - val_loss: 0.9401\n",
      "Epoch 778/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.4199 - val_loss: 0.9594\n",
      "Epoch 779/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3919 - val_loss: 0.9546\n",
      "Epoch 780/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3914 - val_loss: 0.9478\n",
      "Epoch 781/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3828 - val_loss: 0.9521\n",
      "Epoch 782/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3812 - val_loss: 0.9664\n",
      "Epoch 783/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3817 - val_loss: 0.9362\n",
      "Epoch 784/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3861 - val_loss: 0.9791\n",
      "Epoch 785/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3904 - val_loss: 0.9428\n",
      "Epoch 786/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3838 - val_loss: 0.9288\n",
      "Epoch 787/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3714 - val_loss: 0.9693\n",
      "Epoch 788/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3986 - val_loss: 0.9659\n",
      "Epoch 789/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3995 - val_loss: 0.9588\n",
      "Epoch 790/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3907 - val_loss: 0.9664\n",
      "Epoch 791/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3990 - val_loss: 0.9530\n",
      "Epoch 792/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3952 - val_loss: 0.9640\n",
      "Epoch 793/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3764 - val_loss: 0.9559\n",
      "Epoch 794/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3807 - val_loss: 0.9708\n",
      "Epoch 795/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3811 - val_loss: 0.9729\n",
      "Epoch 796/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3805 - val_loss: 0.9389\n",
      "Epoch 797/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3973 - val_loss: 0.9786\n",
      "Epoch 798/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3710 - val_loss: 0.9686\n",
      "Epoch 799/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3790 - val_loss: 0.9736\n",
      "Epoch 800/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3912 - val_loss: 0.9444\n",
      "Epoch 801/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3738 - val_loss: 0.9480\n",
      "Epoch 802/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3556 - val_loss: 0.9651\n",
      "Epoch 803/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3595 - val_loss: 0.9730\n",
      "Epoch 804/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3653 - val_loss: 0.9921\n",
      "Epoch 805/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3753 - val_loss: 0.9846\n",
      "Epoch 806/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3647 - val_loss: 0.9669\n",
      "Epoch 807/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3570 - val_loss: 0.9483\n",
      "Epoch 808/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3389 - val_loss: 0.9665\n",
      "Epoch 809/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3679 - val_loss: 0.9564\n",
      "Epoch 810/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3651 - val_loss: 1.0131\n",
      "Epoch 811/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3815 - val_loss: 0.9533\n",
      "Epoch 812/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3607 - val_loss: 0.9526\n",
      "Epoch 813/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3606 - val_loss: 0.9335\n",
      "Epoch 814/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3394 - val_loss: 0.9460\n",
      "Epoch 815/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3468 - val_loss: 0.9643\n",
      "Epoch 816/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3538 - val_loss: 0.9843\n",
      "Epoch 817/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3588 - val_loss: 0.9640\n",
      "Epoch 818/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3606 - val_loss: 0.9551\n",
      "Epoch 819/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3660 - val_loss: 0.9995\n",
      "Epoch 820/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3604 - val_loss: 0.9736\n",
      "Epoch 821/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3637 - val_loss: 0.9900\n",
      "Epoch 822/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3495 - val_loss: 0.9932\n",
      "Epoch 823/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3337 - val_loss: 0.9697\n",
      "Epoch 824/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3519 - val_loss: 0.9933\n",
      "Epoch 825/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3436 - val_loss: 0.9548\n",
      "Epoch 826/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3781 - val_loss: 0.9396\n",
      "Epoch 827/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3481 - val_loss: 0.9607\n",
      "Epoch 828/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3622 - val_loss: 0.9675\n",
      "Epoch 829/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3738 - val_loss: 0.9697\n",
      "Epoch 830/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3647 - val_loss: 0.9848\n",
      "Epoch 831/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3327 - val_loss: 0.9585\n",
      "Epoch 832/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3465 - val_loss: 0.9429\n",
      "Epoch 833/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3376 - val_loss: 0.9766\n",
      "Epoch 834/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3392 - val_loss: 0.9698\n",
      "Epoch 835/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3694 - val_loss: 0.9582\n",
      "Epoch 836/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3354 - val_loss: 0.9779\n",
      "Epoch 837/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3406 - val_loss: 0.9596\n",
      "Epoch 838/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3467 - val_loss: 0.9818\n",
      "Epoch 839/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3727 - val_loss: 0.9659\n",
      "Epoch 840/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3415 - val_loss: 0.9822\n",
      "Epoch 841/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3571 - val_loss: 0.9603\n",
      "Epoch 842/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3333 - val_loss: 0.9520\n",
      "Epoch 843/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3604 - val_loss: 0.9892\n",
      "Epoch 844/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3420 - val_loss: 0.9886\n",
      "Epoch 845/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3482 - val_loss: 0.9831\n",
      "Epoch 846/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3488 - val_loss: 0.9534\n",
      "Epoch 847/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3406 - val_loss: 0.9392\n",
      "Epoch 848/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3379 - val_loss: 0.9990\n",
      "Epoch 849/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3350 - val_loss: 0.9542\n",
      "Epoch 850/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3345 - val_loss: 0.9894\n",
      "Epoch 851/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3391 - val_loss: 0.9751\n",
      "Epoch 852/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3316 - val_loss: 0.9530\n",
      "Epoch 853/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3072 - val_loss: 0.9862\n",
      "Epoch 854/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3382 - val_loss: 1.0235\n",
      "Epoch 855/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3290 - val_loss: 0.9586\n",
      "Epoch 856/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3347 - val_loss: 0.9868\n",
      "Epoch 857/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3321 - val_loss: 0.9741\n",
      "Epoch 858/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3275 - val_loss: 0.9865\n",
      "Epoch 859/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3382 - val_loss: 0.9672\n",
      "Epoch 860/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3257 - val_loss: 0.9587\n",
      "Epoch 861/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3131 - val_loss: 0.9759\n",
      "Epoch 862/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3215 - val_loss: 0.9754\n",
      "Epoch 863/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3321 - val_loss: 0.9992\n",
      "Epoch 864/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3150 - val_loss: 0.9658\n",
      "Epoch 865/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3235 - val_loss: 1.0093\n",
      "Epoch 866/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2998 - val_loss: 0.9764\n",
      "Epoch 867/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2976 - val_loss: 0.9940\n",
      "Epoch 868/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3249 - val_loss: 0.9870\n",
      "Epoch 869/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3055 - val_loss: 0.9739\n",
      "Epoch 870/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3057 - val_loss: 0.9887\n",
      "Epoch 871/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2919 - val_loss: 0.9749\n",
      "Epoch 872/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3195 - val_loss: 0.9944\n",
      "Epoch 873/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3113 - val_loss: 0.9896\n",
      "Epoch 874/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3278 - val_loss: 0.9958\n",
      "Epoch 875/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3151 - val_loss: 1.0322\n",
      "Epoch 876/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3009 - val_loss: 0.9924\n",
      "Epoch 877/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3268 - val_loss: 0.9887\n",
      "Epoch 878/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3270 - val_loss: 0.9959\n",
      "Epoch 879/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3043 - val_loss: 0.9732\n",
      "Epoch 880/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3116 - val_loss: 0.9783\n",
      "Epoch 881/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3113 - val_loss: 0.9670\n",
      "Epoch 882/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3097 - val_loss: 0.9810\n",
      "Epoch 883/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3240 - val_loss: 0.9643\n",
      "Epoch 884/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3169 - val_loss: 0.9653\n",
      "Epoch 885/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2994 - val_loss: 0.9707\n",
      "Epoch 886/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3073 - val_loss: 0.9862\n",
      "Epoch 887/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3118 - val_loss: 0.9961\n",
      "Epoch 888/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2957 - val_loss: 0.9950\n",
      "Epoch 889/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3078 - val_loss: 0.9896\n",
      "Epoch 890/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3138 - val_loss: 0.9969\n",
      "Epoch 891/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2893 - val_loss: 0.9612\n",
      "Epoch 892/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3018 - val_loss: 0.9832\n",
      "Epoch 893/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2957 - val_loss: 0.9726\n",
      "Epoch 894/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2849 - val_loss: 0.9745\n",
      "Epoch 895/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3144 - val_loss: 1.0036\n",
      "Epoch 896/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2877 - val_loss: 1.0262\n",
      "Epoch 897/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3065 - val_loss: 0.9948\n",
      "Epoch 898/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3124 - val_loss: 0.9948\n",
      "Epoch 899/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2744 - val_loss: 1.0092\n",
      "Epoch 900/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2655 - val_loss: 0.9860\n",
      "Epoch 901/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2857 - val_loss: 1.0018\n",
      "Epoch 902/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3014 - val_loss: 0.9861\n",
      "Epoch 903/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2985 - val_loss: 0.9980\n",
      "Epoch 904/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2789 - val_loss: 1.0026\n",
      "Epoch 905/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2925 - val_loss: 0.9882\n",
      "Epoch 906/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2803 - val_loss: 1.0041\n",
      "Epoch 907/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2835 - val_loss: 0.9718\n",
      "Epoch 908/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2808 - val_loss: 0.9985\n",
      "Epoch 909/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3004 - val_loss: 1.0101\n",
      "Epoch 910/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2970 - val_loss: 1.0243\n",
      "Epoch 911/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2844 - val_loss: 0.9928\n",
      "Epoch 912/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2857 - val_loss: 0.9811\n",
      "Epoch 913/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2795 - val_loss: 0.9890\n",
      "Epoch 914/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.3080 - val_loss: 1.0026\n",
      "Epoch 915/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2976 - val_loss: 0.9926\n",
      "Epoch 916/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2908 - val_loss: 0.9886\n",
      "Epoch 917/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2912 - val_loss: 0.9874\n",
      "Epoch 918/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2883 - val_loss: 0.9878\n",
      "Epoch 919/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2798 - val_loss: 0.9909\n",
      "Epoch 920/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2533 - val_loss: 0.9914\n",
      "Epoch 921/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2883 - val_loss: 1.0011\n",
      "Epoch 922/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2959 - val_loss: 1.0093\n",
      "Epoch 923/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2890 - val_loss: 0.9862\n",
      "Epoch 924/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2855 - val_loss: 0.9988\n",
      "Epoch 925/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2899 - val_loss: 1.0216\n",
      "Epoch 926/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2698 - val_loss: 1.0031\n",
      "Epoch 927/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2637 - val_loss: 0.9964\n",
      "Epoch 928/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2799 - val_loss: 1.0018\n",
      "Epoch 929/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2778 - val_loss: 0.9887\n",
      "Epoch 930/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2810 - val_loss: 0.9871\n",
      "Epoch 931/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2656 - val_loss: 0.9877\n",
      "Epoch 932/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2630 - val_loss: 0.9925\n",
      "Epoch 933/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2710 - val_loss: 0.9920\n",
      "Epoch 934/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2682 - val_loss: 1.0518\n",
      "Epoch 935/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2796 - val_loss: 1.0078\n",
      "Epoch 936/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2655 - val_loss: 1.0137\n",
      "Epoch 937/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2527 - val_loss: 0.9952\n",
      "Epoch 938/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2719 - val_loss: 1.0135\n",
      "Epoch 939/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2664 - val_loss: 1.0124\n",
      "Epoch 940/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2626 - val_loss: 1.0120\n",
      "Epoch 941/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2727 - val_loss: 1.0004\n",
      "Epoch 942/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2598 - val_loss: 0.9993\n",
      "Epoch 943/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2649 - val_loss: 0.9913\n",
      "Epoch 944/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2658 - val_loss: 0.9968\n",
      "Epoch 945/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2721 - val_loss: 1.0100\n",
      "Epoch 946/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2871 - val_loss: 0.9731\n",
      "Epoch 947/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2455 - val_loss: 0.9892\n",
      "Epoch 948/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2634 - val_loss: 1.0105\n",
      "Epoch 949/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2764 - val_loss: 1.0050\n",
      "Epoch 950/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2702 - val_loss: 0.9827\n",
      "Epoch 951/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2683 - val_loss: 1.0109\n",
      "Epoch 952/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2576 - val_loss: 0.9847\n",
      "Epoch 953/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2583 - val_loss: 1.0223\n",
      "Epoch 954/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2678 - val_loss: 0.9782\n",
      "Epoch 955/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2432 - val_loss: 1.0090\n",
      "Epoch 956/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2533 - val_loss: 0.9923\n",
      "Epoch 957/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2404 - val_loss: 0.9838\n",
      "Epoch 958/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2634 - val_loss: 1.0103\n",
      "Epoch 959/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2618 - val_loss: 1.0084\n",
      "Epoch 960/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2572 - val_loss: 0.9778\n",
      "Epoch 961/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2520 - val_loss: 0.9904\n",
      "Epoch 962/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2844 - val_loss: 0.9946\n",
      "Epoch 963/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2590 - val_loss: 1.0358\n",
      "Epoch 964/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2660 - val_loss: 1.0090\n",
      "Epoch 965/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2655 - val_loss: 0.9980\n",
      "Epoch 966/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2283 - val_loss: 0.9996\n",
      "Epoch 967/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2376 - val_loss: 1.0249\n",
      "Epoch 968/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2449 - val_loss: 0.9915\n",
      "Epoch 969/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2430 - val_loss: 1.0158\n",
      "Epoch 970/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2666 - val_loss: 0.9815\n",
      "Epoch 971/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2496 - val_loss: 1.0140\n",
      "Epoch 972/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2391 - val_loss: 1.0208\n",
      "Epoch 973/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2297 - val_loss: 0.9948\n",
      "Epoch 974/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2554 - val_loss: 1.0094\n",
      "Epoch 975/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2425 - val_loss: 1.0068\n",
      "Epoch 976/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2420 - val_loss: 0.9999\n",
      "Epoch 977/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2388 - val_loss: 0.9971\n",
      "Epoch 978/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2405 - val_loss: 1.0143\n",
      "Epoch 979/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2557 - val_loss: 1.0249\n",
      "Epoch 980/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2579 - val_loss: 0.9988\n",
      "Epoch 981/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2512 - val_loss: 0.9910\n",
      "Epoch 982/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2434 - val_loss: 0.9941\n",
      "Epoch 983/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2354 - val_loss: 1.0024\n",
      "Epoch 984/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2498 - val_loss: 1.0029\n",
      "Epoch 985/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2345 - val_loss: 0.9968\n",
      "Epoch 986/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2368 - val_loss: 0.9903\n",
      "Epoch 987/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2342 - val_loss: 1.0094\n",
      "Epoch 988/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2460 - val_loss: 1.0223\n",
      "Epoch 989/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2346 - val_loss: 1.0397\n",
      "Epoch 990/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2447 - val_loss: 1.0458\n",
      "Epoch 991/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2323 - val_loss: 1.0271\n",
      "Epoch 992/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2474 - val_loss: 1.0172\n",
      "Epoch 993/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2362 - val_loss: 1.0163\n",
      "Epoch 994/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2293 - val_loss: 1.0224\n",
      "Epoch 995/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2309 - val_loss: 1.0242\n",
      "Epoch 996/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2322 - val_loss: 0.9872\n",
      "Epoch 997/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2435 - val_loss: 1.0042\n",
      "Epoch 998/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2268 - val_loss: 1.0263\n",
      "Epoch 999/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2341 - val_loss: 0.9958\n",
      "Epoch 1000/1000\n",
      "1000/1000 [==============================] - 0s - loss: 1.2533 - val_loss: 1.0211\n",
      "CPU times: user 58min 9s, sys: 7min 6s, total: 1h 5min 16s\n",
      "Wall time: 11min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(optimizer='Nadam',loss=custom_objective)\n",
    "history = model.fit(train_input, train_output, validation_data=(valid_input,valid_output), nb_epoch=1000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7d384e0438>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGDCAYAAAD53hDCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d3d5cac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'], label = 'Validation loss')\n",
    "plt.plot(history.history['loss'], label = 'Training loss')\n",
    "\n",
    "plt.ylabel(\"Squared error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "plt.ylim([0,7])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks nearly identical to Fig. 1 of [the paper](https://arxiv.org/abs/1703.10743). Next, the \"local decomposition.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data_path = 'data/ss_data_training.csv'\n",
    "valid_data_path = 'data/ss_data_valid.csv'\n",
    "\n",
    "train_input, train_output = load_data_ss(training_data_path)\n",
    "valid_input, valid_output = load_data_ss(valid_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(output_dim=2000,input_dim=64))\n",
    "\n",
    "model.add(Dense(4000,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(4000,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(input_dim=4000,output_dim=36))\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/500\n",
      "500/500 [==============================] - 2s - loss: 1928.0432 - val_loss: 58.7284\n",
      "Epoch 2/500\n",
      "500/500 [==============================] - 1s - loss: 83.0015 - val_loss: 56.8443\n",
      "Epoch 3/500\n",
      "500/500 [==============================] - 1s - loss: 57.4910 - val_loss: 48.1649\n",
      "Epoch 4/500\n",
      "500/500 [==============================] - 1s - loss: 51.7076 - val_loss: 47.2014\n",
      "Epoch 5/500\n",
      "500/500 [==============================] - 1s - loss: 49.7511 - val_loss: 47.0593\n",
      "Epoch 6/500\n",
      "500/500 [==============================] - 1s - loss: 49.4571 - val_loss: 46.9361\n",
      "Epoch 7/500\n",
      "500/500 [==============================] - 1s - loss: 48.8565 - val_loss: 46.5122\n",
      "Epoch 8/500\n",
      "500/500 [==============================] - 1s - loss: 48.1984 - val_loss: 46.0242\n",
      "Epoch 9/500\n",
      "500/500 [==============================] - 1s - loss: 47.9599 - val_loss: 45.4773\n",
      "Epoch 10/500\n",
      "500/500 [==============================] - 1s - loss: 47.1162 - val_loss: 45.5617\n",
      "Epoch 11/500\n",
      "500/500 [==============================] - 1s - loss: 47.5879 - val_loss: 44.9578\n",
      "Epoch 12/500\n",
      "500/500 [==============================] - 1s - loss: 46.9787 - val_loss: 45.3351\n",
      "Epoch 13/500\n",
      "500/500 [==============================] - 1s - loss: 46.7124 - val_loss: 44.6159\n",
      "Epoch 14/500\n",
      "500/500 [==============================] - 1s - loss: 45.8505 - val_loss: 43.7878\n",
      "Epoch 15/500\n",
      "500/500 [==============================] - 1s - loss: 45.1820 - val_loss: 43.5011\n",
      "Epoch 16/500\n",
      "500/500 [==============================] - 1s - loss: 44.6850 - val_loss: 43.1022\n",
      "Epoch 17/500\n",
      "500/500 [==============================] - 1s - loss: 44.2769 - val_loss: 43.3106\n",
      "Epoch 18/500\n",
      "500/500 [==============================] - 1s - loss: 45.6469 - val_loss: 46.3445\n",
      "Epoch 19/500\n",
      "500/500 [==============================] - 1s - loss: 45.9416 - val_loss: 43.2778\n",
      "Epoch 20/500\n",
      "500/500 [==============================] - 1s - loss: 43.7875 - val_loss: 41.2507\n",
      "Epoch 21/500\n",
      "500/500 [==============================] - 1s - loss: 42.4273 - val_loss: 40.4794\n",
      "Epoch 22/500\n",
      "500/500 [==============================] - 1s - loss: 41.5514 - val_loss: 39.6212\n",
      "Epoch 23/500\n",
      "500/500 [==============================] - 1s - loss: 41.3061 - val_loss: 39.5961\n",
      "Epoch 24/500\n",
      "500/500 [==============================] - 1s - loss: 41.2355 - val_loss: 39.4855\n",
      "Epoch 25/500\n",
      "500/500 [==============================] - 1s - loss: 39.9226 - val_loss: 38.0519\n",
      "Epoch 26/500\n",
      "500/500 [==============================] - 1s - loss: 38.5709 - val_loss: 36.1625\n",
      "Epoch 27/500\n",
      "500/500 [==============================] - 1s - loss: 38.5727 - val_loss: 37.6131\n",
      "Epoch 28/500\n",
      "500/500 [==============================] - 1s - loss: 37.8976 - val_loss: 34.6365\n",
      "Epoch 29/500\n",
      "500/500 [==============================] - 1s - loss: 37.1208 - val_loss: 35.1463\n",
      "Epoch 30/500\n",
      "500/500 [==============================] - 1s - loss: 36.6890 - val_loss: 33.6481\n",
      "Epoch 31/500\n",
      "500/500 [==============================] - 1s - loss: 35.6755 - val_loss: 33.2816\n",
      "Epoch 32/500\n",
      "500/500 [==============================] - 1s - loss: 34.9731 - val_loss: 32.5114\n",
      "Epoch 33/500\n",
      "500/500 [==============================] - 1s - loss: 34.5225 - val_loss: 32.0806\n",
      "Epoch 34/500\n",
      "500/500 [==============================] - 1s - loss: 34.0801 - val_loss: 31.1134\n",
      "Epoch 35/500\n",
      "500/500 [==============================] - 1s - loss: 33.5336 - val_loss: 30.7787\n",
      "Epoch 36/500\n",
      "500/500 [==============================] - 1s - loss: 33.0177 - val_loss: 30.5774\n",
      "Epoch 37/500\n",
      "500/500 [==============================] - 1s - loss: 33.0489 - val_loss: 30.3603\n",
      "Epoch 38/500\n",
      "500/500 [==============================] - 1s - loss: 32.5370 - val_loss: 29.1842\n",
      "Epoch 39/500\n",
      "500/500 [==============================] - 1s - loss: 31.9061 - val_loss: 29.2739\n",
      "Epoch 40/500\n",
      "500/500 [==============================] - 1s - loss: 32.3620 - val_loss: 29.7957\n",
      "Epoch 41/500\n",
      "500/500 [==============================] - 1s - loss: 31.4147 - val_loss: 28.6334\n",
      "Epoch 42/500\n",
      "500/500 [==============================] - 1s - loss: 31.0300 - val_loss: 29.8735\n",
      "Epoch 43/500\n",
      "500/500 [==============================] - 1s - loss: 31.8526 - val_loss: 28.9440\n",
      "Epoch 44/500\n",
      "500/500 [==============================] - 1s - loss: 31.0116 - val_loss: 29.2483\n",
      "Epoch 45/500\n",
      "500/500 [==============================] - 1s - loss: 30.5171 - val_loss: 27.3801\n",
      "Epoch 46/500\n",
      "500/500 [==============================] - 1s - loss: 30.2832 - val_loss: 28.1007\n",
      "Epoch 47/500\n",
      "500/500 [==============================] - 1s - loss: 30.3353 - val_loss: 27.4352\n",
      "Epoch 48/500\n",
      "500/500 [==============================] - 1s - loss: 29.8938 - val_loss: 27.6298\n",
      "Epoch 49/500\n",
      "500/500 [==============================] - 1s - loss: 29.8872 - val_loss: 27.3145\n",
      "Epoch 50/500\n",
      "500/500 [==============================] - 1s - loss: 29.7929 - val_loss: 28.0647\n",
      "Epoch 51/500\n",
      "500/500 [==============================] - 1s - loss: 29.6782 - val_loss: 26.7747\n",
      "Epoch 52/500\n",
      "500/500 [==============================] - 1s - loss: 29.4139 - val_loss: 26.7458\n",
      "Epoch 53/500\n",
      "500/500 [==============================] - 1s - loss: 28.5147 - val_loss: 26.0697\n",
      "Epoch 54/500\n",
      "500/500 [==============================] - 1s - loss: 28.7702 - val_loss: 26.3329\n",
      "Epoch 55/500\n",
      "500/500 [==============================] - 1s - loss: 28.7239 - val_loss: 25.6868\n",
      "Epoch 56/500\n",
      "500/500 [==============================] - 1s - loss: 28.5961 - val_loss: 26.4685\n",
      "Epoch 57/500\n",
      "500/500 [==============================] - 1s - loss: 29.7481 - val_loss: 26.0791\n",
      "Epoch 58/500\n",
      "500/500 [==============================] - 1s - loss: 28.8565 - val_loss: 27.3456\n",
      "Epoch 59/500\n",
      "500/500 [==============================] - 1s - loss: 28.8071 - val_loss: 25.8198\n",
      "Epoch 60/500\n",
      "500/500 [==============================] - 1s - loss: 28.3281 - val_loss: 25.7100\n",
      "Epoch 61/500\n",
      "500/500 [==============================] - 1s - loss: 27.8777 - val_loss: 26.0692\n",
      "Epoch 62/500\n",
      "500/500 [==============================] - 1s - loss: 27.8926 - val_loss: 25.4982\n",
      "Epoch 63/500\n",
      "500/500 [==============================] - 1s - loss: 27.6902 - val_loss: 25.2152\n",
      "Epoch 64/500\n",
      "500/500 [==============================] - 1s - loss: 27.1233 - val_loss: 24.7323\n",
      "Epoch 65/500\n",
      "500/500 [==============================] - 1s - loss: 26.8366 - val_loss: 24.5293\n",
      "Epoch 66/500\n",
      "500/500 [==============================] - 1s - loss: 27.0532 - val_loss: 24.8751\n",
      "Epoch 67/500\n",
      "500/500 [==============================] - 1s - loss: 27.3120 - val_loss: 24.3714\n",
      "Epoch 68/500\n",
      "500/500 [==============================] - 1s - loss: 26.7316 - val_loss: 24.9043\n",
      "Epoch 69/500\n",
      "500/500 [==============================] - 1s - loss: 26.9798 - val_loss: 23.8858\n",
      "Epoch 70/500\n",
      "500/500 [==============================] - 1s - loss: 26.3727 - val_loss: 23.8449\n",
      "Epoch 71/500\n",
      "500/500 [==============================] - 1s - loss: 26.0630 - val_loss: 23.6661\n",
      "Epoch 72/500\n",
      "500/500 [==============================] - 1s - loss: 26.0013 - val_loss: 23.5329\n",
      "Epoch 73/500\n",
      "500/500 [==============================] - 1s - loss: 26.1116 - val_loss: 23.7442\n",
      "Epoch 74/500\n",
      "500/500 [==============================] - 1s - loss: 25.8768 - val_loss: 23.4318\n",
      "Epoch 75/500\n",
      "500/500 [==============================] - 1s - loss: 26.1874 - val_loss: 23.4129\n",
      "Epoch 76/500\n",
      "500/500 [==============================] - 1s - loss: 27.0570 - val_loss: 23.4328\n",
      "Epoch 77/500\n",
      "500/500 [==============================] - 1s - loss: 25.6738 - val_loss: 22.9433\n",
      "Epoch 78/500\n",
      "500/500 [==============================] - 1s - loss: 25.2788 - val_loss: 22.4110\n",
      "Epoch 79/500\n",
      "500/500 [==============================] - 1s - loss: 24.9501 - val_loss: 21.9928\n",
      "Epoch 80/500\n",
      "500/500 [==============================] - 1s - loss: 24.7120 - val_loss: 22.5425\n",
      "Epoch 81/500\n",
      "500/500 [==============================] - 1s - loss: 24.7361 - val_loss: 22.6039\n",
      "Epoch 82/500\n",
      "500/500 [==============================] - 1s - loss: 24.9983 - val_loss: 22.7363\n",
      "Epoch 83/500\n",
      "500/500 [==============================] - 1s - loss: 25.2060 - val_loss: 22.4622\n",
      "Epoch 84/500\n",
      "500/500 [==============================] - 1s - loss: 24.8344 - val_loss: 21.8732\n",
      "Epoch 85/500\n",
      "500/500 [==============================] - 1s - loss: 23.9391 - val_loss: 21.3500\n",
      "Epoch 86/500\n",
      "500/500 [==============================] - 1s - loss: 23.5522 - val_loss: 21.1678\n",
      "Epoch 87/500\n",
      "500/500 [==============================] - 1s - loss: 23.5628 - val_loss: 21.5371\n",
      "Epoch 88/500\n",
      "500/500 [==============================] - 1s - loss: 23.7517 - val_loss: 21.7780\n",
      "Epoch 89/500\n",
      "500/500 [==============================] - 1s - loss: 23.5532 - val_loss: 22.1706\n",
      "Epoch 90/500\n",
      "500/500 [==============================] - 1s - loss: 23.8794 - val_loss: 20.1531\n",
      "Epoch 91/500\n",
      "500/500 [==============================] - 1s - loss: 22.6723 - val_loss: 20.2714\n",
      "Epoch 92/500\n",
      "500/500 [==============================] - 1s - loss: 22.3922 - val_loss: 19.2760\n",
      "Epoch 93/500\n",
      "500/500 [==============================] - 1s - loss: 21.8145 - val_loss: 18.5101\n",
      "Epoch 94/500\n",
      "500/500 [==============================] - 1s - loss: 22.4426 - val_loss: 19.3888\n",
      "Epoch 95/500\n",
      "500/500 [==============================] - 1s - loss: 22.0816 - val_loss: 18.8926\n",
      "Epoch 96/500\n",
      "500/500 [==============================] - 1s - loss: 21.7314 - val_loss: 18.1874\n",
      "Epoch 97/500\n",
      "500/500 [==============================] - 1s - loss: 21.8398 - val_loss: 18.5346\n",
      "Epoch 98/500\n",
      "500/500 [==============================] - 1s - loss: 21.7493 - val_loss: 20.6972\n",
      "Epoch 99/500\n",
      "500/500 [==============================] - 1s - loss: 21.9077 - val_loss: 19.2547\n",
      "Epoch 100/500\n",
      "500/500 [==============================] - 1s - loss: 21.1385 - val_loss: 17.6240\n",
      "Epoch 101/500\n",
      "500/500 [==============================] - 1s - loss: 20.9727 - val_loss: 17.6485\n",
      "Epoch 102/500\n",
      "500/500 [==============================] - 1s - loss: 20.7763 - val_loss: 17.6589\n",
      "Epoch 103/500\n",
      "500/500 [==============================] - 1s - loss: 20.2651 - val_loss: 16.5054\n",
      "Epoch 104/500\n",
      "500/500 [==============================] - 1s - loss: 19.4422 - val_loss: 16.0809\n",
      "Epoch 105/500\n",
      "500/500 [==============================] - 1s - loss: 19.2042 - val_loss: 16.9620\n",
      "Epoch 106/500\n",
      "500/500 [==============================] - 1s - loss: 19.6524 - val_loss: 16.7391\n",
      "Epoch 107/500\n",
      "500/500 [==============================] - 1s - loss: 19.5323 - val_loss: 16.2183\n",
      "Epoch 108/500\n",
      "500/500 [==============================] - 1s - loss: 19.1176 - val_loss: 16.6020\n",
      "Epoch 109/500\n",
      "500/500 [==============================] - 1s - loss: 18.7388 - val_loss: 15.8039\n",
      "Epoch 110/500\n",
      "500/500 [==============================] - 1s - loss: 19.0691 - val_loss: 15.7187\n",
      "Epoch 111/500\n",
      "500/500 [==============================] - 1s - loss: 18.3063 - val_loss: 14.5503\n",
      "Epoch 112/500\n",
      "500/500 [==============================] - 1s - loss: 18.3555 - val_loss: 15.1999\n",
      "Epoch 113/500\n",
      "500/500 [==============================] - 1s - loss: 18.1069 - val_loss: 14.9871\n",
      "Epoch 114/500\n",
      "500/500 [==============================] - 1s - loss: 17.8411 - val_loss: 14.8636\n",
      "Epoch 115/500\n",
      "500/500 [==============================] - 1s - loss: 18.3923 - val_loss: 14.1869\n",
      "Epoch 116/500\n",
      "500/500 [==============================] - 1s - loss: 17.8015 - val_loss: 15.2624\n",
      "Epoch 117/500\n",
      "500/500 [==============================] - 1s - loss: 18.0717 - val_loss: 13.9149\n",
      "Epoch 118/500\n",
      "500/500 [==============================] - 1s - loss: 17.1005 - val_loss: 14.2740\n",
      "Epoch 119/500\n",
      "500/500 [==============================] - 1s - loss: 17.2014 - val_loss: 14.4739\n",
      "Epoch 120/500\n",
      "500/500 [==============================] - 1s - loss: 17.4387 - val_loss: 14.2247\n",
      "Epoch 121/500\n",
      "500/500 [==============================] - 1s - loss: 17.1951 - val_loss: 13.7455\n",
      "Epoch 122/500\n",
      "500/500 [==============================] - 1s - loss: 16.8486 - val_loss: 13.1874\n",
      "Epoch 123/500\n",
      "500/500 [==============================] - 1s - loss: 16.7053 - val_loss: 13.2789\n",
      "Epoch 124/500\n",
      "500/500 [==============================] - 1s - loss: 16.3125 - val_loss: 13.0253\n",
      "Epoch 125/500\n",
      "500/500 [==============================] - 1s - loss: 16.3424 - val_loss: 12.7554\n",
      "Epoch 126/500\n",
      "500/500 [==============================] - 1s - loss: 16.3314 - val_loss: 14.0382\n",
      "Epoch 127/500\n",
      "500/500 [==============================] - 1s - loss: 16.7385 - val_loss: 13.5239\n",
      "Epoch 128/500\n",
      "500/500 [==============================] - 1s - loss: 16.2890 - val_loss: 12.5187\n",
      "Epoch 129/500\n",
      "500/500 [==============================] - 1s - loss: 15.4437 - val_loss: 11.7787\n",
      "Epoch 130/500\n",
      "500/500 [==============================] - 1s - loss: 15.5926 - val_loss: 11.9115\n",
      "Epoch 131/500\n",
      "500/500 [==============================] - 1s - loss: 15.0373 - val_loss: 11.4172\n",
      "Epoch 132/500\n",
      "500/500 [==============================] - 1s - loss: 15.1642 - val_loss: 11.9214\n",
      "Epoch 133/500\n",
      "500/500 [==============================] - 1s - loss: 15.4446 - val_loss: 11.6906\n",
      "Epoch 134/500\n",
      "500/500 [==============================] - 1s - loss: 16.5509 - val_loss: 15.0385\n",
      "Epoch 135/500\n",
      "500/500 [==============================] - 1s - loss: 16.2195 - val_loss: 12.3908\n",
      "Epoch 136/500\n",
      "500/500 [==============================] - 1s - loss: 15.7185 - val_loss: 13.9386\n",
      "Epoch 137/500\n",
      "500/500 [==============================] - 1s - loss: 15.6152 - val_loss: 11.8112\n",
      "Epoch 138/500\n",
      "500/500 [==============================] - 1s - loss: 15.1574 - val_loss: 11.8416\n",
      "Epoch 139/500\n",
      "500/500 [==============================] - 1s - loss: 15.0489 - val_loss: 11.2803\n",
      "Epoch 140/500\n",
      "500/500 [==============================] - 1s - loss: 14.4673 - val_loss: 11.4361\n",
      "Epoch 141/500\n",
      "500/500 [==============================] - 1s - loss: 16.7280 - val_loss: 13.6167\n",
      "Epoch 142/500\n",
      "500/500 [==============================] - 1s - loss: 15.7860 - val_loss: 11.2677\n",
      "Epoch 143/500\n",
      "500/500 [==============================] - 1s - loss: 14.1296 - val_loss: 10.6362\n",
      "Epoch 144/500\n",
      "500/500 [==============================] - 1s - loss: 14.4168 - val_loss: 11.7518\n",
      "Epoch 145/500\n",
      "500/500 [==============================] - 1s - loss: 15.6741 - val_loss: 11.5584\n",
      "Epoch 146/500\n",
      "500/500 [==============================] - 1s - loss: 14.8495 - val_loss: 11.8084\n",
      "Epoch 147/500\n",
      "500/500 [==============================] - 1s - loss: 13.8308 - val_loss: 10.3624\n",
      "Epoch 148/500\n",
      "500/500 [==============================] - 1s - loss: 13.2304 - val_loss: 9.8691\n",
      "Epoch 149/500\n",
      "500/500 [==============================] - 1s - loss: 13.3060 - val_loss: 9.5735\n",
      "Epoch 150/500\n",
      "500/500 [==============================] - 1s - loss: 13.4854 - val_loss: 9.7293\n",
      "Epoch 151/500\n",
      "500/500 [==============================] - 1s - loss: 12.7915 - val_loss: 9.6296\n",
      "Epoch 152/500\n",
      "500/500 [==============================] - 1s - loss: 12.4320 - val_loss: 8.8409\n",
      "Epoch 153/500\n",
      "500/500 [==============================] - 1s - loss: 12.1876 - val_loss: 9.7054\n",
      "Epoch 154/500\n",
      "500/500 [==============================] - 1s - loss: 12.3956 - val_loss: 8.5183\n",
      "Epoch 155/500\n",
      "500/500 [==============================] - 1s - loss: 11.9358 - val_loss: 9.3293\n",
      "Epoch 156/500\n",
      "500/500 [==============================] - 1s - loss: 12.2306 - val_loss: 8.0850\n",
      "Epoch 157/500\n",
      "500/500 [==============================] - 1s - loss: 11.4125 - val_loss: 7.5101\n",
      "Epoch 158/500\n",
      "500/500 [==============================] - 1s - loss: 11.0173 - val_loss: 7.7434\n",
      "Epoch 159/500\n",
      "500/500 [==============================] - 1s - loss: 11.2014 - val_loss: 7.0060\n",
      "Epoch 160/500\n",
      "500/500 [==============================] - 1s - loss: 11.0875 - val_loss: 7.6966\n",
      "Epoch 161/500\n",
      "500/500 [==============================] - 1s - loss: 11.6276 - val_loss: 7.1349\n",
      "Epoch 162/500\n",
      "500/500 [==============================] - 1s - loss: 10.5399 - val_loss: 6.3728\n",
      "Epoch 163/500\n",
      "500/500 [==============================] - 1s - loss: 10.8268 - val_loss: 7.9008\n",
      "Epoch 164/500\n",
      "500/500 [==============================] - 1s - loss: 10.9474 - val_loss: 7.5107\n",
      "Epoch 165/500\n",
      "500/500 [==============================] - 1s - loss: 11.7909 - val_loss: 8.8236\n",
      "Epoch 166/500\n",
      "500/500 [==============================] - 1s - loss: 11.4318 - val_loss: 6.8427\n",
      "Epoch 167/500\n",
      "500/500 [==============================] - 1s - loss: 10.7585 - val_loss: 7.4368\n",
      "Epoch 168/500\n",
      "500/500 [==============================] - 1s - loss: 10.4682 - val_loss: 6.3239\n",
      "Epoch 169/500\n",
      "500/500 [==============================] - 1s - loss: 10.2039 - val_loss: 6.7206\n",
      "Epoch 170/500\n",
      "500/500 [==============================] - 1s - loss: 10.5190 - val_loss: 6.8035\n",
      "Epoch 171/500\n",
      "500/500 [==============================] - 1s - loss: 9.3056 - val_loss: 6.4316\n",
      "Epoch 172/500\n",
      "500/500 [==============================] - 1s - loss: 9.0501 - val_loss: 5.1253\n",
      "Epoch 173/500\n",
      "500/500 [==============================] - 1s - loss: 8.3399 - val_loss: 5.7806\n",
      "Epoch 174/500\n",
      "500/500 [==============================] - 1s - loss: 8.6715 - val_loss: 4.9853\n",
      "Epoch 175/500\n",
      "500/500 [==============================] - 1s - loss: 8.8605 - val_loss: 5.6089\n",
      "Epoch 176/500\n",
      "500/500 [==============================] - 1s - loss: 8.2402 - val_loss: 4.5588\n",
      "Epoch 177/500\n",
      "500/500 [==============================] - 1s - loss: 8.1634 - val_loss: 5.0486\n",
      "Epoch 178/500\n",
      "500/500 [==============================] - 1s - loss: 8.2378 - val_loss: 4.8302\n",
      "Epoch 179/500\n",
      "500/500 [==============================] - 1s - loss: 8.2387 - val_loss: 5.2692\n",
      "Epoch 180/500\n",
      "500/500 [==============================] - 1s - loss: 8.3342 - val_loss: 5.1009\n",
      "Epoch 181/500\n",
      "500/500 [==============================] - 1s - loss: 8.1874 - val_loss: 4.4188\n",
      "Epoch 182/500\n",
      "500/500 [==============================] - 1s - loss: 8.5127 - val_loss: 5.8360\n",
      "Epoch 183/500\n",
      "500/500 [==============================] - 1s - loss: 9.3278 - val_loss: 7.7671\n",
      "Epoch 184/500\n",
      "500/500 [==============================] - 1s - loss: 9.9096 - val_loss: 5.9508\n",
      "Epoch 185/500\n",
      "500/500 [==============================] - 1s - loss: 8.7522 - val_loss: 5.0897\n",
      "Epoch 186/500\n",
      "500/500 [==============================] - 1s - loss: 8.1514 - val_loss: 5.5797\n",
      "Epoch 187/500\n",
      "500/500 [==============================] - 1s - loss: 8.0158 - val_loss: 4.6018\n",
      "Epoch 188/500\n",
      "500/500 [==============================] - 1s - loss: 7.2932 - val_loss: 3.6828\n",
      "Epoch 189/500\n",
      "500/500 [==============================] - 1s - loss: 6.7976 - val_loss: 3.5923\n",
      "Epoch 190/500\n",
      "500/500 [==============================] - 1s - loss: 6.6601 - val_loss: 3.4250\n",
      "Epoch 191/500\n",
      "500/500 [==============================] - 1s - loss: 6.5509 - val_loss: 3.8488\n",
      "Epoch 192/500\n",
      "500/500 [==============================] - 1s - loss: 6.6878 - val_loss: 3.3129\n",
      "Epoch 193/500\n",
      "500/500 [==============================] - 1s - loss: 6.1467 - val_loss: 3.7122\n",
      "Epoch 194/500\n",
      "500/500 [==============================] - 1s - loss: 6.6668 - val_loss: 3.8315\n",
      "Epoch 195/500\n",
      "500/500 [==============================] - 1s - loss: 7.0483 - val_loss: 5.8750\n",
      "Epoch 196/500\n",
      "500/500 [==============================] - 1s - loss: 7.1647 - val_loss: 4.6958\n",
      "Epoch 197/500\n",
      "500/500 [==============================] - 1s - loss: 6.7713 - val_loss: 3.3452\n",
      "Epoch 198/500\n",
      "500/500 [==============================] - 1s - loss: 6.5446 - val_loss: 3.3485\n",
      "Epoch 199/500\n",
      "500/500 [==============================] - 1s - loss: 6.3982 - val_loss: 3.9603\n",
      "Epoch 200/500\n",
      "500/500 [==============================] - 1s - loss: 6.5716 - val_loss: 3.6029\n",
      "Epoch 201/500\n",
      "500/500 [==============================] - 1s - loss: 6.6997 - val_loss: 3.1458\n",
      "Epoch 202/500\n",
      "500/500 [==============================] - 1s - loss: 6.2691 - val_loss: 3.2734\n",
      "Epoch 203/500\n",
      "500/500 [==============================] - 1s - loss: 6.4622 - val_loss: 3.3147\n",
      "Epoch 204/500\n",
      "500/500 [==============================] - 1s - loss: 5.9702 - val_loss: 2.4278\n",
      "Epoch 205/500\n",
      "500/500 [==============================] - 1s - loss: 5.6693 - val_loss: 2.9080\n",
      "Epoch 206/500\n",
      "500/500 [==============================] - 1s - loss: 6.0875 - val_loss: 2.8858\n",
      "Epoch 207/500\n",
      "500/500 [==============================] - 1s - loss: 5.5837 - val_loss: 3.1185\n",
      "Epoch 208/500\n",
      "500/500 [==============================] - 1s - loss: 5.6562 - val_loss: 2.7291\n",
      "Epoch 209/500\n",
      "500/500 [==============================] - 1s - loss: 5.4512 - val_loss: 2.5840\n",
      "Epoch 210/500\n",
      "500/500 [==============================] - 1s - loss: 5.4928 - val_loss: 3.1645\n",
      "Epoch 211/500\n",
      "500/500 [==============================] - 1s - loss: 5.6749 - val_loss: 3.1559\n",
      "Epoch 212/500\n",
      "500/500 [==============================] - 1s - loss: 6.1027 - val_loss: 2.9530\n",
      "Epoch 213/500\n",
      "500/500 [==============================] - 1s - loss: 5.7644 - val_loss: 2.8974\n",
      "Epoch 214/500\n",
      "500/500 [==============================] - 1s - loss: 5.4408 - val_loss: 3.0485\n",
      "Epoch 215/500\n",
      "500/500 [==============================] - 1s - loss: 5.4080 - val_loss: 2.2956\n",
      "Epoch 216/500\n",
      "500/500 [==============================] - 1s - loss: 4.9712 - val_loss: 2.1414\n",
      "Epoch 217/500\n",
      "500/500 [==============================] - 1s - loss: 4.7840 - val_loss: 1.8948\n",
      "Epoch 218/500\n",
      "500/500 [==============================] - 1s - loss: 5.1520 - val_loss: 2.5227\n",
      "Epoch 219/500\n",
      "500/500 [==============================] - 1s - loss: 5.3126 - val_loss: 1.8040\n",
      "Epoch 220/500\n",
      "500/500 [==============================] - 1s - loss: 4.8045 - val_loss: 2.0338\n",
      "Epoch 221/500\n",
      "500/500 [==============================] - 1s - loss: 4.6550 - val_loss: 1.9782\n",
      "Epoch 222/500\n",
      "500/500 [==============================] - 1s - loss: 4.6351 - val_loss: 1.8332\n",
      "Epoch 223/500\n",
      "500/500 [==============================] - 1s - loss: 4.6952 - val_loss: 2.2893\n",
      "Epoch 224/500\n",
      "500/500 [==============================] - 1s - loss: 4.6099 - val_loss: 2.3695\n",
      "Epoch 225/500\n",
      "500/500 [==============================] - 1s - loss: 4.5715 - val_loss: 1.8765\n",
      "Epoch 226/500\n",
      "500/500 [==============================] - 1s - loss: 4.3441 - val_loss: 1.7817\n",
      "Epoch 227/500\n",
      "500/500 [==============================] - 1s - loss: 4.2001 - val_loss: 1.7008\n",
      "Epoch 228/500\n",
      "500/500 [==============================] - 1s - loss: 4.5778 - val_loss: 1.9930\n",
      "Epoch 229/500\n",
      "500/500 [==============================] - 1s - loss: 4.5752 - val_loss: 1.9139\n",
      "Epoch 230/500\n",
      "500/500 [==============================] - 1s - loss: 4.5134 - val_loss: 1.6818\n",
      "Epoch 231/500\n",
      "500/500 [==============================] - 1s - loss: 4.4104 - val_loss: 1.4291\n",
      "Epoch 232/500\n",
      "500/500 [==============================] - 1s - loss: 4.3837 - val_loss: 2.0426\n",
      "Epoch 233/500\n",
      "500/500 [==============================] - 1s - loss: 4.5516 - val_loss: 1.8445\n",
      "Epoch 234/500\n",
      "500/500 [==============================] - 1s - loss: 4.4904 - val_loss: 1.8949\n",
      "Epoch 235/500\n",
      "500/500 [==============================] - 1s - loss: 4.4605 - val_loss: 1.5963\n",
      "Epoch 236/500\n",
      "500/500 [==============================] - 1s - loss: 4.3438 - val_loss: 1.8792\n",
      "Epoch 237/500\n",
      "500/500 [==============================] - 1s - loss: 4.3992 - val_loss: 1.6114\n",
      "Epoch 238/500\n",
      "500/500 [==============================] - 1s - loss: 4.1809 - val_loss: 2.0185\n",
      "Epoch 239/500\n",
      "500/500 [==============================] - 1s - loss: 4.2456 - val_loss: 1.5622\n",
      "Epoch 240/500\n",
      "500/500 [==============================] - 1s - loss: 4.3564 - val_loss: 1.6728\n",
      "Epoch 241/500\n",
      "500/500 [==============================] - 1s - loss: 4.1857 - val_loss: 2.0035\n",
      "Epoch 242/500\n",
      "500/500 [==============================] - 1s - loss: 4.4218 - val_loss: 2.1638\n",
      "Epoch 243/500\n",
      "500/500 [==============================] - 1s - loss: 4.3590 - val_loss: 1.9175\n",
      "Epoch 244/500\n",
      "500/500 [==============================] - 1s - loss: 4.4782 - val_loss: 2.3463\n",
      "Epoch 245/500\n",
      "500/500 [==============================] - 1s - loss: 4.5182 - val_loss: 1.9176\n",
      "Epoch 246/500\n",
      "500/500 [==============================] - 1s - loss: 4.2608 - val_loss: 1.5383\n",
      "Epoch 247/500\n",
      "500/500 [==============================] - 1s - loss: 4.4674 - val_loss: 2.0951\n",
      "Epoch 248/500\n",
      "500/500 [==============================] - 1s - loss: 3.9751 - val_loss: 1.3204\n",
      "Epoch 249/500\n",
      "500/500 [==============================] - 1s - loss: 4.0403 - val_loss: 1.7277\n",
      "Epoch 250/500\n",
      "500/500 [==============================] - 1s - loss: 4.0162 - val_loss: 1.5315\n",
      "Epoch 251/500\n",
      "500/500 [==============================] - 1s - loss: 3.8845 - val_loss: 1.3248\n",
      "Epoch 252/500\n",
      "500/500 [==============================] - 1s - loss: 3.7396 - val_loss: 1.1626\n",
      "Epoch 253/500\n",
      "500/500 [==============================] - 1s - loss: 3.7342 - val_loss: 1.4158\n",
      "Epoch 254/500\n",
      "500/500 [==============================] - 1s - loss: 3.8723 - val_loss: 1.4234\n",
      "Epoch 255/500\n",
      "500/500 [==============================] - 1s - loss: 3.6967 - val_loss: 0.9893\n",
      "Epoch 256/500\n",
      "500/500 [==============================] - 1s - loss: 3.6360 - val_loss: 1.7676\n",
      "Epoch 257/500\n",
      "500/500 [==============================] - 1s - loss: 4.0274 - val_loss: 1.4162\n",
      "Epoch 258/500\n",
      "500/500 [==============================] - 1s - loss: 3.8734 - val_loss: 1.3667\n",
      "Epoch 259/500\n",
      "500/500 [==============================] - 1s - loss: 3.7334 - val_loss: 1.3034\n",
      "Epoch 260/500\n",
      "500/500 [==============================] - 1s - loss: 3.6527 - val_loss: 1.2300\n",
      "Epoch 261/500\n",
      "500/500 [==============================] - 1s - loss: 3.8820 - val_loss: 1.7735\n",
      "Epoch 262/500\n",
      "500/500 [==============================] - 1s - loss: 3.9917 - val_loss: 1.3752\n",
      "Epoch 263/500\n",
      "500/500 [==============================] - 1s - loss: 3.6973 - val_loss: 1.4040\n",
      "Epoch 264/500\n",
      "500/500 [==============================] - 1s - loss: 3.7384 - val_loss: 1.3597\n",
      "Epoch 265/500\n",
      "500/500 [==============================] - 1s - loss: 3.8233 - val_loss: 1.5710\n",
      "Epoch 266/500\n",
      "500/500 [==============================] - 1s - loss: 3.9037 - val_loss: 1.5031\n",
      "Epoch 267/500\n",
      "500/500 [==============================] - 1s - loss: 3.7198 - val_loss: 1.0980\n",
      "Epoch 268/500\n",
      "500/500 [==============================] - 1s - loss: 3.6646 - val_loss: 1.6870\n",
      "Epoch 269/500\n",
      "500/500 [==============================] - 1s - loss: 3.7391 - val_loss: 1.4695\n",
      "Epoch 270/500\n",
      "500/500 [==============================] - 1s - loss: 3.8487 - val_loss: 1.5701\n",
      "Epoch 271/500\n",
      "500/500 [==============================] - 1s - loss: 3.6862 - val_loss: 1.0557\n",
      "Epoch 272/500\n",
      "500/500 [==============================] - 1s - loss: 3.5585 - val_loss: 1.5156\n",
      "Epoch 273/500\n",
      "500/500 [==============================] - 1s - loss: 3.8232 - val_loss: 1.3221\n",
      "Epoch 274/500\n",
      "500/500 [==============================] - 1s - loss: 3.8222 - val_loss: 1.3993\n",
      "Epoch 275/500\n",
      "500/500 [==============================] - 1s - loss: 3.6637 - val_loss: 1.2120\n",
      "Epoch 276/500\n",
      "500/500 [==============================] - 1s - loss: 3.5550 - val_loss: 1.5198\n",
      "Epoch 277/500\n",
      "500/500 [==============================] - 1s - loss: 3.5031 - val_loss: 1.3929\n",
      "Epoch 278/500\n",
      "500/500 [==============================] - 1s - loss: 3.9795 - val_loss: 1.4485\n",
      "Epoch 279/500\n",
      "500/500 [==============================] - 1s - loss: 3.8654 - val_loss: 1.4748\n",
      "Epoch 280/500\n",
      "500/500 [==============================] - 1s - loss: 3.4574 - val_loss: 1.2789\n",
      "Epoch 281/500\n",
      "500/500 [==============================] - 1s - loss: 3.5138 - val_loss: 1.2360\n",
      "Epoch 282/500\n",
      "500/500 [==============================] - 1s - loss: 3.7030 - val_loss: 1.3026\n",
      "Epoch 283/500\n",
      "500/500 [==============================] - 1s - loss: 3.8741 - val_loss: 1.4417\n",
      "Epoch 284/500\n",
      "500/500 [==============================] - 1s - loss: 3.7972 - val_loss: 1.1690\n",
      "Epoch 285/500\n",
      "500/500 [==============================] - 1s - loss: 3.3484 - val_loss: 1.2018\n",
      "Epoch 286/500\n",
      "500/500 [==============================] - 1s - loss: 3.3349 - val_loss: 0.9829\n",
      "Epoch 287/500\n",
      "500/500 [==============================] - 1s - loss: 3.4195 - val_loss: 1.1481\n",
      "Epoch 288/500\n",
      "500/500 [==============================] - 1s - loss: 3.4528 - val_loss: 1.3549\n",
      "Epoch 289/500\n",
      "500/500 [==============================] - 1s - loss: 3.5590 - val_loss: 1.9513\n",
      "Epoch 290/500\n",
      "500/500 [==============================] - 1s - loss: 4.0321 - val_loss: 1.5812\n",
      "Epoch 291/500\n",
      "500/500 [==============================] - 1s - loss: 3.6949 - val_loss: 1.6886\n",
      "Epoch 292/500\n",
      "500/500 [==============================] - 1s - loss: 3.7315 - val_loss: 1.2912\n",
      "Epoch 293/500\n",
      "500/500 [==============================] - 1s - loss: 3.5747 - val_loss: 1.3013\n",
      "Epoch 294/500\n",
      "500/500 [==============================] - 1s - loss: 3.3887 - val_loss: 1.0416\n",
      "Epoch 295/500\n",
      "500/500 [==============================] - 1s - loss: 3.3819 - val_loss: 1.0654\n",
      "Epoch 296/500\n",
      "500/500 [==============================] - 1s - loss: 3.4369 - val_loss: 1.2010\n",
      "Epoch 297/500\n",
      "500/500 [==============================] - 1s - loss: 3.4015 - val_loss: 1.1858\n",
      "Epoch 298/500\n",
      "500/500 [==============================] - 1s - loss: 3.3568 - val_loss: 1.0868\n",
      "Epoch 299/500\n",
      "500/500 [==============================] - 1s - loss: 3.3142 - val_loss: 1.4660\n",
      "Epoch 300/500\n",
      "500/500 [==============================] - 1s - loss: 3.7237 - val_loss: 1.2372\n",
      "Epoch 301/500\n",
      "500/500 [==============================] - 1s - loss: 3.4159 - val_loss: 1.6738\n",
      "Epoch 302/500\n",
      "500/500 [==============================] - 1s - loss: 3.5486 - val_loss: 1.2870\n",
      "Epoch 303/500\n",
      "500/500 [==============================] - 1s - loss: 3.4404 - val_loss: 1.6207\n",
      "Epoch 304/500\n",
      "500/500 [==============================] - 1s - loss: 3.2716 - val_loss: 1.2255\n",
      "Epoch 305/500\n",
      "500/500 [==============================] - 1s - loss: 3.1875 - val_loss: 1.3057\n",
      "Epoch 306/500\n",
      "500/500 [==============================] - 1s - loss: 3.4978 - val_loss: 1.2490\n",
      "Epoch 307/500\n",
      "500/500 [==============================] - 1s - loss: 3.5266 - val_loss: 1.3423\n",
      "Epoch 308/500\n",
      "500/500 [==============================] - 1s - loss: 3.4850 - val_loss: 1.3093\n",
      "Epoch 309/500\n",
      "500/500 [==============================] - 1s - loss: 3.4766 - val_loss: 1.4630\n",
      "Epoch 310/500\n",
      "500/500 [==============================] - 1s - loss: 3.3026 - val_loss: 1.0277\n",
      "Epoch 311/500\n",
      "500/500 [==============================] - 1s - loss: 3.1343 - val_loss: 0.9550\n",
      "Epoch 312/500\n",
      "500/500 [==============================] - 1s - loss: 3.2058 - val_loss: 0.9907\n",
      "Epoch 313/500\n",
      "500/500 [==============================] - 1s - loss: 3.3018 - val_loss: 1.4125\n",
      "Epoch 314/500\n",
      "500/500 [==============================] - 1s - loss: 3.3261 - val_loss: 0.9826\n",
      "Epoch 315/500\n",
      "500/500 [==============================] - 1s - loss: 3.1498 - val_loss: 1.0712\n",
      "Epoch 316/500\n",
      "500/500 [==============================] - 1s - loss: 3.2153 - val_loss: 1.0992\n",
      "Epoch 317/500\n",
      "500/500 [==============================] - 1s - loss: 3.2806 - val_loss: 1.3962\n",
      "Epoch 318/500\n",
      "500/500 [==============================] - 1s - loss: 3.3730 - val_loss: 1.4300\n",
      "Epoch 319/500\n",
      "500/500 [==============================] - 1s - loss: 3.4524 - val_loss: 1.1916\n",
      "Epoch 320/500\n",
      "500/500 [==============================] - 1s - loss: 3.3216 - val_loss: 1.0728\n",
      "Epoch 321/500\n",
      "500/500 [==============================] - 1s - loss: 3.1925 - val_loss: 0.9582\n",
      "Epoch 322/500\n",
      "500/500 [==============================] - 1s - loss: 3.1302 - val_loss: 1.0066\n",
      "Epoch 323/500\n",
      "500/500 [==============================] - 1s - loss: 3.0876 - val_loss: 1.3794\n",
      "Epoch 324/500\n",
      "500/500 [==============================] - 1s - loss: 3.0836 - val_loss: 1.1581\n",
      "Epoch 325/500\n",
      "500/500 [==============================] - 1s - loss: 3.2366 - val_loss: 1.3415\n",
      "Epoch 326/500\n",
      "500/500 [==============================] - 1s - loss: 3.1781 - val_loss: 1.0848\n",
      "Epoch 327/500\n",
      "500/500 [==============================] - 1s - loss: 3.1847 - val_loss: 1.3082\n",
      "Epoch 328/500\n",
      "500/500 [==============================] - 1s - loss: 3.1997 - val_loss: 1.3481\n",
      "Epoch 329/500\n",
      "500/500 [==============================] - 1s - loss: 3.1705 - val_loss: 1.2140\n",
      "Epoch 330/500\n",
      "500/500 [==============================] - 1s - loss: 3.2323 - val_loss: 0.9882\n",
      "Epoch 331/500\n",
      "500/500 [==============================] - 1s - loss: 3.2079 - val_loss: 1.4395\n",
      "Epoch 332/500\n",
      "500/500 [==============================] - 1s - loss: 3.3927 - val_loss: 1.2815\n",
      "Epoch 333/500\n",
      "500/500 [==============================] - 1s - loss: 3.2788 - val_loss: 1.3950\n",
      "Epoch 334/500\n",
      "500/500 [==============================] - 1s - loss: 3.2899 - val_loss: 1.3792\n",
      "Epoch 335/500\n",
      "500/500 [==============================] - 1s - loss: 3.2420 - val_loss: 1.1922\n",
      "Epoch 336/500\n",
      "500/500 [==============================] - 1s - loss: 3.2977 - val_loss: 1.1514\n",
      "Epoch 337/500\n",
      "500/500 [==============================] - 1s - loss: 3.0439 - val_loss: 0.9693\n",
      "Epoch 338/500\n",
      "500/500 [==============================] - 1s - loss: 3.0493 - val_loss: 1.3604\n",
      "Epoch 339/500\n",
      "500/500 [==============================] - 1s - loss: 3.3884 - val_loss: 1.5604\n",
      "Epoch 340/500\n",
      "500/500 [==============================] - 1s - loss: 3.6037 - val_loss: 1.6549\n",
      "Epoch 341/500\n",
      "500/500 [==============================] - 1s - loss: 3.5605 - val_loss: 1.3416\n",
      "Epoch 342/500\n",
      "500/500 [==============================] - 1s - loss: 3.4757 - val_loss: 2.0039\n",
      "Epoch 343/500\n",
      "500/500 [==============================] - 1s - loss: 3.5074 - val_loss: 1.1451\n",
      "Epoch 344/500\n",
      "500/500 [==============================] - 1s - loss: 3.2544 - val_loss: 1.1766\n",
      "Epoch 345/500\n",
      "500/500 [==============================] - 1s - loss: 3.0757 - val_loss: 1.5257\n",
      "Epoch 346/500\n",
      "500/500 [==============================] - 1s - loss: 3.2114 - val_loss: 1.3101\n",
      "Epoch 347/500\n",
      "500/500 [==============================] - 1s - loss: 3.2737 - val_loss: 1.5882\n",
      "Epoch 348/500\n",
      "500/500 [==============================] - 1s - loss: 3.3171 - val_loss: 1.1697\n",
      "Epoch 349/500\n",
      "500/500 [==============================] - 1s - loss: 3.0213 - val_loss: 1.2819\n",
      "Epoch 350/500\n",
      "500/500 [==============================] - 1s - loss: 3.0606 - val_loss: 0.9880\n",
      "Epoch 351/500\n",
      "500/500 [==============================] - 1s - loss: 3.0650 - val_loss: 1.3208\n",
      "Epoch 352/500\n",
      "500/500 [==============================] - 1s - loss: 3.1045 - val_loss: 1.3940\n",
      "Epoch 353/500\n",
      "500/500 [==============================] - 1s - loss: 3.2777 - val_loss: 1.4500\n",
      "Epoch 354/500\n",
      "500/500 [==============================] - 1s - loss: 3.2692 - val_loss: 1.1134\n",
      "Epoch 355/500\n",
      "500/500 [==============================] - 1s - loss: 3.1557 - val_loss: 1.3617\n",
      "Epoch 356/500\n",
      "500/500 [==============================] - 1s - loss: 3.1645 - val_loss: 1.5315\n",
      "Epoch 357/500\n",
      "500/500 [==============================] - 1s - loss: 3.2510 - val_loss: 1.1977\n",
      "Epoch 358/500\n",
      "500/500 [==============================] - 1s - loss: 3.2341 - val_loss: 1.3880\n",
      "Epoch 359/500\n",
      "500/500 [==============================] - 1s - loss: 3.2242 - val_loss: 1.0072\n",
      "Epoch 360/500\n",
      "500/500 [==============================] - 1s - loss: 3.0256 - val_loss: 1.0613\n",
      "Epoch 361/500\n",
      "500/500 [==============================] - 1s - loss: 3.0052 - val_loss: 1.1863\n",
      "Epoch 362/500\n",
      "500/500 [==============================] - 1s - loss: 2.9494 - val_loss: 1.5005\n",
      "Epoch 363/500\n",
      "500/500 [==============================] - 1s - loss: 3.1848 - val_loss: 0.9270\n",
      "Epoch 364/500\n",
      "500/500 [==============================] - 1s - loss: 3.0877 - val_loss: 1.1687\n",
      "Epoch 365/500\n",
      "500/500 [==============================] - 1s - loss: 3.0506 - val_loss: 0.9988\n",
      "Epoch 366/500\n",
      "500/500 [==============================] - 1s - loss: 2.9690 - val_loss: 1.1543\n",
      "Epoch 367/500\n",
      "500/500 [==============================] - 1s - loss: 3.0979 - val_loss: 1.2624\n",
      "Epoch 368/500\n",
      "500/500 [==============================] - 1s - loss: 3.0079 - val_loss: 1.1323\n",
      "Epoch 369/500\n",
      "500/500 [==============================] - 1s - loss: 3.0521 - val_loss: 1.2321\n",
      "Epoch 370/500\n",
      "500/500 [==============================] - 1s - loss: 3.0867 - val_loss: 1.1142\n",
      "Epoch 371/500\n",
      "500/500 [==============================] - 1s - loss: 2.9492 - val_loss: 0.9846\n",
      "Epoch 372/500\n",
      "500/500 [==============================] - 1s - loss: 2.9953 - val_loss: 0.9794\n",
      "Epoch 373/500\n",
      "500/500 [==============================] - 1s - loss: 3.1030 - val_loss: 1.2909\n",
      "Epoch 374/500\n",
      "500/500 [==============================] - 1s - loss: 3.1844 - val_loss: 1.0073\n",
      "Epoch 375/500\n",
      "500/500 [==============================] - 1s - loss: 3.0648 - val_loss: 1.2751\n",
      "Epoch 376/500\n",
      "500/500 [==============================] - 1s - loss: 3.0570 - val_loss: 1.0687\n",
      "Epoch 377/500\n",
      "500/500 [==============================] - 1s - loss: 2.9099 - val_loss: 0.9214\n",
      "Epoch 378/500\n",
      "500/500 [==============================] - 1s - loss: 2.8927 - val_loss: 0.9752\n",
      "Epoch 379/500\n",
      "500/500 [==============================] - 1s - loss: 2.7753 - val_loss: 0.8077\n",
      "Epoch 380/500\n",
      "500/500 [==============================] - 1s - loss: 2.7440 - val_loss: 0.8956\n",
      "Epoch 381/500\n",
      "500/500 [==============================] - 1s - loss: 2.7609 - val_loss: 1.0479\n",
      "Epoch 382/500\n",
      "500/500 [==============================] - 1s - loss: 2.7874 - val_loss: 0.8562\n",
      "Epoch 383/500\n",
      "500/500 [==============================] - 1s - loss: 2.7265 - val_loss: 0.6732\n",
      "Epoch 384/500\n",
      "500/500 [==============================] - 1s - loss: 2.7713 - val_loss: 1.0092\n",
      "Epoch 385/500\n",
      "500/500 [==============================] - 1s - loss: 2.8485 - val_loss: 1.0239\n",
      "Epoch 386/500\n",
      "500/500 [==============================] - 1s - loss: 2.8394 - val_loss: 1.0833\n",
      "Epoch 387/500\n",
      "500/500 [==============================] - 1s - loss: 2.8544 - val_loss: 1.2758\n",
      "Epoch 388/500\n",
      "500/500 [==============================] - 1s - loss: 2.9453 - val_loss: 0.9304\n",
      "Epoch 389/500\n",
      "500/500 [==============================] - 1s - loss: 2.8345 - val_loss: 0.9291\n",
      "Epoch 390/500\n",
      "500/500 [==============================] - 1s - loss: 2.8187 - val_loss: 1.1854\n",
      "Epoch 391/500\n",
      "500/500 [==============================] - 1s - loss: 2.7440 - val_loss: 0.8075\n",
      "Epoch 392/500\n",
      "500/500 [==============================] - 1s - loss: 2.6701 - val_loss: 0.8387\n",
      "Epoch 393/500\n",
      "500/500 [==============================] - 1s - loss: 2.8044 - val_loss: 0.8178\n",
      "Epoch 394/500\n",
      "500/500 [==============================] - 1s - loss: 2.8569 - val_loss: 1.1718\n",
      "Epoch 395/500\n",
      "500/500 [==============================] - 1s - loss: 2.9057 - val_loss: 1.0679\n",
      "Epoch 396/500\n",
      "500/500 [==============================] - 1s - loss: 2.9336 - val_loss: 1.3327\n",
      "Epoch 397/500\n",
      "500/500 [==============================] - 1s - loss: 2.9622 - val_loss: 1.0381\n",
      "Epoch 398/500\n",
      "500/500 [==============================] - 1s - loss: 2.8567 - val_loss: 1.0641\n",
      "Epoch 399/500\n",
      "500/500 [==============================] - 1s - loss: 3.0400 - val_loss: 1.2560\n",
      "Epoch 400/500\n",
      "500/500 [==============================] - 1s - loss: 2.8940 - val_loss: 1.0361\n",
      "Epoch 401/500\n",
      "500/500 [==============================] - 1s - loss: 2.7723 - val_loss: 1.0377\n",
      "Epoch 402/500\n",
      "500/500 [==============================] - 1s - loss: 2.7850 - val_loss: 1.0826\n",
      "Epoch 403/500\n",
      "500/500 [==============================] - 1s - loss: 2.8017 - val_loss: 0.8878\n",
      "Epoch 404/500\n",
      "500/500 [==============================] - 1s - loss: 2.7510 - val_loss: 0.8614\n",
      "Epoch 405/500\n",
      "500/500 [==============================] - 1s - loss: 2.8098 - val_loss: 0.9802\n",
      "Epoch 406/500\n",
      "500/500 [==============================] - 1s - loss: 2.9680 - val_loss: 1.1796\n",
      "Epoch 407/500\n",
      "500/500 [==============================] - 1s - loss: 2.7935 - val_loss: 0.9946\n",
      "Epoch 408/500\n",
      "500/500 [==============================] - 1s - loss: 2.9327 - val_loss: 1.4287\n",
      "Epoch 409/500\n",
      "500/500 [==============================] - 1s - loss: 2.9698 - val_loss: 1.0838\n",
      "Epoch 410/500\n",
      "500/500 [==============================] - 1s - loss: 2.8139 - val_loss: 0.7942\n",
      "Epoch 411/500\n",
      "500/500 [==============================] - 1s - loss: 2.6702 - val_loss: 0.9439\n",
      "Epoch 412/500\n",
      "500/500 [==============================] - 1s - loss: 2.6510 - val_loss: 0.7810\n",
      "Epoch 413/500\n",
      "500/500 [==============================] - 1s - loss: 2.6641 - val_loss: 0.8238\n",
      "Epoch 414/500\n",
      "500/500 [==============================] - 1s - loss: 2.7782 - val_loss: 1.1202\n",
      "Epoch 415/500\n",
      "500/500 [==============================] - 1s - loss: 2.9678 - val_loss: 1.1215\n",
      "Epoch 416/500\n",
      "500/500 [==============================] - 1s - loss: 2.7939 - val_loss: 0.9038\n",
      "Epoch 417/500\n",
      "500/500 [==============================] - 1s - loss: 2.8002 - val_loss: 1.2477\n",
      "Epoch 418/500\n",
      "500/500 [==============================] - 1s - loss: 2.9498 - val_loss: 1.2322\n",
      "Epoch 419/500\n",
      "500/500 [==============================] - 1s - loss: 2.8769 - val_loss: 1.0341\n",
      "Epoch 420/500\n",
      "500/500 [==============================] - 1s - loss: 2.8150 - val_loss: 1.0834\n",
      "Epoch 421/500\n",
      "500/500 [==============================] - 1s - loss: 2.7527 - val_loss: 1.0528\n",
      "Epoch 422/500\n",
      "500/500 [==============================] - 1s - loss: 2.8166 - val_loss: 1.1400\n",
      "Epoch 423/500\n",
      "500/500 [==============================] - 1s - loss: 2.9064 - val_loss: 1.0067\n",
      "Epoch 424/500\n",
      "500/500 [==============================] - 1s - loss: 2.6595 - val_loss: 1.0117\n",
      "Epoch 425/500\n",
      "500/500 [==============================] - 1s - loss: 2.8324 - val_loss: 1.1863\n",
      "Epoch 426/500\n",
      "500/500 [==============================] - 1s - loss: 2.8581 - val_loss: 1.1083\n",
      "Epoch 427/500\n",
      "500/500 [==============================] - 1s - loss: 2.8051 - val_loss: 0.8193\n",
      "Epoch 428/500\n",
      "500/500 [==============================] - 1s - loss: 2.5928 - val_loss: 1.0478\n",
      "Epoch 429/500\n",
      "500/500 [==============================] - 1s - loss: 2.7161 - val_loss: 0.8672\n",
      "Epoch 430/500\n",
      "500/500 [==============================] - 1s - loss: 2.7581 - val_loss: 1.2649\n",
      "Epoch 431/500\n",
      "500/500 [==============================] - 1s - loss: 2.8570 - val_loss: 1.2107\n",
      "Epoch 432/500\n",
      "500/500 [==============================] - 1s - loss: 2.9855 - val_loss: 1.2049\n",
      "Epoch 433/500\n",
      "500/500 [==============================] - 1s - loss: 2.8624 - val_loss: 1.0689\n",
      "Epoch 434/500\n",
      "500/500 [==============================] - 1s - loss: 2.7993 - val_loss: 1.5174\n",
      "Epoch 435/500\n",
      "500/500 [==============================] - 1s - loss: 2.9518 - val_loss: 1.0728\n",
      "Epoch 436/500\n",
      "500/500 [==============================] - 1s - loss: 3.0064 - val_loss: 1.2256\n",
      "Epoch 437/500\n",
      "500/500 [==============================] - 1s - loss: 2.9413 - val_loss: 0.8973\n",
      "Epoch 438/500\n",
      "500/500 [==============================] - 1s - loss: 2.8198 - val_loss: 1.1681\n",
      "Epoch 439/500\n",
      "500/500 [==============================] - 1s - loss: 2.6616 - val_loss: 0.8427\n",
      "Epoch 440/500\n",
      "500/500 [==============================] - 1s - loss: 2.6762 - val_loss: 1.1082\n",
      "Epoch 441/500\n",
      "500/500 [==============================] - 1s - loss: 2.7853 - val_loss: 0.9196\n",
      "Epoch 442/500\n",
      "500/500 [==============================] - 1s - loss: 2.7146 - val_loss: 1.1087\n",
      "Epoch 443/500\n",
      "500/500 [==============================] - 1s - loss: 2.7808 - val_loss: 1.0361\n",
      "Epoch 444/500\n",
      "500/500 [==============================] - 1s - loss: 2.7023 - val_loss: 0.9198\n",
      "Epoch 445/500\n",
      "500/500 [==============================] - 1s - loss: 2.7801 - val_loss: 1.1487\n",
      "Epoch 446/500\n",
      "500/500 [==============================] - 1s - loss: 2.9748 - val_loss: 0.9606\n",
      "Epoch 447/500\n",
      "500/500 [==============================] - 1s - loss: 2.8379 - val_loss: 1.0124\n",
      "Epoch 448/500\n",
      "500/500 [==============================] - 1s - loss: 2.7821 - val_loss: 0.9282\n",
      "Epoch 449/500\n",
      "500/500 [==============================] - 1s - loss: 2.6463 - val_loss: 1.1668\n",
      "Epoch 450/500\n",
      "500/500 [==============================] - 1s - loss: 2.7363 - val_loss: 0.8944\n",
      "Epoch 451/500\n",
      "500/500 [==============================] - 1s - loss: 2.7149 - val_loss: 1.1372\n",
      "Epoch 452/500\n",
      "500/500 [==============================] - 1s - loss: 2.7972 - val_loss: 1.0422\n",
      "Epoch 453/500\n",
      "500/500 [==============================] - 1s - loss: 2.9121 - val_loss: 0.9869\n",
      "Epoch 454/500\n",
      "500/500 [==============================] - 1s - loss: 2.8324 - val_loss: 0.9611\n",
      "Epoch 455/500\n",
      "500/500 [==============================] - 1s - loss: 2.6154 - val_loss: 0.9452\n",
      "Epoch 456/500\n",
      "500/500 [==============================] - 1s - loss: 2.7626 - val_loss: 0.9421\n",
      "Epoch 457/500\n",
      "500/500 [==============================] - 1s - loss: 2.6960 - val_loss: 1.2721\n",
      "Epoch 458/500\n",
      "500/500 [==============================] - 1s - loss: 2.9348 - val_loss: 1.1670\n",
      "Epoch 459/500\n",
      "500/500 [==============================] - 1s - loss: 2.7938 - val_loss: 0.9307\n",
      "Epoch 460/500\n",
      "500/500 [==============================] - 1s - loss: 2.7965 - val_loss: 0.9277\n",
      "Epoch 461/500\n",
      "500/500 [==============================] - 1s - loss: 2.5116 - val_loss: 1.1485\n",
      "Epoch 462/500\n",
      "500/500 [==============================] - 1s - loss: 2.7482 - val_loss: 1.1774\n",
      "Epoch 463/500\n",
      "500/500 [==============================] - 1s - loss: 2.8449 - val_loss: 0.8904\n",
      "Epoch 464/500\n",
      "500/500 [==============================] - 1s - loss: 2.8624 - val_loss: 1.2008\n",
      "Epoch 465/500\n",
      "500/500 [==============================] - 1s - loss: 2.8798 - val_loss: 1.0452\n",
      "Epoch 466/500\n",
      "500/500 [==============================] - 1s - loss: 2.6510 - val_loss: 0.9477\n",
      "Epoch 467/500\n",
      "500/500 [==============================] - 1s - loss: 2.7047 - val_loss: 1.3045\n",
      "Epoch 468/500\n",
      "500/500 [==============================] - 1s - loss: 2.9081 - val_loss: 1.2746\n",
      "Epoch 469/500\n",
      "500/500 [==============================] - 1s - loss: 2.8157 - val_loss: 1.2106\n",
      "Epoch 470/500\n",
      "500/500 [==============================] - 1s - loss: 2.7818 - val_loss: 1.6937\n",
      "Epoch 471/500\n",
      "500/500 [==============================] - 1s - loss: 2.8250 - val_loss: 1.1361\n",
      "Epoch 472/500\n",
      "500/500 [==============================] - 1s - loss: 2.6816 - val_loss: 1.1325\n",
      "Epoch 473/500\n",
      "500/500 [==============================] - 1s - loss: 2.8659 - val_loss: 1.1268\n",
      "Epoch 474/500\n",
      "500/500 [==============================] - 1s - loss: 2.7532 - val_loss: 1.0626\n",
      "Epoch 475/500\n",
      "500/500 [==============================] - 1s - loss: 2.7380 - val_loss: 1.6342\n",
      "Epoch 476/500\n",
      "500/500 [==============================] - 1s - loss: 2.9656 - val_loss: 1.1002\n",
      "Epoch 477/500\n",
      "500/500 [==============================] - 1s - loss: 2.6675 - val_loss: 0.9056\n",
      "Epoch 478/500\n",
      "500/500 [==============================] - 1s - loss: 2.6789 - val_loss: 0.9996\n",
      "Epoch 479/500\n",
      "500/500 [==============================] - 1s - loss: 2.6139 - val_loss: 0.8488\n",
      "Epoch 480/500\n",
      "500/500 [==============================] - 1s - loss: 2.6518 - val_loss: 1.1997\n",
      "Epoch 481/500\n",
      "500/500 [==============================] - 1s - loss: 2.5539 - val_loss: 1.0100\n",
      "Epoch 482/500\n",
      "500/500 [==============================] - 1s - loss: 2.5982 - val_loss: 0.8822\n",
      "Epoch 483/500\n",
      "500/500 [==============================] - 1s - loss: 2.7610 - val_loss: 0.9569\n",
      "Epoch 484/500\n",
      "500/500 [==============================] - 1s - loss: 2.6718 - val_loss: 0.8928\n",
      "Epoch 485/500\n",
      "500/500 [==============================] - 1s - loss: 2.5639 - val_loss: 1.0198\n",
      "Epoch 486/500\n",
      "500/500 [==============================] - 1s - loss: 2.7998 - val_loss: 1.2749\n",
      "Epoch 487/500\n",
      "500/500 [==============================] - 1s - loss: 2.7768 - val_loss: 1.2442\n",
      "Epoch 488/500\n",
      "500/500 [==============================] - 1s - loss: 2.9754 - val_loss: 1.1099\n",
      "Epoch 489/500\n",
      "500/500 [==============================] - 1s - loss: 2.7664 - val_loss: 1.2537\n",
      "Epoch 490/500\n",
      "500/500 [==============================] - 1s - loss: 2.7629 - val_loss: 1.0294\n",
      "Epoch 491/500\n",
      "500/500 [==============================] - 1s - loss: 2.6245 - val_loss: 1.1686\n",
      "Epoch 492/500\n",
      "500/500 [==============================] - 1s - loss: 2.5552 - val_loss: 0.9612\n",
      "Epoch 493/500\n",
      "500/500 [==============================] - 1s - loss: 2.5345 - val_loss: 1.1487\n",
      "Epoch 494/500\n",
      "500/500 [==============================] - 1s - loss: 2.5948 - val_loss: 1.2097\n",
      "Epoch 495/500\n",
      "500/500 [==============================] - 1s - loss: 2.5864 - val_loss: 0.9257\n",
      "Epoch 496/500\n",
      "500/500 [==============================] - 1s - loss: 2.7105 - val_loss: 0.7400\n",
      "Epoch 497/500\n",
      "500/500 [==============================] - 1s - loss: 2.5360 - val_loss: 0.9044\n",
      "Epoch 498/500\n",
      "500/500 [==============================] - 1s - loss: 2.6540 - val_loss: 1.1479\n",
      "Epoch 499/500\n",
      "500/500 [==============================] - 1s - loss: 2.6447 - val_loss: 0.8514\n",
      "Epoch 500/500\n",
      "500/500 [==============================] - 1s - loss: 2.5779 - val_loss: 1.1611\n",
      "CPU times: user 2h 11min 39s, sys: 19min 54s, total: 2h 31min 34s\n",
      "Wall time: 14min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(optimizer='adam',loss=custom_objective)\n",
    "\n",
    "history = model.fit(train_input, train_output, validation_data=(valid_input,valid_output), nb_epoch=500, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGDCAYAAAABPus1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xl8U1X6+PHPTZouabrvkJZS2rIvUgGFAlrBBZBVAUEF\ndHBBmGHGEX+A2+gXcMBtZHAU1JFxg0Gx4sKOqCAI4gIKI1CkpZTubbovae7vj0AgtoU2TZsWnvfr\nxcvm3HPvfXKo5Mm5Z1FUVVURQgghhGhFNK4OQAghhBDi9yRBEUIIIUSrIwmKEEIIIVodSVCEEEII\n0epIgiKEEEKIVkcSFCGEEEK0OpKgCCGEEKLVkQRFCCGEEK2OJChCCCGEaHUkQRFCCCFEq9PqEpR1\n69YxadIkuz9//vOf7eqsXbuW+++/nzvvvJNnnnmGzMxMh++3a9eupoYsGknavOVJm7c8afOWJ23e\n8pqzzVtdggIQGRnJqlWrWLlyJStXruSZZ56xHUtOTmbTpk3cd999LF68GA8PDxYtWoTZbHboXrt3\n73ZW2KKBpM1bnrR5y5M2b3nS5i2vOdu8VSYoWq0WX19f/Pz88PPzw2Aw2I5t3LiRCRMmkJCQQFRU\nFLNnzyY/P599+/a5MGIhhBBCOJObqwOoy5kzZ7j//vtxd3cnLi6OKVOmEBwcTHZ2NoWFhfTs2dNW\nV6/XExcXx9GjRxk4cKALoxZCCCGEs7S6BCUuLo5Zs2bRrl07CgsLWbduHU8++STPP/88hYWFAPj5\n+dmd4+fnZzsmhBBCiLav1SUoffr0sf0cFRVFbGwss2bNYs+ePbRv397p9+vatavTrykuLiwszNUh\nXHGkzVuetHnLkzZvec35GdrqEpTf0+v1REREkJmZSffu3QEwmUz4+/vb6phMJqKjoy96nV27dtUa\nzNO1a1dGjx7t9JjFxU2fPt3VIVxxpM1bnrR5y5M2b3mjR49mw4YNHDlyxK580KBBJCYmNunarT5B\nqaioIDMzk6FDhxIaGoq/vz+HDh2iQ4cOAJSVlXHs2DFuuummi14nMTGx3sbKXbqQzOsm8OwRM9Ou\nCqFPhKHOesI5fH19KSoqcnUYVxRp85Ynbd7ypM1blpubGwEBAYwePbpZvuy3ugTl7bffJiEhgZCQ\nEPLz8/nvf/+Lm5sbgwYNAmDEiBGsX7+e8PBwQkNDWbNmDUFBQfTr18/he5rTTxJQXYy74sHKbzN4\ncUQ0GkVx1lsSv6OqKtXV1a4O44oibd7ypM1bnrT55aXVJSh5eXm8/PLLFBcX4+vrS5cuXVi0aBE+\nPj4AjBkzhsrKSlatWkVpaSldu3ZlwYIFuLk18a1YapjYI4jHt5/iWF4FnYO9nPBuhBBCCOGIVpeg\nzJ0795J1Jk6cyMSJE5174xoz3UL1eGgVDmeXSYIihBBCuFCrXKjNJWpqcNModA724nBOuaujEUII\nIa5okqCcU1MDQLdQL45kl2FRVRcHJIQQQly5JEE5x3IuQdFTXGUh3VTl4oCEEEKIK1erG4PiMmcT\nlM7BXmgV+CW7jCh/DxcHJYRoS/z9/dForN/7NBoNgYGBLo7oyiJt7lwWi8Wlq7RLgnLO2Uc8nm4a\nYgI9OZxTzi3xAS4OSgjRlmg0GvLz810dhhBO4epkTx7xnKWeTVAAuofq+SW7DFXGoQghhBAuIQkK\ngKKB8jLbywFGA3llZrafMLkwKCGEEOLKJQkKQEAQZJ22vewWqmdotC9v/5gjvShCCCGEC0iCAhAU\nipp52q4osYMPhRU15JaZXRSUEEIIceWSBAVQgsIgM92urMPZGTzv/JTDmoO5rghLCCGEuGJJggIQ\nHAK52ajV59c+CfXW4eWmYedvRXx0JA+zRR71CCGEMyUkJDBv3jzb66+//hqj0cj+/fsvee7YsWO5\n4447nBrP3//+dzp06ODUazZETU0NRqORl19+ucXv3ZpJgsLZHhTVAlkZ58sUxdaLUmFWScmvcFV4\nQgjhMjNmzCA2NpaysrJ668yePZuOHTs2es0MpY5d4+sqa+i5DVFWVsYLL7zAvn376rzmuXVshOvJ\n3wRAaAR46bGsXo5adP5/sOgAD9y1Ch5ahV+y6v+fUwghLlfjxo2jsrKSjRs31nm8vLycLVu2kJSU\nhL+/f5PuNXjwYFJSUujXr1+TrnMxpaWlvPDCC+zdu7fWsb/+9a8cPXq02e4tGkcSFEDx9ELz10VQ\nkIvl2XmoZaUAjO0ayCOJ7ega4sX+0yUyo0cIccW58cYb8fb2Jjk5uc7jmzdvpry8nHHjxjnlfu7u\n7k65Tn0u9u+4RqNBp9M16/1Fw0mCcpYS1QnNI0sgNwv1wG4AInzc6W/0YWTnAA7nlPPd6VIXRymE\nEC3L09OTW265hV27dtW5Su5HH32EwWBg+PDhtrIVK1YwZswYunfvTqdOnRgxYgSbNm265L3qG4Oy\nevVqBg4cSKdOnbj11lvrHKNSWVnJ0qVLufnmm+natStxcXHcdtttfPvtt7Y6J0+epG/fviiKwtKl\nSzEajXZjP+oag2I2m3nhhRcYOHAgMTExXHvttSxbtozq6mq7egkJCfzhD39g7969jBw5kk6dOjFo\n0CA++uijS77v+hw8eJApU6bQuXNn4uPjmTx5Mj/++GOt+J577jkGDRpEp06d6NmzJ+PHj2f37t22\nOllZWfzpT38iISGBmJgY+vbty7333ktGRsbvb9mqSIJyASWsHXTphfrtl3bl/dob6BzsxebjrtuT\nQAghXGXcuHFUV1ezYcMGu/LCwkK++uorbrnlFjw8zu9d9uabb9KrVy/mzZvH/Pnz0Wg0zJw5ky+/\n/PL3l67l92NL3n77bRYuXEi7du14/PHHSUhIYPr06WRlZdnVKyoq4r///S+JiYksXLiQhx9+mOzs\nbKZMmcKvv/4KQGhoKIsWLUJVVUaNGsXy5ctZvnw5N998s+3ev7//n//8Z1544QWuuuoqnnzySfr3\n788//vEP5syZUyvulJQUZs2axXXXXccTTzyBj48Pc+fO5cSJE5d83793+PBhJkyYwLFjx5gzZw5z\n584lNTWVCRMmcOjQIVu9v//97/zjH/9g6NChLFq0iDlz5hAREcHPP/9sq3Pvvfeybds2pk6dypIl\nS7jnnnsoKirizJkzjY6rJclePL+jDBiKuno5qqkAxc+6F4+iKHQL8WJ3WpGLoxNCiJaXmJhIWFgY\nycnJTJ8+3Vb+ySefYDabaz3e+eabb+wSlunTpzN8+HBWrVrF0KFDG3zf6upqli5dSp8+fVi7di1a\nrRaATp06MX/+fLvejqCgIPbu3Yub2/mPtSlTppCYmMi///1vnn32WfR6PSNGjGDhwoV069btko+l\nDh06xEcffcS0adNYtGgRANOmTSMgIIA33niD/fv3242XOX78OB9//DF9+/YFYMSIEfTv35+1a9cy\nf/78Br9vsCYeqqqSnJxM+/btARg/fjxDhgxh0aJFrFmzBoAdO3Zw0003sXjx4jqvk5+fz48//sjf\n/vY37r33Xlv57NmzGxWPK0gPyu8ovay/bOrPB+zKO/h7kF1qpqzaumePWlFOzR/vQD3xa4vHKIRo\n+9TKStTUlOb9U1nplFg1Gg2jR4/mwIEDnD59flHL5ORkQkJCSExMtKt/YXJiMpkoKiqiX79+dt/8\nG+KHH36goKCAu+66y5acAEyePBmDwVArxnPJiaqqFBYWYjab6d27t11vQmNs374dRVGYOXOmXfn9\n99+Pqqps27bNrrxr16625AQgJCSEjh07kpaW1qj7ms1mdu3axYgRI2zJCUB4eDhjxoxh7969lJeX\nA+Dr68uRI0c4efJkndfS6/XodDq++eYbiora1pds6UH5HcXHD6LjUA99B4OG2crPTTlOK6yiS4gX\nFJugvBQ1JxMlprOrwhVCtFWZ6Vj+78/NegvNYy9Ch05Oudb48eNZtWoVH330EbNnz+bMmTPs27eP\nP/zhD7Uei2zZsoWXX36ZI0eOUHlBktTYAbDp6ekoikLHjh3tynU6HUajsVb9tWvXsnLlSlJSUjCb\nz68CHhMT06j7nnP69Gnc3NyIjo62K4+IiMBgMNgla4BdMnGOn58fJlPj9nXLycmhsrKyzrhjY2Op\nqanhzJkzxMTE8MgjjzBz5kwSExPp0qULSUlJTJgwgc6drZ9Lnp6ePProoyxZsoTevXuTkJDAsGHD\nuO222wgODm5UXC1NEpQ6KD2vRt2ajGo2o5zNyI1+7mgUSC2stCYolRVUadz4NNud0WYLHm7SGSWE\naIRwozWBaOZ7OEvPnj2JjY0lOTmZ2bNn22b1/P4xye7du7n33nsZNGgQS5YsITQ0FDc3N9577z0+\n//xzp8Xze2vXruXhhx9m5MiRzJ49m6CgIDQaDS+99BKZmZnNdt8LXdjLc6HmnAE6cOBAdu/ezebN\nm/nqq6949913ee2113juuee4/fbbAXjggQe45ZZb2LRpE19++SVLly5l+fLlfPjhh3Tp0qXZYmsq\nSVDqoPRMQN3wHqT8Dzr3AMBdqyHCx52ThWcXbKsoZ030jSQXBRCdWUY/o+EiVxRCCHuKh4fTejda\nyrhx43juuec4cuQIycnJdOzYkV69etnV2bhxI3q9nnfffdfuA/udd95p9P2MRiOqqvLbb7/Rv39/\nW3l1dTXp6emEhITYyj7//HM6derEa6+9ZneNZ5991u51YxZ4a9++PWazmZMnT9r1omRmZlJSUlJn\nj4kzhISE4OHhQUpKSq1jx48fR6vVEhERYSvz9/dn0qRJTJo0ibKyMsaMGcMLL7xgS1AAOnTowP33\n38/999/PiRMnGD58OCtXruSFF15olvfgDPK1vy5RncDXH/W7XahFBbbiuCBPjuZaE5Tq8go+bz8I\ngMoai0vCFEKIljR+/HhUVeW5557jl19+Yfz48bXqaDQaNBoNNTU1trLU1FS2bt3a6PtdddVV+Pv7\n8/bbb9td77333qOkpMSubl29F/v37+enn36yK9Pr9QANGo9xww03oKoqr7/+ul35a6+9hqIoDBs2\nrJ4zm8bNzY3BgwezceNGu6nAWVlZbNiwgWuvvRYvLy8ACgoK7M7V6/VER0dTVWXduqW8vNzuMRtY\nkxVvb29bndZKelDqoGg0KN2vQt35OeoPe9AsewtFUegS7MXXJ4uoNFvILamkSmv9BSmurLnEFYUQ\nou2LjIzk6quvZvPmzSiKUucsmGHDhvHmm28yZcoUxo4dS3Z2NqtXr6ZTp04NWqX1wschOp2ORx55\nhMcee4zbb7+d0aNH89tvv/HBBx/UWq9k2LBhbNmyhT/84Q9cf/31pKam8s477xAfH2/3Aa3X64mJ\niSE5OZmoqCj8/Pzo1q0bcXFxtWLp2bMn48aNY/Xq1RQUFNC/f38OHDjA+vXrufXWW5t1xdtHH32U\nb775hjFjxjBt2jQUReGdd96hpqaGhQsX2uoNHjyYIUOG0KtXL/z8/Pjhhx/YvHmzbWDvsWPHmDp1\nKrfeeivx8fFoNBo+++wzCgoKGDNmTLPF7wySoNRDuXEs6m/HIDMd9f2VqAHBdLlmJDUqHM+rwFx6\nfpGekipJUIQQV4Zx48Zx4MABrrrqqjo31hsyZAjLli3jlVde4cknn6RDhw488cQTpKSk1EpQGrIX\nz7Rp0wBrr8UzzzxD9+7dWb16NYsXL7arO2XKFHJzc3nvvffYuXMn8fHxvPLKK3z44Ye1Fjd7/vnn\nefLJJ/nb3/5GVVUVjzzyiC1B+f39X3rpJWJiYli3bh0bN24kNDSUuXPnMnfu3Fpx1/f4qCGPlX5/\nfteuXVm/fj1Llixh+fLlAPTt25dXX32VHj162OrNnDmTrVu38uWXX1JVVUVkZCTz58/n/vvvB6yP\nycaMGcOuXbv48MMPcXNzIzY2llWrVtktrtcaKaqs305OTk6tVQEB1PIyLH+aYt1IMCgUFq9iyrpj\n3N4jiIDffuZlUxjBlnISu7dnRt9QF0TeNgUGBta5IqVoPtLmLUPaWVxOLvX7rNPp7MYBOZuMQbkI\nxUt/fhBbXjaaEhM9w/R8n1FCXqWKT3UpgZYyecQjhBBCOJkkKJegDLoBel5tfXHyGP2NBo7klHOy\nWkdQpQmDuVwe8QghhBBOJgnKJWiuG4FmzuNg8EX97RhXtzdgUWF3TRBBlSZ8JEERQgghnE4SlAZQ\nFMW6umzqcQK93OgWYp29E1RpwlBVQkmlTDMWQgghnEkSlAZSIqPh9EkAro/xA0CjWjBUllIsPShC\nCCGEU0mC0lDtoyE/F7W0hIFRPgDEFp/CUFksj3iEEEIIJ5MEpYEU49nNqtJPYnDXsubUaq7PPICh\n3ERVjUqlWR7zCCGEEM4iCUpDhbUDNzfU9JMAuFeWonj7YKguA2SxNiGEEMKZJEFpIMXNDYwdUX8+\nYC2oKAdff3yqSwEokrVQhBBCCKeRBKURlGGj4ecDqMePWBMU/0ACq6wbTuWVmV0cnRBCCHH5kASl\nEZR+gyEiEnXbBqisQPELJKCqGA2SoAghhBDOJAlKIygaDUricNQfv4XqKghrh1a1EKBTyS2rvZeP\nEEKIxjl+/DhGo5ENGzY0+tzKykqMRiOvvPJKM0R2cU2JW9RNdjNuJOWa61DXr4b47iiJw1A/fpdg\ntxrpQRFCXJaMRuMl6yiKwrp167jmmmuccs+G7P57sXObcr5oPSRBaSTF1x/No3+H0Hbg4QlAoFIl\nPShCiMvS8uXL7V6vW7eOr7/+muXLl6Oqqq08Li7OKfeLjY0lJSUFd3f3Rp/r4eFBSkoKOp3OKbEI\n15IExQFKx/jzL7z0BFvK+UF6UIQQl6Fx48bZvT5w4ABff/01Y8eObdD5FRUVeHp6NuqejiQnzjhX\ntC4yBqWpvH0IMpeQW1Zt921CCCGuNDt37sRoNLJx40YWLVpEQkIC8fHxVFVVkZ+fz5NPPklSUhJx\ncXF07dqVadOmcfToUbtr1DWW48EHH6Rnz56cPn2au+++m/j4eHr37s2zzz5rd25dY1AWL16M0Wjk\n9OnTzJkzh65du9K9e3fmzZtHVVWV3fnl5eXMnz+f7t2707lzZ2bOnEl6enqTxrXs3LmT0aNHExsb\nS/fu3Zk5cya//fabXZ2ioiIWLlzIgAEDiImJoXfv3kydOpVff/3Vrl3uuece+vTpQ6dOnejXrx9z\n5syhvLzcobjaAulBaSpvH4KqiqjQqJRWWzC4a10dkRBCuNSyZcvQ6/XMmjWLsrIytFotKSkp7Ny5\nk5EjR2I0GsnKyuKdd97htttuY+fOnQQGBtZ7PUVRMJvN3HHHHVx77bU8/vjj7Ny5kxUrVhATE8PE\niRMveq6iKNx7773ExMSwYMECfvzxR95//33Cw8P5y1/+Yqs7a9Ystm3bxuTJk+nZsydff/0199xz\nj8NjWrZv386MGTOIi4tj3rx5lJaW8vrrrzN27Fg2b95MeHg4AA8//DBffPGFLcb8/Hz27t1LSkoK\nnTt3pqKigsmTJ6PRaJg5cybBwcFkZGSwZcsWysrK8PLycii+1k4SlKby9iG8LAcMkFFURXzw5fmL\nIoQQDaWqKsnJybi5nf+I6d27N19++aVdvbFjx5KUlMR///tfHnjggYtes6SkhLlz53L//fcDcNdd\nd5GUlMSaNWsumqCci6dfv34888wztnOzs7N5//33bQnKd999x9atW5kzZw6PPvooAHfffTcPPfQQ\nR44caVwDnPX0008TFhbGhg0b8Pb2BuCGG25g5MiRvPTSS7YeoC+++ILp06czf/5827kPPvig7efD\nhw+TmZnJf/7zH5KSkmzlf/7znx2Kq62QBKWJFIMPxsIzKAZIM1VKgiKEaJBKs4X0oqpLV2wCo687\nHm4t/yR/0qRJdskJ2I8NqampoaioCD8/PyIjI/n5558bdN0777zT7nW/fv3Ytm3bJc9TFKXWuQMG\nDODLL7+kuroanU7Hzp07URSFu+++267ejBkz+PjjjxsU34VOnTpFSkoKDz/8sC05AejVqxcDBgxg\n+/bttjIfHx8OHDhATk4OISEhta7l6+sLWBOZQYMG4eHh0eh42iJJUJrK2weP06mE++hILax0dTRC\niDYivaiKv2w82az3eOGWaDoFNm6AqjNERkbWKrNYLLz66qu88847pKenY7FYN1hVFIXo6OhLXtPX\n19fugx7A398fk8nUoJjat29v99rPzw9VVSkqKiIoKIj09HTc3d2JiIiwq9exY8cGXf/30tPTAYiJ\nial1LC4ujm+//RaLxYJGo+Hxxx/nkUce4eqrr6ZXr14kJSVx++2326Z4x8bGMn36dN566y3WrFnD\nNddcw/Dhw5kwYUKtNrmcSILSVAYfKCkmys+DNElQhBANZPR154Vbopv9Hq5Q16ydZcuWsXz5cu66\n6y4GDhyIn58fGo2G+fPnN2iCgVZb9/i+hk5OaOr5zWn8+PEMHDiQTZs28dVXX/HKK6/wyiuv8NZb\nbzFo0CAA/u///o8pU6awZcsWvvrqKxYuXMi//vUvPvnkE4KDg138DpqHJChN5e0LpUVE+Xmw/UTD\nMnkhhPBw07ikd8NVPv/8c5KSkliyZIldeWFhoYsismc0GqmqquLMmTN2vSgnTpxw+HoAKSkptY4d\nP36c8PBwNJrzj9/Cw8OZPn0606dPJycnh+HDh/PPf/7TlqAAdOvWjW7dujF37ly++eYbJk6cyHvv\nvccf//hHh2Js7WSacVMZfMBsJt5PQ365mYOZpa6OSAghXKa+GS9arbZWb8UHH3xAQUFBS4R1SUOH\nDkVVVVavXm1X/u9//9uhWTyRkZHExsayZs0aSkvPfy4cOnSIvXv3MmzYMADMZrPdcYCQkBCCg4Nt\n06CLi4ttj8TO6dKlC0CtqdKXE+lBaSLF2wcVSPAx0y3Ei3/sOcOcayLoE3H5PhcUQoj61PfIZNiw\nYfzrX/9i3rx59O7dm8OHD7Nhw4Y6x6u4Qr9+/bjhhhtYsWIFOTk59OrVi127dnHq1CnAseX3n3ji\nCWbMmMGYMWOYOHEiJSUlvPnmmwQFBfGnP/0JgIKCAgYPHsyoUaPo0qULXl5e7Ny5k19//ZXFixcD\nsGPHDhYtWsSoUaPo2LEjVVVVrFu3Dg8PD2655RbnNUIrIwlKUwUEAaDJz+VP18bx3O4MXvwmg9UT\nnLPssxBCtDYX+7Cu79hf/vIXKisr+fTTT0lOTqZ37968//77LFiwoEHXqO+6vy+vay+ehiYXr776\nKk8//TQbNmzgs88+Y8iQIbz88sskJSU1aObM7++TlJTE22+/zfPPP8/SpUtxd3dn0KBBLFiwwLYG\nio+PD1OnTuWrr77is88+Q1VVOnbsyHPPPcekSZMA68yfwYMHs3nzZrKystDr9fTo0YP333+f7t27\nN+i9tUWK2hpGCLlYTk4O1dWO7aWjms1Y5kxEuf0eNEmj2HHCxD/2nOG/k+JdMr2vLQgMDCQ/P9/V\nYVxRpM1bhrTz5efAgQOMGTOGVatWXda9FXW51O+zTqerc1q0s7T6HpTk5GTef/99RowYwbRp02zl\na9euZceOHZSWltqWJD6XkbYkxc0NIiIh/SQAwXprk+aVmWnnohH0QgghGq+ufYPeeOMNdDod/fv3\nd1FUV65WnaAcP36cbdu20aFDB7vy5ORkNm3axOzZswkJCWHNmjUsWrSIF198sdbiQC1BMXZEPWXd\nWyFYb91FM7esWhIUIYRoQ1566SVSUlIYMGAAiqKwbds2du3axb333ktQUJCrw7vitNpnEBUVFSxf\nvpwHHnig1kI0GzduZMKECSQkJBAVFcXs2bPJz89n3759rgk2siNkpKJaagg624OSK7sbCyFEm9K/\nf3+ys7N58cUXWbRoEenp6Tz66KM8+eSTrg7titRqe1Bef/11EhIS6NGjBx9++KGtPDs7m8LCQnr2\n7Gkr0+v1xMXFcfToUQYOHNjisSrGaNSqKsg6g0eEEV8PLblljo1pEUII4RpJSUl2e90I12qVPSi7\nd+8mNTWVKVOm1Dp2blEfPz8/u3I/Pz/XLfgTaV0KWT1lXdAnWO9Gbqn0oAghhBCOanUJSl5eHm+9\n9RZz5sxxyXgSRygGXwgIhvSz41C8ddKDIoQQQjRBq8sATpw4QVFRkW27a7BuMnX48GE2bdrESy+9\nBIDJZMLf399Wx2QyXXTDqV27drF79267srCwMKZPn46vr2+T92MwxcRD5mn8AgMxBhTyY0YRgYGB\nTbrm5Uqn00nbtDBp85Zx4dLlQrR1Go3mov9unFv35a233iIrK8vu2KBBg0hMTGzS/VtdgtKzZ0+e\nf/55u7IVK1bQvn17xo4dS1hYGP7+/hw6dMg2u6esrIxjx45x00031XvdxMTEehurqKjI4XVQzrGE\ntUf9egt5P/+It9abrOIKWQ+hHrJWRMuTNm8ZkgSKy4nFYmnQOijTp09vlvu3ugTF09PTtsnShWU+\nPj628hEjRrB+/XrCw8MJDQ1lzZo1BAUF0a9fP1eEDIDSpRfqpg+xPDWHoFF/pLSqPeXVFrx08o1K\nCCGEaKxWl6A0xJgxY6isrGTVqlWUlpbStWtXFixY4NIxK0rX3miWr0V991WC9m2BrjPIK6vG6Hfp\n5ZGFEEIIYa9NJCh1zUGfOHEiEydOdEE09VPcPVC79CL4++8B61ookqAIceWwWCy2xzwajabWDrSi\neUmbO5er27JNJChtieIfSGBlEYDM5BHiCnPhUgcy7qflSZtfXmSAhLP5B6FTa/B3U2UtFCGEEMJB\nkqA4W4C1ezdYayZHelCEEEIIh0iC4mSKpx48vQhWy9mWYmLNwVxXhySEEEK0OZKgNAf/IG6vSaFb\niBdfnjS5OhohhBCizZEEpTkEBBFTmMbNcf5kFFdTVCFjUYQQQojGkASlGSh+gaiFeXQJ8QLg19wK\nF0ckhBBCtC2SoDQHvwAoKiTUW4e/p5b/5Za7OiIhhBCiTZEEpTn4+EJJMYqiEBfkRUq+9KAIIYQQ\njSEJSnMw+EJ5KTX//D9i0n7kRH5Fk3dLFkIIIa4kkqA0A8XgZ/3hp310PLwLU2UNeeUyUFYIIYRo\nKElQmoOJScdAAAAgAElEQVTBx/ZjTMlpAE7IYx4hhBCiwSRBaQ4+vrYfgypN+HpoOZYnCYoQQgjR\nUJKgNIdzj3gABegT7s23p0pcF48QQgjRxkiC0hy89KDV2l4OjvYh1VRJamGlC4MSQggh2g5JUJqB\noijWmTxnXRVhwMtNw/506UURQgghGkISlOZyQYLippqJ8nfndLH0oAghhBANIQlKc7kgQaGygnY+\n7pwuqnZdPEIIIUQbIglKM1F8/c+/qCinna87GcVVrgtICCGEaEMkQWkmytg7Ue56yPqiopz2Pu4U\nV9ZQVFnj2sCEEEKINsDN1QFcrpTQCKiuQgVrD0pgGABniqvw9fByaWxCCCFEayc9KM3J82wiUlFO\nhI87AOkmGSgrhBBCXIokKM3pggTF001DOx932dlYCCGEaABJUJrT2Uc5akU5APHBnhyVJe+FEEKI\nS5IEpRkpbm7gpkPd8hHqiV+JD/Lit4IKqmssrg5NCCGEaNUkQWluigIZaVhWLCI+2BOzBU4UyDgU\nIYQQ4mIkQWlu1WfXPjH4Eu3viV6n4YeMUtfGJIQQQrRykqC0FHcPdFqF/kYDu9KKXB2NEEII0apJ\ngtLMlKRR1h9MBQAkRvlyylRFmuxsLIQQQtRLEpRmprnjPpSpD4IpH9VioU+EHm+dRnpRhBBCiIuQ\nBKUFKP6BYLFAiQmdVsOASAO7U4tRVdXVoQkhhBCtUqMTlKqqKj7//HMOHz7cHPFcnvwCrf8ttD7m\nGRTlS3pRFWkm2TxQCCGEqEujExR3d3feffddMjIymiOey5P/2QTFlA9Ar3A9HlqFAxklLgxKCCGE\naL0cesQTFRVFTk6Os2O5fPn6g6KgFloTFHethp5hepluLIQQQtTDoQRl8uTJbNu2jYMHDzo7nsuS\notVCUCj8dtRW1redgcM5ZZRV17gwMiGEEKJ1cnPkpE2bNmEwGFi0aBGhoaGEhobi7u5uV0dRFObN\nm+eUIC8HyrXXo25JRr39HhQvPX3bebPyOziUVcYAo4+rwxNCCCFaFYcSlLS0NACCg4OxWCxkZmbW\nqqMoStMiu8wog29C/fS/qN/vQRl0AxE+7oQbdPyQUSoJihBCCPE7DiUoK1ascHYclz0lIAgijHDy\nKAy6AYCEdt7sSi3G11PLlF4hLo5QCCGEaD1kHZQWpETFoKam2F4PifZDo1FYeyiPjCKZciyEEEKc\n41APyjmHDx/m+++/t83oCQkJoW/fvnTr1s0pwV12ojrBgW9Qa2pQtFq6hHjx6ugYpq47xncZJYz2\nDXR1hEIIIUSr4FCCYjabeemll9i/fz8Aer0egLKyMj755BP69+/Pn/70J9zcmpT/XHaUqE6o1VWQ\nmQ7tOwDg6aahR5ie706XMLqLJChCCCEEOJigrFu3jv3793PrrbcyatQo/P39ATCZTHzyySd88skn\nfPDBB0yePNmpwbZ5UTGg1aL+egjlbIIC0DfCm7d/zOF0URU1FpUofw8XBimEEEK4nkNjUHbt2sXQ\noUO58847bckJgJ+fH3feeSdDhgzh66+/dlqQlwvFSw9d+6Dut2+b7qF6qi0qC7am8tIeWaFXCCGE\ncChBKSwsJDY2tt7jcXFxFBYWOhzU5UzpPwSOH0HNO78Sb8cADzzdNBRW1HDKVIVFNhEUQghxhXMo\nQQkMDLzoZoGHDx8mMFDGU9RF6ZkAgHriV1uZVqPQJcQLgKoalZzSagorzFSaLS6JUQghhHA1hxKU\noUOHsmfPHlauXElGRgYWiwWLxUJGRgarVq1iz549XHfddU4O9fKgGHzBx886UPYCN8X6MSjKumBb\nuqmKJ7af4r2Dua4IUQghhHA5hwbJjh8/nqysLLZv38727dvRaKx5jsVi/cY/dOhQxo0b57woLzfh\n7WslKAOjfLkm0ofv1h4lJb+CtMJKvHWyTI0QQogrk0MJikaj4aGHHmLUqFH88MMPduugXHXVVXTo\n0OESV7iyKeFGuwXbztEoCu193dmdVowKpJoqUVVVtg0QQghxxWl0glJVVcW2bduIjo6mW7dukow4\nIrw9fPslqsWCorHvJYkL8mLzcesA49IqC7llZkK8da6IUgghhHCZRj9DcHd359133yUjQ6bDOkoJ\nN0JVJRTk1Tp2fYwvAAZ3619NamFli8YmhBBCtAYODXKIioqyPdYRDugYD25uqPu/qnWoS7AXHfw8\n6NfegLdOw4n8ChcEKIQQQriWQ2NQJk+ezMsvv0z37t3p1auXUwPasmULW7duJTs7G4DIyEhuu+02\n+vTpY6uzdu1aduzYQWlpKZ07d2bmzJmEh4c7NY7mpPj4oQy4DnX7p6g3jEbRnX+EoygKTw+LRKdR\nKDdbOJBRysSewS6MVgghhGh5DiUomzZtwmAwsGjRIkJDQwkNDcXd3d2ujqIozJs3r9HXDg4OZurU\nqbaEY+fOnSxdupSlS5diNBpJTk5m06ZNzJ49m5CQENasWcOiRYt48cUX29TeP8pN41G/3Ym6/j8o\nk+61O+bvaX0f/dob+OfeTAorzLYyIYQQ4krg0COetLQ0zGYzwcHBWCwWMjMzSUtLq/XHEX379qVP\nnz6Eh4cTHh7O5MmT8fT05NixYwBs3LiRCRMmkJCQQFRUFLNnzyY/P599+/Y5dD9XUSKMKOOnoW77\nGPXnA3XWubq9AYCvTxa1ZGhCCCGEyzn0tXzFihXOjqNOFouFPXv2UFlZSefOncnOzqawsJCePXva\n6uj1euLi4jh69CgDBw5skbicRbnhVtRfvsey+p9olr5Zazqxv6cbN3Ty492fctl7qpiHBkTQzte9\nnqsJIYQQl49G96BUVVWxevVqvvvuu+aIB7D20Nx9991MnTqV119/nUceeYR27drZ9vfx8/Ozq+/n\n59cm9/5RNBo0Q26CwjwoNtVZZ8ZVoUT5e/BzdjlbU9reexRCCCEc4dA0423btmEy1f2B6gzt27dn\n2bJlLF68mBtvvJF//vOfnD59utnu51LBYdb/5mXXedjgoWXpTR24KdafXanFsj+PEEKIK4JDj3hi\nYmI4deqUs2Ox0Wq1hIVZP7g7duzI8ePH+fzzzxkzZgwAJpMJf39/W32TyUR0dPRFr7lr1y52795t\nVxYWFsb06dPx9fVFddEOwhYPHXmAd0UpbqUm1LJSKr7ajDYoFP34u2z1RvbSsvn4L0xdd4wZAyKZ\n0rc9Wo39I6HSKjNuGg0ebq17iXydTiebSbYwafOWJ23e8qTNW9a5YQlvvfUWWVlZdscGDRpEYmJi\nk67vUIIybdo0lixZQmRkJNdddx1arbZJQVyKqqpUV1cTGhqKv78/hw4dsq1gW1ZWxrFjx7jpppsu\neo3ExMR6G6uoqIjq6mqnx91gem9KTqagvvCk9XVIOPgFUnHdSFuVKE+VZ26I5EBGKav2pLHnRC5P\nJUXidkGS8ujmVLqEeDGjb2hLv4NGCQwMJD8/39VhXFGkzVuetHnLkzZvWTqdjpCQEKZPn94s13co\nQXnllVfQaDSsXLmSf//73wQGBtY5zXjZsmWNvvZ7773HVVddRXBwMOXl5ezatYvDhw/z2GOPATBi\nxAjWr19PeHg4oaGhrFmzhqCgIPr16+fIW2kdgkIhPfX864JcKCu124dHURR6hXvTK9ybvu28eXL7\nKTYfK2Rk5wDAmsSdLKxEI9v2CCGEuAw4lKAYDAZ8fHxo166ds+OhqKiIFStWUFBQgF6vp0OHDjz2\n2GP06NEDgDFjxlBZWcmqVasoLS2la9euLFiwoE2tgVJLcBjqvi/PvzabwVwMpnzwD6pVvXe4N0kx\nfqz7OZcR8f4oikJxZQ0VZgunZINBIYQQlwGHPtWfeuopJ4dx3gMPPHDJOhMnTmTixInNFkNLUwJD\nqGsEjOWRGSgTpqG5eUKtY/2MBrafMFFYUUOAlxuZJdZHVMVVFluZEEII0Va17tGUVwjl2iSU4WPQ\nPLW81jH16C91nhPpZ32klmaybiaYVXJ+DM25MiGEEKKtcvhrdllZGVu2bOGXX37BZDJx3333ERsb\nS0lJCTt37uTqq69uU/vjuJLSoRNKh07WmUSeXqBooLoSzGYUL+86z4kwuOOmUThZUEnnYC+ySqvR\n6zRU16jsSDHROdgLz1Y+m0cIIYSoj0MJSl5eHk899RS5ublERERw+vRpKiqsu+4aDAa2bt1KTk4O\nM2bMcGqwlztFUWzromgeWYzlzZdQS+pe5l6rUTD6uvPm99ms/iGbGhWMvu4MjPJh/eF8gr113NUn\npCXDF0IIIZzGoa/Yb7/9NuXl5SxbtqzO8Sj9+vXj0KFDTY3tiqR06IQSGYOiN6D4BUJJ/Qvi1Zxd\nu2VoR+vKusF6N6b2DuG6jr58k1bksrVdhBBCiKZyqAfl4MGDjBw5EqPRSHFxca3jYWFh5OXlNTm4\nK5Fy9+zzL3x8oZ4eFIApvYLZl17CH68JZ3LPINy11nzz2kgftqWYSDNV0cHfo7lDFkIIIZzOoQSl\nqqoKX1/feo+Xl5c7HNCVTtFcsOidjx8UF9U7bXhglC8Do6x/D2GG8+vQ9A7Xo9dp2JNWLAmKEEKI\nNsmhRzxGo5EjR47Ue3z//v2XXHpeNIDBF6qrsMyfaZvNo+ZmYVm9HLWmpt7TdFoNV7c3sOdU7d4t\nIYQQoi1wKEEZMWIEu3fvJjk5mbKyMgAsFguZmZksX76co0ePMnLkyEtcRVyK4nO2lyovG/WnfQCo\n3+9B3bUV8rIuciYMjPThZGEl/9hzhrwyFy7jL4QQQjjAoUc8Q4YMITc3l7Vr17JmzRoAFi9ejKqq\naDQa7rjjDvr37+/UQK9IBj/bj+qJ/6FaLJCaYi3Iz4XQ+lfy7dvOm4R23uw/XUJWSRXP3BBVa3NB\nIYQQorVyeB2U8ePHM2TIEPbu3UtmZiaqqhIWFsaAAQNsOxGLJjJcMM7n+BEsc6dAubXHSs3P4WLp\nhoebhieuj+THM6U8ueMUR3LK6RGmb954hRBCCCdp0nrowcHBjBo1ylmxiN/z8bN/fTY5ASA/p85T\n1NwsMPiieHoB0Ctcj4+Hlp8yS+kRpkdVVSwq0psihBCiVZOlRlsxRaeD+O5oHlqIMnkmyojbrQf0\n3tZHPHWwPLcQdevHttcaRaFXmJ6fMq3JzX9+zGHu57/JGilCCCFaNdlRrpXTPrIEAAWs0437Dcay\n4T3UOnpQ1OpqyMuGXPsBtL3C9by2P4tfssr4+Eg+NSpkllQT4eNe+xqqyo4TJoZE+6HTSi+LEEII\n15AelDZEURQUYzRKYEjdPSgF1jLVlG9XPCjKF083DU/sOEWwtw6NAnM//42lX5+udYnj+RW8vDeT\ng5mlzfIehBBCiIaQBKUtCgyBnDNYtn9qX36uV8VUYFfs46FlXNdALKrKnwdG0CnQkwqzyu60Ymos\n9o96UgutOyHnlZubLXwhhBDiUiRBaYOUPgOgYzzq2tdRK86v2mt77FOYX+uc23sEsXJMJ7qG6Lkh\nxo9Qbx0AKfkVdvXSziYoubJ2ihBCCBeSBKUNUkIj0Ex9EFQLnDwGgOWTNahrX7dWKClCNdsnGIqi\nEHI2KbklPoB/jY7BQ6vwc1aZXb1UUxUAeWXSgyKEEMJ1GjRI9m9/+1ujL6woCk888USjzxMNFBEJ\nXnoszz8GPa+G0yeh7IJxI0WF1kdB9XDTKHQP1fPNqWLGdQu07fVzrgdFEhQhhBCu1KAEpa7N6nJz\nc8nOzkav1xMaGgpAdnY2ZWVlhIWFERQU5PxohY2i0YCbtUeEQ9/VrmAqQM3KgLjuKG51/zXf2iWA\nv32Rzu60YtJMlXT09yS/3EyAp1aWxxdCCOFSDUpQnnrqKbvX//vf//j73//O/fffz9ChQ9FqrTvw\n1tTU8MUXX/Duu+8ya9Yspwcr7CkjJ6GuWXm+ICQc5epE1I0fWPfs2fQhyoy5KAOT6jz/qghvuoV4\nsWxXhq3Mz0PLTXH+fPK/gjrPEUIIIVqCQ2NQ3n77ba6//nqSkpJsyQmAVqtl2LBhXH/99fznP/9x\nWpCibpobRqF59SPw8AQPTzT/9yrK2DtBq0Xd8Ym10pGf6j1fURSeviGShUPb89hQI+5ahXHdAmnn\n405ptYWy6vp3TBZCCCGak0MJSmpqqu2xTl1CQ0NJS0tzOCjRcIpWCzGdITIGRaOx/hk5CaqqwD8Q\n9chPF101VqfV0N/oQz+jgTfGxTK2ayDBeuujo+wSecwjhBDCNRxKUAICAtizZw81NbW/YdfU1PDN\nN98QEBDQ5OBEw2juno1mxh/Pv751MppnX0dz9xww5UP6yQZdx9dDi6IoxAZ54uWmYXdacTNFLIQQ\nQlycQwnKmDFj+N///sfChQvZvn07v/zyC7/88gvbtm1jwYIF/Prrr4wePdrZsYp6KMFhKKHt7MuC\nQqFLLwgMRv18XaOu5+GmIbGDDztOmGot5CZ7+AghhGgJDu3FM2zYMDQaDe+//z4rV660O+br68vM\nmTMZNmyYUwIUjlN0OpRb70BdvRx1zBSUcGODzx0e68/WFBPfnS5hQKQPqqry8t5Myqst/L8h7Zsx\naiGEEKIJmwUmJSUxdOhQUlJSyM217gETHBxMp06d7AbOCtdS+g9BfX8l6g97UW65DcC6iFtNDYqH\nZ73ndQ72omuIFx8dyae/0cD2EyZ2nDABkG6qxOjn0SLxCyGEuDI1aTdjrVZLfHw88fHxzopHOJni\n7gHdr0L98VssgSGoWz9Gie2KmpqC9tFnL3rubd2DeGZnOttSTKz+MYfEDj4czCxjy/FC7kkIa6F3\nIIQQ4krkcIJSVlbGli1b+OWXXzCZTNx3333ExsZSUlLCzp07ufrqqwkPD3dmrMJBylXXor75Imp+\nLhTmoZ5OBY2mzgX4LpTQzpt+7Q3889tMPN003NM3lHd+yuFwTnm95wghhBDO4FCCkpeXx1NPPUVu\nbi4RERGcPn2aigrrpnMGg4GtW7eSk5PDjBkznBqscIzSLxH1i8/gt6OgdYNz+/QU5kNA/Sv+KorC\nH68JZ//pErqG6AnS64jy8+CbtOJLJjdCCCFEUziUoLz99tuUl5ezbNky26DYC/Xr14/vv//eKQGK\nplPcdGgenI/68wH43yHUfV9aD2SdvmiCAuDr6cYNnfxtryP9PKgwq+SUmgk16JozbCGEEFcwh6YZ\nHzx4kFtuuQWj0Vjnt+iwsDDy8vKaHJxwHiUgCM3gG1FunYwy86/WRzzZGZc+8Xeizg6OTTNVOjtE\nIYQQwsahBKWqqgpfX996j5eXyxiF1koJb4+m/xAIDoOsxicoId5ueLppJEERQgjRrBxKUIxGI0eO\nHKn3+P79+4mOjnY0JtESQtuhfrcb9ad9jTpNURQ6+HtwNNeahKqqSklVDYu/TCenVJbGF0II4RwO\nJSgjRoxg9+7dJCcnU1ZWBoDFYiEzM5Ply5dz9OhRRo4c6dRAhXNpbrkNgkKw/OtZ1B+/pWbJI1j2\n7mzQuYOifNh/upQT+RU8sOEE87ek8m16CQcySpo3aCGEEFcMRXVw7fL169ezbt06VFW1zehQVRWN\nRsOkSZMYO3ass2NtNjk5OVRXX3nf/lVzNZaXnz6/43FgMJpFr4FGi6KpP3c1VZi556PjaBQFi6pi\ntljL7+odwm09Lj7oFiAwMJD8/HxnvAXRQNLmLU/avOVJm7csnU5HSEhIs13f4QQFIDc3l71795KZ\nmYmqqoSFhTFgwADCwtrWIl5XaoICoFZXoa7/D/gHoX74Frh7gNmMZv5SlA6x9Z635XghqYWV3Bjr\nz4HTJXzyawH92huYNeDSa9/IPyItT9q85Umbtzxp85bV3AlKo6cZV1VVsW3bNqKjo+nWrRujRo1q\njrhEC1F07iiT/gCA2jEe9eRR1E3rUfd9fdEE5cbY81OPO/h78GteOVkyBkUIIYSTNHoMiru7O+++\n+y4ZGY2fASJaNyW+O5obx6H0GYD6w55G7Vwc6q0ju0QSFCGEEM7h0CDZqKgocnJynB2LaCWUq66B\nnEzIONXgc0K9deSUVmNx/ImhEEIIYeNQgjJ58mS2bdvGwYMHnR2PaA269AYPL9Qf99qKLHu/wLLx\nw3pPCTXoqLaomCpqWiJCIYQQlzmHlrrftGkTBoOBRYsWERoaSmhoKO7u7nZ1FEVh3rx5TglStCxF\np0PpmYD6w17UwcOxvPcaHPgGALVzD5SYzrXOifS1rjD7w5lSkmL8WjReIYQQlx+HelDS0tIwm80E\nBwfb1j9JS0ur9Ue0YX0GQOpx1LVvwuEfUe6eDcZoLJ+sqbN6O193BhgNvH8wlx/PlPL49jSqa+Rx\njxBCCMc41IOyYsUKZ8chWhml59WoWjfUfV+iXHM9msE3YqmsQP1wNWpVJYq7h62uaioAHz9u7xHE\nXzelsuq7LNKLqth7qpjB0fVviSCEEELUx6EeFHH5U/Te0Lmn9UW3Ptaybn3AXA3HDtvqqTmZWP46\nDXXvTjoFeuLroSW9qAqAz44WtHjcQgghLg9NTlDKy8vJy8sjNze31h/RtikJ14JGg9K1t7UgIhL8\nA1EP/2iro55bHt9UgEZR6BmmB2CA0cCRnHJ+zS2nrLqGb08V82uubCIphBCiYRx6xAOwZcsWPv30\nU7Kysuqts3btWkcvL1oBJXE4Slx3FP9A62tFQenaB/XwD8AMVLMZdfc2a2WzdQ2U3uHe7E4rZkbf\nUI7nV/D/tqTiodVQbrYQbtDx2phOLno3Qggh2hKHEpQtW7bwxhtv0Lt3b66//nrWrFnDyJEj0el0\n7Ny5E39/f2655RZnxypamKLRWntNLtStD+zZgVpUgLp7OxSc7SkrLQYgKcaPCB8dET7u3NEzmK9S\ni2jv487GY4WUVtU0avE3IYQQVy6HHvFs2rSJ3r17s2DBAoYNGwZA3759ueOOO3jxxRcpLy+nuLjY\nqYGK1uHc4x71+72on61DSRoFcd2gpAgAnVahV7g3AMNj/Xnmhige6B/OY0ONFFdZyC0zuyx2IYQQ\nbYdDCUpWVhYJCQkAaLVaAMxm6wePXq8nKSmJLVu2OClE0ZoofgFg7GjdYLCqEmX4WPD2RS29eEIa\nE2id9ZOSX9ESYQohhGjjHEpQ9Ho9NTU1tp/d3d3tBsV6eXlRWFjonAhFq6O54z6oqoReV6MEBqMY\nfKDk4glKoJcb/p5aDmaWtlCUQggh2jKHxqBERkaSmppqex0fH8/WrVvp27cvFouFbdu2ERER4bQg\nReuixHdHM38ZBAZbC7x9bGNQ6j1HURgZH8C7B3NJiM4hIUTbApEKIYRoqxxKUAYPHszWrVuprq5G\np9Nx++2388wzz/Dggw9aL+rmxsMPP+xQQB999BH79u0jIyMDd3d34uPjmTp1Ku3atbOrt3btWnbs\n2EFpaSmdO3dm5syZhIeHO3RP0XhKhwtm4zSgBwXg9h5BnC6u4u87Unj+5g5E+nlc8hwhhBBXJkV1\n0rSKrKwsDhw4gEajoVevXrUSioZasmQJgwYNIiYmBovFwnvvvcepU6d48cUXbfv9JCcn8/HHHzN7\n9mxCQkJYs2aNrY6bW+NzrpycHKqrqx2KV4Bl11bU1cvRvPoRirZ2z4jlvVehqgrN9D9Sabbw0Kcn\nGWD0ZubVYS6I9soUGBhIfn6+q8O4okibtzxp85al0+kICQlptus7bSXZsLAwRowYwc033+xwcgIw\nf/58hgwZgtFoJCoqilmzZpGbm8uJEydsdTZu3MiECRNISEggKiqK2bNnk5+fz759+5zxVkQjKQYf\n6w/1POZRM06hnrL+/Xm4aRjYMYDvTpfIlGMhhBD1avVL3ZeVlQFgMBgAyM7OprCwkJ49e9rq6PV6\n4uLiOHr0qEtivOJ5W/fbUXdvrzvpKC2Bgjzby2ujA8gsqeZ0cVVLRSiEEKKNcWgMyqRJkxpUr6kr\nyaqqyltvvUWXLl0wGo0AttlBfn5+dnX9/Pxk5pCrnO1BUdevRontal0X5UJlxVBsQjWbUdzcSDD6\noVXgUGYZRl8ZhyKEEKI2hxKUCRMmoCiKXZnFYiEnJ4f9+/fTrl07+vbt2+TgXn/9ddLT03nmmWea\nfC3RjELbodxwK+r2T1DPnEL5fYJSenZqsakAgkLw1Gkx+npwsrCy5WMVQgjRJjiUoEycOLHeYwUF\nBSxcuLDJ04zfeOMNfvjhB55++mkCAgJs5f7+/gCYTCbbz+deR0dH13u9Xbt2sXv3bruysLAwpk+f\njq+vr4yHaKpZj5L38wE8TPkYAgNtxWp1NbmV1k0CfdVqdIGB6HQ64sN8SC+uJPCCuqL56HQ6aesW\nJm3e8qTNW9a5joq33nqr1r58gwYNIjExsUnXd3izwPoEBAQwfPhwPvzwQ4eDe+ONN/juu+946qmn\nCA4OtjsWGhqKv78/hw4dokOHDoB1nMqxY8e46aab6r1mYmJivfEUFRXJLB4nsIREUJ6aQtUFo+jV\nogLbz0WpJ1GC2xEYGEg7vcLXJ0pJz8rh018LuCnWHz9Pp/86irNkdkPLkzZvedLmLevcLJ7p06c3\ny/Wb5RPBw8OD7Oxsh859/fXX2b17N/PmzcPDw8M2ruTcirUAI0aMYP369YSHhxMaGsqaNWsICgqi\nX79+TnsPovGUsHaoP39vX1haYvtRLczj3IPB6AAPKswW1h7KI/lIPpuOFbJiVAxeulY/blsIIUQL\ncHqCkpaWxsaNGx2earx161YAnnrqKbvyWbNmMXToUADGjBlDZWUlq1atorS0lK5du7JgwQKH1kAR\nThTeHnZ+jnroAJaP30Xz/5aeT1AUBQrPf7PpFOiJRoFPfy0g3KAjq6Sab9KKuKGTfz0XF0IIcSVx\n6BP9oYceqjVIFqC0tJSysjI8PDy47777HAqooTN/Jk6ceNGxMKLlKWHtUWtqsHzxGaQeh+OHofLs\nQNiQcCg8P9XYz9ONMV0C+ehIPrf3COKrk0VsP2GSBEUIIQTgYILSrVu3OhMUg8FAWFgYgwYNsq1b\nIuAwe9oAACAASURBVK4gUTHW/x7+AQD1p/0Q2dFaFhGJWmQ/DfyOXsEYPLQkdvDFTaPw4jdn+Mee\nM2SXVLFoeIeWjFwIIUQr43APihC/p3j7QFAo5GWDokE9uB8lKBg8PFECg1GP/mJX38NNw23dgwC4\nNtKH13RZ7DhhAqC82iLjUYQQ4gomnwDCuc5tItgzAbIzICsD9AbwDYCi+hfS83DTMLiDr+31yYKK\n5o5UCCFEK+ZQD8oHH3zg0M1uu+02h84TbYcS1Qn1+z1oEodjObgf9dAB8DaArz+UFKHW1NR77pRe\nwSS082bZrgxSCiroGqpvwciFEEK0Jg4lKOvWrXPoZpKgXP6U3v1Rfz0E/5+9+w6ssjofOP497703\nNzc7N3uRAAmRjYgow23BUbfFukedraPV1j1Qi3XUVqu2dbVY/bmrFAcoiqgsAdl7BAgkZO/k7vf8\n/nhDQkzCJhB4Pv+Q+77nvvfck8t9n5zxnAHHQFQMVJahRpyCio23kuE11EEnu1/GuewclxVNjzgn\nry4oIy0qjGMyonhjURkDUyIYmi7zmoQQ4kixVwHKP/7xD/70pz+RlZXF2Wef3bKkuKioiM8//5yt\nW7dy7733Ska/I5DKzMF2Z/PWBD37wLIFqFN+DjRn6q2t7vS52w1MiWBDlZenZxbxzNgcJq2qYmud\nXwIUIYQ4guzVHJTXXnuNtLQ0br/9dnr37o3L5cLlcpGbm8vtt99OSkoKr7/++v6uq+hm1HEnoUac\niuqZZ81BgZ3OQ9nuqiFJvH5Bb8JsBo/P2IKpYUVpE8/OLKagSuamCCHEkWCvApQVK1YwYMCATs8P\nHDiQ5cuX73WlxOHBOO4kjOt+az2IsfKb7Jj6vjM2Q5EY4eDKIUmUNQZxGIrGgMl3m61cKUIIIQ5/\nexWgOBwO1q5d2+n5NWvW4HA49rpS4vCjHA6IiISSrQQK1qKDu9776LResfRLcnFeXzcuu/VRbfB3\nPslWCCHE4WOv5qCMHj2aKVOmEBERwZlnnklKSgoApaWlTJkyhZkzZ3LmmWfu14qKw0BcAnrKf6mZ\n8l/UZTejTjlrp8VthuJPY6yEbaf3juXtpRUU1fm7oqZCCCEOsr0KUK644grq6+v54osv+OKLLzAM\n669b0zQBa5vlK664Yv/VUhwWjBvugspy+PDf6JKte/TctOgwcuKcLChqoLDWx6sLSrn1uFRSosIO\nUG2FEEIcTHsVoNjtdm677TbOPfdcFi1aRHl5OQBJSUkMGTKEnJyc/VlHcZhQmT0hsye2OdPxl5fs\n8fMzY8JoCpj8ccZWShsCvDy/lIdOzuxw2wUhhBDd2z5t/5udnU12tuyZIvaMLSUdFv2wx8/LiLF6\nS0obApzf182kVVWsKvfQTxK6CSHEYWefApTtioqKmDNnDjU1NaSnp3PyyScTESE3DdExIzkNKsvQ\nddWYf30E46rbrKXIu5AeE8ZVQ5I4Oi2SnHgn84sa+GRNtQQoQghxGNrtVTxTp07ljjvuoK6urs3x\nBQsWcPfdd/PBBx8wbdo03njjDe6555525YTYzpacBn4fevEPsHUT5nOPoIPBXT7PUIqL+ifQyx2O\noRTn5Mczp7C+ZYNBsPKlrCpv2qP6bKr2yt4/QghxiNntAGXBggWkpKQQE9O6oVsoFOLll1/GMAxu\nueUW/vznP3PZZZdRUVHBRx99dEAqLLo/W0oaAHrpAutAUwP6u6mY/33DSoe/m8bmxXFqr1he+mEb\ntd4gptY8N6eYv//Qfn6L1pqlJY0dXv+Ozzdxx+eb9uq9CCGEODB2O0DZunUreXltu+FXrFhBXV0d\nZ599NieffDJZWVmcd955jBgxgkWLFu33yorDg5GSYf2wajH0Pgrciej3XkNP/S9UV+z+dZTimqOt\nfX2+2VjL4m2NlDUGKaz1U1jra1N2ZbmHh77ewpR1u85kK4QQ4uDb7QClvr6ehISENseWLVsGwPDh\nw9scz8/Pp6Ji92804shiuCIgrx/4/aiMbNSAYdC8RJ0tG/foWjHhdoZnRvPvheU8+s1WUqIcRDgM\nZhfWtylX2mAlhpu6tqbTXpp6nySBE0KIQ8VuT5KNi4ujpqbtX5+rV6/G6XS2W8ljt9ux2/fL/Ftx\nmFLDT0KvWwnp2aj0LPS8b0GD3lKAGjx81xfYwVVDkuiX5CI23E52nJM3F5ezptzTpkxJg5XgbXOt\nj001PnrGh7e7ztZaH31lwq0QQhwSdrsHpVevXnz77bd4PNYX/5YtW1i/fj2DBw/GZrO1KVtUVNSu\nt0WIHaljR0NmT9RRg1B9B2M89zb0zEPvYQ8KWEnczjnKzYk5MWTHOcmOc7Kppu0QT2l9gLyEcFx2\ng/lbG1qO79ibslWy1AohxCFjt7s5fvGLX3Dfffdx++23k5WVRUFBAQAXXHBBu7Lz58+nf//++6+W\n4rCjIqOxPfJ862ObDZXVEz3vO3RpMSolfa+vnRPnpMoTpM4XIsZpBc/bGgJkxoSRFOlgflED4wYm\nAuALSYAihBCHot3uQenRowcPP/wwvXr1orq6mry8PO677z569erVptyKFSsICwtjxIgR+72y4vCm\nRp0ONjvmSxP26TrZ8U4APl1TRUPzvJKSBj+pUWGMyIpmbaWXNxaVAW03HyxtCKC15qGvC1m8rXGf\n6iCEEGLf7NFEkfz8fO67776dlunfvz/PPvvsPlVKHJlURjbq7F+g3/onOhhE7eU8pvRoK+Pse8sq\nqfGEuHZoMrXeEKnRDkZnR1NUl8C7yyoZkxuHL2g2P8dBrTdIo99kaUkTPWKdDEmL3G/vTQghxJ7Z\n7R4UIbqCSkwBbbZbbqw3rUN7di8Bm91QnJkXB8Cq8ia+32wlDezdnODtgn4JhNkUswvrafRbAUpG\njJMab5DyJmu1z0/nsAghhOhaEqCIQ0tiCgDmK88QevZBtGmiTRPzzw+gv5u625e5eXgqd41Kp7DW\nz0s/lHBidgxZsdbQT7jd4Jj0KKYX1LKteXVPVmwY1Z4QZY3NAUq1d4+SxgkhhNi/JEARhxZ3EigF\nm9bB6qXoT9+F6krweaGidI8uNTi1dcnwlb3thO6/EV1bDcAF/dzUeoO8MNfKOpsRE4YnaFLUPFG2\nwW9S6dl1+n0hhBAHhgQo4pCi7A6Ib16inpmD/uRdzLf/CYCurtyja8WG23nyZz148+I8kurLobwE\nyrYBkJ/o4vphKS1lEyIcAKyv9BJuVwBsqpZhHiGEOFgkQBGHnuZhHuOOR2DoCFg63zpeVb7Hl+qb\nHGEtNfY1bwbobZ3HMii1dRJsXLi1HHldpYe8BBdOm2rpTRFCCNH1JEARhxyVlAqJKai4BFRuv9YT\n1ZXoYBBz7jdo/x72bvitAEU3tS4fdrtaVwnFh1s/lzUGSYp0kB4TJgGKEEIcRJKPXhxy1DmXok6x\n9tJRvfJpmaraUGdtKjjjcygqRF109W5fU3u396C0TYF/Tn48td4Q0c7WbMipUQ58QZPieglQhBDi\nYJEeFHHIUQnJqOze1oMevcFuh+YdkPWMz6FHL/S0SejKPRjyae5BwdM2Adv1w1K4a3Q6NkO1HDu1\nVyzp0WEUSw+KEEIcNBKgiEOacjhQF1+L+vm4lmPG7x4DpdCLZrcpa879BvPLjzu+0PYeFE8Tuqmh\nwyJ9EsI5MSemZYin0hPE25zITQghRNeSAEUc8ozTzkEdPdJ6MHAYKioG+g5BL/qhTTn9+l/RH/wb\nHQq1v8j2OSgLZmLefR3a134Oy9Njs7lzZBrQmo12mwzzCCHEQSEBiugWlNOJcc9TGLfcaz0echys\nW4luqGtfeMOq9se2r+Ip22b9vMPztN+H9vtQSqGUNdSTGRuGAjZUeff3WxFCCLEbJEAR3YbK7Yty\nWD0basAxoE30qqUAVtbXMCtTrF66oP2TfT8JNBrrW37Ub/0d/eZLbU5HhdnIiXeyoqyJQMiUQEUI\nIbqYBCiiW1LuREjNhFWLrSGdpkZoXnqsN61r/4SdBSjlpeiKsnZPGZgSwZJtTdw3rZA7p2yirCGw\nX9+DEEKIzkmAIrot1W8I+vsvMe+5Dgo3WAf7DYHSonZl9U8DlB0nyjY1tH3cbEBKBJWeIOsqreeu\nqfC0KyOEEOLAkABFdFtqxCmQ2xd8Xsy3X7aO9R0MNVVo7092Pv5JgKJ36EGhscHqgfmJo9MiuWRg\nAs+ekUNypIO1lRKgCCFEV5EARXRbKicP2z1PoX5+CZRsBZsdldffOlm6rW3hdkM8O/SYNNa3y48C\nEGYzuGxQErkJ4fRJDGdthcxDEUKIriIBiuj21KnnQFKqtclgaiYA+qfDPD4vGDt83Jt7ULTfB8EA\n+LzoYOe7F+cnuthQ5aUp0MESZiGEEPudBCii21MOB8ZN92Bc8itUZBREx0JJBwFKTHzr4+09KDv2\npHTQi7LdyB7RhLTmm4IOljULIYTY7yRAEYcFld0bNeR460FqBhQXti3g80Jsc4AS526dg7LjXJQO\n5qFslxjh4LjMKD5bW83y0ibmbKnvtKwQQoh9J5sFisOOys5FL5nX9qDPi8ofiHYnglLQ0Bxg/HQ1\nz05c3D+R30/dxINfFRLhMEBDTLiN/skR+/kdCCGEkB4UcfjJzoXyEnTz8I02TStHSmoGtl/fj4pL\naO052XGIZyc9KAC5CeGc19eN22WnMWDy5PdF3D+tcKfPEUIIsXckQBGHHZWTC4D5+l/Q27ai37GW\nIG/PNEtkNFRVoBvr2yw31rsIUACuHZrMq+f3Jj3aYb0WzVlshRBC7FcSoIjDT3K69e+yBZh/exQ9\nYwpg7ecDWJNoPY2Y42+zelKcLlAGNDVgzpiCXraA0J1Xotd3sKcPYDMU1w1N4cTsGDRQ7e14Zc+6\nSg+PTt9CICQ7IgshxJ6SAEUcdpRhoK6/C3ofBRWlrSeaV/Go405CnXSGldBt9TKIjIKISGhqQP/f\nPzD/9hjU16JXLu70NY7NjOLywYkAbKq28qP4giaPfbOlZQfkz9ZUs3BbI7MLZUKtEELsKQlQxGHJ\nOO4kjF9cB4AacSrG8++geuVbjyMiUZfcYA35LP+xNUDZtrXtRfw7T8yWHOXAZTfYWG3tAbS0pIkf\nixtZVmplsfUErZ6Tz9fW7M+3JoQQRwQJUMThq2ceDDkOdeIYVERkm1PK4YC0LOvnAUPBFYnevB4A\nY/wLkNcPaqp2enlDKfITw1lY3ECNN8iCYmvC7fYelM01PqLDDFZXeKj3SYI3IYTYExKgiMOWMmzY\nfvMAKrdfh+eNcdehzrscdf6VkJDUmjslMRUVl4DeRYACcHLPWJaXebhh0gamrrN6SrbVB/AGTUrq\nA5yRZw0rrZWNBoUQYo9IgCKOWKrPAIyfX2LNWdkexMTGW5Np49y77EEBK8NspMMgIyaMoxJd9HaH\nU9LgZ02FBw0clxVFjNPGaglQhBBijxySidpWrVrF5MmTKSgooKamhj/84Q8MGzasTZn33nuP6dOn\n09jYSH5+PjfccAOpqakHqcaiu1N5/dEAiSnWgTg31FSitUYp1enznHaDP5+RQ5zLRoTDxkcrK3lj\nUTl/+raI7DgnOXHh5Ce6JEARQog9dEj2oPh8PnJycrj++us7PD9p0iSmTp3KjTfeyBNPPIHT6WTC\nhAkEd7LZmxA71aMXOMNRSWnW47gEKz2+d9eBRXpMGBEOGwBpUWEAaDRPjumBw6YYnBrBitKmlrkp\nQgghdu2Q7EEZMmQIQ4YM6fT8lClTuOiiizjmmGMAuPXWW7nhhhuYN28eI0eO7KpqisOIstlQF16F\nysi2HsclWD0qNZXg2v1U9hmxVoByyYDElqBlTG4cH6+s4q0l5fiCJj1inVx1dPL+fgtCCHFYOSR7\nUHamrKyMmpoaBg4c2HIsIiKCvLw81q5dexBrJro749Sfo/KbP1fxCda/FWV7dI0esU6ePyuHC/q5\nW4457QaXDkpk5uZ65hc18t+Vu57bIoQQR7puF6DU1FgrJWJjY9scj42NbTknxD5LSLZ2Pd5JsrbO\n5MSHt5u3cmqvWDJjrN6VWKdtv1RRCCEOZ90uQBGiKyjDQA0ajl7yw37Za8dmKB47LYtf9E+gzhfa\no/T3noCJNyjp8oUQR5ZDcg7KzsTFxQFQW1vb8vP2xzk5OZ0+b+bMmcyaNavNsZSUFK655hpiYmJk\nw7cu5HA4cLvduy54kPlGn0bdd1OJqa3Ent0LZdu3/y5uN9RqJx+sqCTgiCQlzrVbz7vv01WEO2w8\nMrbPXr92d2nzw4m0edeTNu9a23uKJ06cSGlpaZtzo0aNYvTo0ft0/W4XoCQnJxMXF8eyZcvIzrYm\nNDY1NbFu3TrGjh3b6fNGjx7daWPV1dURCAQOSH1Fe263m6qqQ38ehs7qDQnJ1PzpHmioRV1wFURF\nw4pFGL+6c6+u6TKtlTxriyqIMCN3URoCIc28whrSosL2qc26S5sfTqTNu560eddyOBwkJSVxzTXX\nHJDrH5IBitfrpaSkpOVxaWkpmzZtIioqisTERM466yw++ugjUlNTSU5O5t133yUhIYFjjz32INZa\nHG6U3Y4651L0xOchOxf93mvQdzBsWI2+buf5UTqTGOFAAeWNuxcQr6304A9pShv9u8zJIoQQh5ND\nMkApKCjg0UcfbXn8n//8B4CTTjqJX//615x33nn4fD5effVVGhsb6du3L/fffz92+yH5dkQ3pkae\niurVB7TGfORWWL0MtAk/zkJHRKL6Hb1H13PYFG6XnbLdDFCWlVgbD3qDmjpfiNhw+YwLIY4Mh+S3\nXb9+/Xjvvfd2WmbcuHGMGzeui2okjlRKKUjLQpshCAsDvzVEY77xAmRkY9vDAAWgl9vJ7MJ6LhmY\niN3YeY/ImgoPCRF2KpuClDQEJEARQhwxZBWPELtBGTbIyGk94PVA5Z7lSNnu8sFJFNf7mbZ+18vi\nN9b4OD4zCoDSBpknJYQ4ckiAIsRuUlm9rB/CrHwm1Fajg50HDdrbhF46v93xnvHhDEiOYNG2RrxB\nkzcWlVHtab9NQ403SLUnSP/kCKLCDMokQBFCHEEkQBFiN6nhJ6BOGAPJGdYBraGqotPyet53mC/+\nEe3ztjvXJ9HFukovL87dxkcrq5i2oX1vyqZqH2AlfkuJCqNY9vIRQhxBJEARYjep/IEYV90Kicmg\nmv/rVJV3/oTKciuIaahvdyovIZwqT5DvN1vn1naw2/HGai9OmyI1ykFeQrjsiCyEOKJIgCLEHlLD\nRqPGXgCArtxJgLK9d6Whrt2pvIRwANKjHfxyYAIryzyETCtZYEVTgAVFDcwqrKdvkguboRiQHEFR\nnZ+qDoaChBDicCRLAoTYQ8ZxJ8FxJxGa/fVOJ8rq7b0rje0DlIQIB0PSIjmtVyzxLhvvLqvk7/NK\nKKjyUlzvxxu0gpVHTskEYGCKtaPy8tImTsyJ2c/vSAghDj0SoAixtxKSoaK08/PVVg+Kbqino8XE\nj56aBUDI1JyZF8d3m+s4Ji2KEVnR2AzFhiovR6dZ2WbjXHZ6xTv5vyXl9E1ykRTp2N/vRgghDikS\noAixl1R2b/TKJe2O68Z69HuvQ3lzNuQOhnh2ZDMUNw9P5ebhqTstd++JGfx+6mY+XVPNtUOT97re\nQgjRHcgcFCH2kjpqMJQVE/rHk+hVS9AL56CbGtErl6DnTG8t2MEk2d1lfvMZ5kdvAJASFcaAlAjW\nVcpkWSHE4U96UITYW/kDrH8XzsbcvB4qy1AXXgVRO8wRMYxd9qDsjF652OqJufBqAPLc4by3vIKQ\nqbHtIgutEEJ0Z9KDIsReUlExkJ1rPWieLKtXLYHa6tZCGdnoWdMw33xp716koa5NgJObEI43qNla\nJzlRhBCHNwlQhNgHxv3PoK65vfXAupVQUQKZORgvT4KkNPD70bOno01zz1+gOUDR2lrVk5sQjsLa\no6cjIVPTFAjtxTsRQohDiwQoQuwDZdhQOX2sB6mZEAygF8+D2HiUYaAirFU4BANQU7XnL9BQD6EQ\nNDUCEOGwkZcQzsLihnZFyxsD3DllE3dO2dSSU0UIIborCVCE2FdpGRAVgzrpDAh3QWM9Ks4N7JAL\nBVpX9ewmbYagsTkQqW9NhT88M4pF25oIhNr2yLy9tJzShgDb6gMsK23au/cihBCHCAlQhNhHyrBh\nPPYS6pSzoUdv62CsFaC0bDAI6KXzCD37IObHb+7ehZsaQTcHIfWt81CGZ0bjDZpM21CL1poaT5AG\nf4iZm+u5qL+bzJgwpq5rDWi21fvxBWXYRwjRvcgqHiH2AxUda/3bozd67XKIjbcen38Fasz5mI//\nDv3lJLDb0QWr0WMvQEVE7fyiO67+qa9t+bFHbBhjc+N4eX4pn6+tZkutnwv6ugmamlN7xRLvsvPC\n3BIWFjdQ5QnywtwSzh/YyLWD4vf7+xZCiANFelCE2J+yrR4Utb0HxW5HxcRB0Fp1o35xHYRC6Dkz\ndn2tHQIU3dAaoCiluGV4CtccnURJfQCAyaurOCrRRUKEg9N6xXJ0WiRPf1/Mi3OtYaXp6yp5+vsi\nNtf49se7FEKIA04CFCH2I9X7KLA7rAmzO4q0cqOoE8ZC76Ngw6pdX2x7gGKztRniAStIuaBfAh/8\nsg+DUyMIaTgmI6rl3N0npJOfGM4pvWJ4emw2dd4gswrrmbqu+qevIoQQhyQZ4hFiP1JJqRjPv40K\nc7Y5bvzuUairRTkcKHcyumLXE2b19qAkKbXNEE+b11OKo9MiWVLSxDHpkS3HIxw2Hj2th3Udrbl4\ncBqrttUwb2sD1w41+W5THaf0jG2T7G1pSSO+oObYzF0MPQkhRBeQHhQh9rOfBicAKiEZ1TPPeuBO\nhB1X93SmoR4ioiAmvl0Pyo5+lhvHb45LJTvajm5ejtzmtZXijhN7Mm5AIhVNQV5bUMYLc0varPTR\nWvPP+aU8N6cYT2Av8rUIIcR+JgGKEF3NnQQ1VZjfTUWXFXderqEOoqJR7qSd9rhEhdkYkxsHM7/E\nfOyOTssNSIkgKcLOF+utFT7zi1pzqWys9lFU56fBb/J1QU1nlxBCiC4jAYoQXUy5E8E00W/+HT1j\nCub3X6K9HeQtqamyVgNlZkNRIXrbltZhn46Ul0BlWcfXAuyG4uIBCQC4XXY+XVPNhG+30hQI8cma\namKcNkb1iGby6mpJ9CaEOOgkQBGiq7mTWn7U82ei//MieuGcdsV0TSUqPhGVng0+D+aEu9Cfvtv5\ndbfvmlxR1mmR03vHcdvxqfxuZBqRDoPF2xq5a8pmphfUcuWQJC7qn0BpQ4D3l1fgC8pQjxDi4JEA\nRYiuFp/Y+nNNpfVv6TYAdMCPXr7Q2nunphLiEiAj2yrj86KLNnd6Wd24PUAp7bSM3VCc3juOQamR\nvD2uD78dmUaM08aNw1IYkxtHb3c4p/SM4d1llbyxyAp0arxBXv+xlHqfJHsTQnQdWcUjRBdTEZFW\nSnwN+Jo3/SsrRpsm+qvJ6I/+g7rgSitAiXdDfAK4IsHTCCVFnV+4eVmyrixDdV6qjVE9YhjVI6bN\nsd+OTCcu3M7XBbVcfXQyD31VSGGtn7ToMM7qI8nehBBdQ3pQhDgI1PGnoM69tOWxXjwX845L0V9/\nCmFO9Mdvgt+PiktAKQV9+kNCMtRWdbhSB2jdt2cnPSi764ScGOp8If45v4TCWj8uu8GCovYbFAoh\nxIEiAYoQB4Fx+c2on52HOu0c1MjTIBgErwdqq1BjL2wtGGdNajV+8wDGLfdax0q2dnzR5iEevZM5\nKLurV7yTPgnhTC+oo3+yi0sHJbK0pIlGvwzzCCG6hgQoQhwkSimMX96AGjzcOpCRjTrjorYBSnxC\nS9nt2Wn1tvYBitbaClBs9v3Sg2Jlo80gO9bJRf0SGNkjGruheGT6Fp6fU8yDXxXyw5b6lom03qBJ\naYNfVv8IIfYbmYMixMGWlAqAGnkaxpjz256LbZ3zoZzh1jBPRz0onkYwTcjKhqqK/VOtSAd/+3nP\nlsePnpbFawtKWVfpJdxu8MR3RWTGhPGXM3N4YFoh66u8JLjsXDookR5xTp76voi+SS6OTotsl7UW\nwBMwUQq+3VjH/KIGLujrpjEQYmh6FHZjd2fRCCEOVxKgCHGQqayeGHf9EfoMaD04cBgsW4CyO9oW\nTs1AdxSgNM8/UVm90Fs2on0+lLN9Rtt9kZ/o4pkzcgCrx2ZtpZcHvyrkie+KWF/l5eohSWyq8fHi\nD1ZSuZ7xTorr/MwurOetJRUYwDNnZPN1QS3egMkPWxsoafATNCE+3Maj32zBF9L85rhUK/GcEOKI\nJgGKEIcAddSgNo+NW+5rmVPSplxaFnrZj+0vsD0HSlaO9W91BaRm7Oda7lAPpchPdPGrY5L5x7xS\nEiPsnNfXjc1QnJ0fT2GNjxE9ookKs7G8tIkZG2uZV9TAzZMLCJoaU4PdgAv6JtAv2YXbZefOKZuw\nG1aGWwlQhBASoAhxCFIOB8S5259IzYTpn6KDgba9K43WEmOV2RMNUF2BDgsDuwMVc+Bu9mfkxRPj\ntBHhsLUM4eQnushPdLWUGZASwYCUCJaWNPLtpjrOzItnU40Xm1Kc0iu2pdy/LshlekEtbywu5/dT\nN9ErPpyrj04iMszW5jU/WV1FjNPGST2t5zYFQszcXM9JOTE47Xs2rS5oan4sauCYjF0PK/mCJn+f\nV8IVg5NIinTstKwQYt9JgCJEN6LSMtGmCWXb0Akp6Kn/RZ1xEbquef+czBwAdHWFtVQ5zInt9xMO\naJ1G/iSPSmcGpUYyKNXacTk3Ibzd+TiXnVHZ0UxeU02s08bMwjrWVnoYf0oWswrrqfIEOSc/nn8v\nLCOkocFvckJODPd8sYni+gB1vhAnZsfwf0vK2Vzr49FTs4hx2vhqQy1RThsjsqJZWNxAUZ2fE3Ni\niA23801BLS/+UEL/ZBePn9YDm6H4bE01G6u9XDIwsU0gsqCogRkb63DZDW4enrp/Gk8I0SkJO2VA\nmwAAIABJREFUUIToTrav5Fm/EgrWNKe+1+jpn0JmT4iMhqgYKCqETetBm+iiQnB30BtzCEqJCmPi\nhbkAbKr2Mv6brdzwvw34Q9bqoAVFDSilGNs7llcWlPLZ2mpqfSFGZEXz3rIK3llaQVSYganhoa+3\nEBVmsKLMg6Fg3IAE3ltWiVIwbX0tj52Wxdwt1tDYijIPS0oa8QZNXllQSrhdUVzv54mfZbfUbe4W\na57PtA21bKjy8pvjUsmJbx9ovbaglJx4J+MOoTYPmRpTaxw2Wbgpug/b+PHjxx/sShxsTU1NmKbs\nO9JVXC4XHo/nYFejewpzotevgq8/hYI14PfBupUQFYPxwJ9RYU70/O9g0zprZY/TBWgijh3d7do8\nzmVnVI9oYsNtnNEnnn5JEczdWs/IrGhuPT6VqDAby0qbuP6YZM7Oj6e8KcgpPWO5Y0Q6R6dHsqbC\nQzAEvx6eCgo+XVNDZkwYj52WxdT1NUxaVUVhrZ/rhiZT3hhgbaWHKetqGNkjmrPz4/lsTQ0/y43F\nZTdYX+XlrSUVnJEXR2KknfLGIF+ur2F0dgwRDisgMpSivDHAs7OKWVnuYXO1hwZvgJz4cIKm5rM1\n1Xy3qY5ar5VLJt61878P67zBPR6y6ojWmj99X8RLP5SwtdZPpSdAuN0gNvzw+/tUvlu6ls1mIzIy\n8oBdX2mtj/jEBeXl5QQCgYNdjSOG2+2mqqrqYFej29Kmif7g3+iv/mdtPFhVjjprHMYFVwAQevGP\nsGQexLpRx4xEL5xN4ovvUrVsEeTktl8Z1I1sz7Py0yXLu2JqzbT1tfRJDKdnfDg1niBvLilnTYWH\n8adm8f2mOiYuKmdIWiT3n5hBIKS5+qN1HJsRzaYaL9vqA/SMd/LIKVnEu+zUeoP8fuqm5sm+iipP\nkP7JEdgNxZKSRkKmxmYY+EMmlw1KJMJh8K+FZSRHOihpCGAoePCkTI7JiKLGG2RNuYe8RGuycGmD\nnzcWlTOrsJ5zj4rnmqOTd/l+630h/j6vhNHZ0fRJcLXUMSHCwVcbanhhbgln58cze3Md1d4QmTFh\nPH92T+yGwhMwKaj20i/JZeXbaeYJmITbVZtjhzr5bulaDoeDpKSkXRfcSxKgIAFKV5MvkX2nTRNW\nLwGHE/O5hzEe+RsqOR0A85vP0J99gDrhZ6i+QzCfua/leeraOzBGntZ8jRDKsKHra9ErF6N65rVc\n40gTMjVVnmCbOSevzC/h20119E2KYGxuHEPSInHYWm/WhbU+Pl5ZSZjNICXSwdLSJlaUNXFiTgwn\n5sSQn5HE5MWF/N/SCpw2xajsaO4YkY4nYPLsrGKWlTby83w3n62pxhM0SY500C/JxczCOmKcdkZk\nRTFlXQ3DMqK4ckgSPWKdTFpVybKSJvISXDT4Q0SEGRRUeSmq81PSEGB7njyHoTC15s9n5PD0zCJ6\nxodzzwkZhExNQbWXu7/YzPl93dR4Q8zcXIc/pPndyDRO7hmLqTUvzN3G9II6MmPCOL+vm2821lLl\nCRIfbufywUkMSInAFzSZsbGOUdnWaq3OeIMmMzbWMjQtiuSoAxscy3dL15IApQtIgNK15Etk/9KB\ngLXqp6NzZgjz/puwx8QR3LgWdfq5GJdcjzl3Bvr91zEeeg79+fvoGVPAFYnx8HPo5T+iMnJQef26\n+J10f4GQxmZYwz1ut5vKykqmbahl2voa7hyVTlp0GGDdtB/8qpCCKi9jcuM4vXccE77disOmOLtP\nPGNy43A5DOZtrefFuSXU+kLEhtuo9YboERtGnS9EVJiNel+I1Ogw4sJtnN/XjdZQ7w+xtdbP9I21\nNPlDVHtDPD02u83KqneXVvDOsgoiHQYX9ktgWWkjW2r9ZMU5qWgMsLXOz+WDE5m1uZ5NNT56u50M\nTIlkWWkTZY0BrhicyIYqL1+uryXGaePY5lVQq8qbGJoexaryJnrGhzM0PZKX55dS2RQkKsxgYEoE\nVwxJIjNm1zl6tNY77b3xBU0MpZi7pR6nXTE8M7rdd0tTIESEw4Y/ZBIyweVoO2TmCZg47QpDqV2+\nXke21PpIjw7DZihKG/xsqvYxJC1yp0NzNd4gMU4bRhf1TPmC5m4PFdZ5g0Q7bbvdDhKgdAEJULqW\nBChdS/t9uFNSqfjj76G6EqJjYcMq8DShLrgSPXs6qkcvdMEaK5+KzwPZudge/MvBrnq3tqvPuS9o\n4gmaxDXPBfEFTeyGajecEwiZLCxupKDaS1p0GCf3jO3ocu2sqfDw1pJy+iS4uHJI25uI1prP19Yw\nMCWCHnFONlV7eWZmMRkxYcS77ByXGcXQ9ChMrfEFdctQT50vxGPfbGFDlRdTwwV9rYnA322uo8YT\nJDfBRVljgPzEcBYUNRI0NQNSIrj26GSmb6zlx6IGGgMmQ9MiuXKItVx7x1vQ9gCo2hPkkzXVHJcZ\nxam9YumT4MJQsKbCy8zNdSwuaaSozk90mI06XwgNXDs0iauO701hSQWx4TY+WlnFW0vKOSknhpmb\n67EZ8PDJWfRPiQCgvDHA76duok+ii7G5cTw7q5i+SS7O6+umX1IEX6yvZmO1jysHJzG/qAGn3eC4\nzCicdoOQqXl7aQUfrqhkUEoEA1MieHtpBRprbtE9o9PpmxzR7neyoqyJh74q5PisaG4+NoWY5t+9\nqTUfr6xibaWHSwcmkhMfTiCkeeybLfR2h3PxgASiwmz4gibfb66jpD5AhMPg/H5uphfUsrLMw8X9\nEzC1xh1hZ97WBnrGh1PvC/HoN1u454QMhmVE7fSzuKnGx4NfFfKz3DhuHJayW58xCVC6gAQoXUsC\nlK7ndrupeP1v6M/fB2XAkOEQCsHKxRAMYNx0N/Tsg/7mM/Scb8AwsD0z8WBXu1s7nD/nTYEQayq8\nDEqJwGYofEGTWm+ozRBOUZ0fT8Ckt9vZ8hd5rTfIe8sqmLu1gUZ/iJSoMEobAjhtithwG4W1fsAa\nohqSFsnSkkZ8IU1mTBhZsU7mbKkn3mVneEYUvd3h/FjcgMthkBjh4MMVlS2vHeEwaAqYZMSEUVTn\n56w+cWyt87Om3MOtx6cRG27j1QWl1PtC1PlCmBr6JbloClg36jCbItC8cszlMPAETDSQnxjOqB4x\nfLm+huJ6P2f2iWdO8xL4s/PjGZsbxz/nlbC+ysuvjklmxsY66n0hQloTH26nsNZHgsvBtgY/pobz\n+7oprvdT2hCgoMpLYoQdb9BkcFokW2r9bKn1sf0OfeWQJL5cX0NZY4B4l53KpiCn945lxsZaQBFs\nHt+Ldlo9a2E2hdNuUO8LkRPn5LLBifRNisA0NbHhNv6zuJziej9XDE7ijzO2UtIQaHluerSD64am\ncGxma1CzutxDSYOf4ZlRlDUESIsOI8rllADlQJMApWsdzl/chyq3203FlI/Rrz0Lffpj+8Of0Fs2\nYj52BwDGX95CRVv5TPSPszD/+RTGn99AxcajVy2BvP4o++G36uNAks955+q8Qb5YX0NlU5CUKAdV\nniAN/hAnZMcwKDUSm7KyFXuDJgVVXj5aWcmibY3cdGwqp/eO7XB4ZEFRAwGbE9PvYWOVj/7NPRsb\nq73kJbjwBU2e+HYri0uaAMiICeO+E615OTXeUPMkZ6sXZ2W5h5FZ0UxdV813m+t5ckwP6rwhHviq\nEK1hdHY05x7lpk+ii0BIs6nGS647HKUU/pDJhBnW66RHO+jtDsduKMqbgqRFObhqSBIamLiojOkF\ndfR2O4lx2vlF/wSyYsO47bONNPpNesQ5OT4rimPSo3hnaQXzixqIDbfxp59lkxETxsvzS/h8bQ1D\n0yL53ah0Vpc3EdLwf0vKGZwaSazTRkVTkL5JLp6fs43tN3pDQV6CizUVHmKdNmqbg5kbhqUwPDOK\nBUUNfL+5nqUljYzsEU2kw8aaCg9ban2ENESFGTT4TaLDDG4dmcWFx/Y+YJ8TCVCQAKWryRd313O7\n3VQu/RHz0TtQ436F8bPzANCb1qE3b8A46YyWsrq8BPP+GzFufxiS0zEfvBn1q99hHH9Ka5mizdBY\nj9px/6C9pEuLITYeFe7adeFuRD7n+1cgZO4yj8uu2tzUmpL6AEGtSYsKazPpuSNaa3whTXjzHI45\nhfW4HAZD0na+tNbUmlpviBinrdMVWFpriusDpEc72sz5KKz1EQxperlbc+xsq/dz75ebufHYFEY1\nJ0bsaGL39uv+dA5Joz9EtTfI2govFY0BVpV7OLlnDMMyonhvWQU948PbZHUOmZrP11bzzcZaGv0m\ng1IjSIkKo84bZEutnwv7u5m3tYFhWXGcOaQnB4oEKEiA0tXki7vrud1uKisq0NMmoU4Yg4rofDxa\na4155xWo/kMhfyD6Py+iTjkb47KbrPOL5mL+/QkAjJc+QIXt3aaE2u+DUAjznl+hRp6K8csb9uo6\nhyr5nHe9w7nNTa27bGLt7jrQc1AkraAQRwhlGBhjL9xpcAJW17q6+Dr0D9+i//MiALpgDXr5j+im\nBszvploZawFWLbXOBwNoM9RyDb1sAdrbNmGW9vvQFaXWz1XlmA//BvPhX4OnEf3DDLSnCXPi8+ia\nSsSBoX1edMB/sKsh9sKhFpx0BQlQhBDtGKNOQ51+XuuBzesxn38U847LYPlC1LmXQkoGeuFstGli\nPnkP5gM3o9ettIaI/vYY5pN3WzlZPE3otcvR/3sb8/HfogMBzH89Z60WqqmCuARoqEd/+G/0rK/R\nSxccvDfeCR0MEHr+UfTmDQe7KvvEfGkC+t3XDnY1hNgtMutNCNEhdd6l6ML1qMHD0R/8G4YcZy1T\n3rweNXQENDWi//d/1nyUzeshLQvztT+jxlxoXaBoM/rtl9FfTYaybRAWBn4/esoHsGYZxs33ogsL\nUL36YH7yLvq7L6znbVyLjoyGIcehbG0TgJkzp4HThXHsaMDKAaPf+jvqnF+iEtsujdQ+HwR8qKjd\n28xwpwrWwvIf0eEu+MV1KHfiTotrnw8dCu20TFfTAT+sW4GurzvYVREHgG6oA2WgInfeQ9qdyF48\nyF48XU32y+h6e9Pmyu7AGHU69DoKUjIwfn6JNX9l1GmohGTI6w9pPWDxHMgfiHHdb9FffAyrF0NG\nNsa9T0NDHaxdDo4wCPitf1ctgeQ01GU3YfQbgkrNgEAAlv9ovfCWjegFM8HvR/U/uk2dzMd/Bz/O\nQp11McqwwZql6A/+ZX0xDxiKrquxlkknpqDf+jv6X8+hMnMgGARXBBitSah0YwM4HLuVlErPmQ5r\nlkFxIfqr/6HyB6ISkzsua4asoav6Wvxff4JKTkPFHryNA3VZMebfn0B/OQnqaqGpAXXGRdDUAMpA\nT/kQMrI7nUukGxvADLbbImFvEpsdaAfru0U3NqDCwrr8dXdkPj8evXwhxvATrTr5fJh/fRjVoxcq\nNv6AvOaB3otHAhQkQOlqEqB0vX1pc6UUKjMHZbOhjNa/0JRSqIweqNN+jho2urWnYsUi1LDR1hdl\ndp6VZ+WXN0BcAuroEdDUgHHjH1Axca0vkpSK/m4q5PaFilKIirYCmdQMsNnQUz5EV1dYewwB2O2Q\nk4f+fhpsWA3lJeAMR3/yLnzzGXred627OS+YiV61BD1zmhUsKQVVFZiP34Heugk9Ywp61jTUgGNQ\n4S7M2dPRG9egsnNbqmdOfgcSkqyAzOe1ktwNHdGurcxP34Xvp8G6FQTWLIfiQvD7WsrqYBA9/3v0\n15/A4OEopdDrVkJ9DSouwSqz+Af0t1OtoMEV0fI8KkpQkdHWFgXKsHpEDGuUXn/2HtjssHGNNWyW\nmGJd29uE+fT9UFUOVRXNlTRR/YZgPvF79A8z4MdZEBHdkjlYV1eip36EXrsMklKtYbnVy1A9ekNY\nGMruQBcVWqu7Bg5r+3vsQh0FSB19znVludWeuX0PSEClN67DfOgW1KBhqLiDE4jqumr0u69CdSVq\nzPlW8L56qZX3KNyF6nf0ri+yFw50gCJDPEKIfaKM1mEYNfYCKClCjbCWJKuEJNTlt1g/9+xjFTrl\nrPbXiI7BePZN2LgGc/VS1C9vtIZU3vgbOtYNlWWw/Y+Inn3Q/3sb/eX/rB2be+XDpnXot1+2rnXJ\nr9DvvW79POZ8axlzc2Cjt21B/zjLSlYXFW0FNzl5sHEt5guPo9Iy0XNngGGgUzIhu7c1rLVhFeqi\nqzFOPw/zs/fRn75LyNOIcf2dYHdAeam10/Sn70MoCK5Iq252B/rH2YQqysDptBLjNS+cVCefhc7q\nifnanyEyGtvDz1s3u5cmgM2OLi3GuO0hK9CY/Db6i4/gqMHQUIfK64ee8Tlk52Kcd5nVHv97u7U9\nz78CzvoFesp/obYK48G/Yv7zSet9b92I+d6r4PVASZH1Xj96A7OqHPr0R7/+F0BBKIiePxO8Xli1\nBPPx36KOOxl17R3Wjc/ThF4yz+qhAvSa5ejizdbS81AQ1aM3Wmv0hxNRg4ahVy9FjTwNlZS608+T\n1ho99SPUgKGorJ7oUKj9UN9n76NXLsK464+wcglERKJ65be/lhlCT5uE/voTVM88OGpQh69pzp5u\n1fm4k9r1JGkzBKEQytHaQ2LOmGL1vqVno+d+A6ZpBcBao3Lydvr+dpc56ytwhKGOPaG1169l/6w6\nVHSMlbNo2v+s36PWVvC8YQ3kD0CvXmI9Z/lCuPha62etoamx3TCQ+dX/oKYKNXoMes0y1NARqGhr\n2bH2eaGupt3vTXs90MkWG/uLLDNGlhl3tcN5KeChqru0uTZN9I+zUENHQjCI+dTdsHUT6rrfWTdO\nuwPjhfegqgw9cxr62y8wbvg99D7K6lWprUYlphD6451QuAHjL2+CGcK862qIisG45nZ0U6M1b+Wa\nO1rnsmxYjfn2y9bwx+nnWsMhVeXWdb0eCIUwHvwLyhmOrq9DT3oLPXc66tgT0Vs3WXNwbDYrAOjT\nHzV4OC4zhDethxWAZPWy8sYMGw1RMeiP30SNPBU16FjMZ+4HQF1yvdXz42nCOP8KzH8+iTr5TNRF\n12Def6M1XKa11QOkNeq0c5rLN0JYOGr4iahjR6NXLLYCiLQs6zWPGYlx2c3o6krQGnP8beBpRI06\nDfoMBEOhX/+r9Quw2aBXPsZvHsAcfzvUVGL8fgLmf16E2mrQJurcy9H/fcO6OUVEgc2GOvp4q1do\n++3EZkNddhPKnYz5/HgriAsGrIDqnqda9o7SAT/U16Hcic03zwb0Fx9bw075AzHG/Qrz2QcxbrkX\nddQg9IKZmO+9ZrVFMIg65Wyr5y08AuPX9xPRUENTr76oOLe1HH7i81adPE0w5Dhsv3mg5bNmfvM5\nesVCK9j7cKJ18JiRVoDl9aDXrcS49EbM91+HtStQl1yPGjQM6moxx9/a9oNrs1uBKc2B55YCjHMv\nRdfVghkCrwc1/ETMfz2HMfJU1LDR6LUrMN98EXXGxehFc6wh1ObgRldXYt53gxU0nXc56oQxmM+N\nh22FqBPGoL+dirr6dvTU/1rXryyH/IFQuAHCXZCQbA1JRkVDQz3Gk6+jEpIwv/gIPflt63fQw0qw\nptevxHzqXut5Ph9oE7J6QkM96qQzrMDY78d4/O+opFSrl9A00SsWETbiVFIu+9X+/ApoQwIUJEDp\nat3lZnk46a5trutqYNsWVP5AQuNvA7tjt/YI0ovmolcsxLji1wCE/vwAKjOnJdeKDvjb/EXc7vnb\ntqBXL0W/84p187vnSVRGdpsy5uR30J+8A3EJGJfeaAULyWkYF14F7LzNzbdftv7ijo23bjDbh1/c\niRhX34bqdzTmt1PR775i9cbU12L89lGrbhtWQ3UF6qpbYcUizOfHo0adjnHN7dZ5rWH5Qsw3X4Lq\nCowH/4rKbs32qRfPRVdVWL0Z4S6r/KrF6B/noL+binHHI6gBx6CXzEOXFmGMucCah+L1YN5/gzVE\ndMpZ1jyfD/5tBWXatIYW+gxAlxRBRanVwxPuspakV5ZB38GwbqV184uMxrj4Wsw3X4QtGzHufRo9\n/VOrTZSybrarl0JKBpQWwZDjMX59H+bjv7VuxnFuiE+AFYugzwCrTG219QazczHOvRTztb9YQYPf\nZ93UZ05DXXIDOJ2o3L6YD98KMbHW8xJTUOdciv73c9b7AevmXl9rDaPlD7T2r4qIgvo6K1B+9AX0\n+lXoD/6NOv9y9OcfgN/XWg/DaO31A3C6rJVrdjvYHFYw2NRgnbPZrK0nUjOs99xYD0WbUSNPszby\n7NHLGvqMjrWGDbf30AHG75+wehEBvXA2rFqC9jTC4h9QV92K/vDfEB1nXd/TaO23FRuPGn26NWl9\n4Wzr93HHI9Z8rph4KyhxRViBXb+jrbrkD0SdchbmU/e0vqUH/0LyiBM7/X+0r7p1gDJ16lQ++eQT\nampqyMnJ4dprryU3N3fXT/wJCVC6Vne9WXZnh0Ob603rrK723kft+XNDIVAKZexZZgX942xISmn5\na7PNOdO0brzxiR1uA7CzNtfeJmuIqrwEddIZLRNWGTC0zTwJvXEd+vsvrOGOoSM7vtbCOdD7qHYT\nIXVxIXrFopaswbt8r40NVu/VCWM6nauh166AyGhURg90RSnmK89YCfyqKuDo49s8z5z/PWxcizr+\nFGuCdGZPWL8S8+1/Wje++lrrRhvntnqpaipRYy6wgp9YN+Zzj1g9Yjm56B++g8hIqzfgjvHWhOjm\noQcSkq0bb1kJ0eFh1P7xLvD7oU9/jF9ZPWkMGGZNXC4vsSqXkAymiXHfM5jPPog68yKMUadbwVVC\nshXYBPzopQtQaZmQmmn1aJgh0KCGn4Bx1a3t2sec9RV68tsQnwhbClCDhkOYE/Wz8zD/8yJq+AnN\nK9qc1ryewcPRX03G+MMTUFaMXr0MXb7N6r0YeRpq9OmY/3gSSoswLr0JDAPzn09i3PVH9MZ1VuBw\n2U07nVujVyzCfOUZK7gpLcK4Yzzmx/+B4i3gDIc4N8ZvHmgzhKPLtlnDjF9NRp1zCXrhHPQbL1gB\nWnKaNc8pNh7n+L+RnNzxZPH9odsGKLNnz+all17ixhtvJDc3l88++4w5c+bw/PPPExOzZ8sKJUDp\nWofDzbK7kTbvetLmndMlRVaPxqk/t4bgJtwJysB48rX2c0C8HvSkt6yeGLsdNfbCTgNNt9tN5aYN\nULoNevZpEzjq1UvRKxeBKwq9cQ3GmPNRuf12ezWSXr3U6hVJTofIqE574LQZsnopqivaTLTu9Lod\nzLHZaflgoN2Kql0+Z/v8lKLNqN5HoYMB67ErwloBt4v3r7W2VsWtXY5x1wRruC7MSVhCkmwW2JEH\nHniA3Nxcrr22dfLPLbfcwplnnsl55+3eXwzbSYDSteSLu+tJm3c9afPdp7dtseZpbJ9IvZekzQ8s\nbZptgkNJdd+BYDBIQUEBAwcObDmmlGLgwIGsXbv2INZMCCHEnlJpWfscnIgDb0+HSPdVtwxQ6uvr\nMU2T2NjYNsdjY2Opqak5SLUSQgghxP4ieVAAewcT3MSBo5TCcYDXz4u2pM27nrR515M271oH+t7Z\nLe/M0dHRGIZBbW1tm+O1tbXExXWc1XDmzJnMmjWrzbG+ffty7rnnEh9/YNIAi84dyHFL0TFp864n\nbd71pM273uTJk1m1alWbY6NGjWL06NH7dN1uGaDY7XZ69erFsmXLGDZsGGBNkl2+fDlnnnlmh88Z\nPXp0h401efJkzj333ANaX9HWxIkTueaaaw52NY4o0uZdT9q860mbd73t99ADcR/tlnNQAM4++2y+\n/vprvv32W4qKinj11Vfx+XycfPLJe3Sdn0Z94sArLS092FU44kibdz1p864nbd71DuQ9tFv2oACM\nHDmS+vp63n///ZZEbQ888MAe50ARQgghxKGn2wYoAGPHjmXs2LEHuxpCCCGE2M+67RCPEEIIIQ5f\ntvHjx48/2JU42Hr06HGwq3DEkTbvetLmXU/avOtJm3e9A9Xm3TbVvRBCCCEOXzLEI4QQQohDjgQo\nQgghhDjkSIAihBBCiEOOBChCCCGEOOR06zwo+2Lq1Kl88sknLUnerr32WnJzcw92tbqlVatWMXny\nZAoKCqipqeEPf/hDyxYE27333ntMnz6dxsZG8vPzueGGG0hNTW05HwgEeOONN5gzZw6BQIDBgwdz\n/fXXt9uxWsDHH3/MvHnzKC4uJiwsjD59+nD55ZeTnp7eppy0+f715ZdfMm3aNMrKygDIysri4osv\nZsiQIS1lpM0PnEmTJvHOO+9w1llncfXVV7cclzbfvz744AM+/PDDNsfS09P561//2vK4q9r8iOxB\nmT17Nm+++Sbjxo3j6aefJjs7mwkTJlBXV3ewq9Yt+Xw+cnJyuP766zs8P2nSJKZOncqNN97IE088\ngdPpZMKECQSDwZYyEydOZNGiRdx11108+uijVFdX8+yzz3bVW+hWVq9ezZlnnsmECRN46KGHCIVC\nTJgwAb/f31JG2nz/S0xM5PLLL+epp57iqaeeYsCAATz99NNs3boVkDY/kNavX89XX31FdnZ2m+PS\n5gdGVlYWr776Kq+88gqvvPIKjz/+eMu5Lm1zfQS6//779b/+9a+Wx6Zp6ptuuklPmjTpINbq8DBu\n3Dg9f/78NsduvPFG/cknn7Q8bmxs1JdddpmeNWtWy+NLL71U//DDDy1lioqK9Lhx4/S6deu6puLd\nWG1trR43bpxetWpVyzFp865x7bXX6unTp2utpc0PFI/Ho2+//Xa9bNkyPX78eD1x4sSWc9Lm+9/7\n77+v77777k7Pd2WbH3E9KMFgkIKCAgYOHNhyTCnFwIEDWbt27UGs2eGprKyMmpqaNu0dERFBXl5e\nS3sXFBQQCoUYMGBAS5n09HQSExPld7IbmpqaAIiKigKkzbuCaZrMmjULn89Hfn6+tPkB9Nprr3HM\nMce0aTeQz/mBtG3bNm666SZuu+02/va3v1FRUQF0fZsfcXNQ6uvrMU2z3VhYbGwsxcULUlwBAAAI\nQElEQVTFB6lWh6+amhqADtt7+7mamhrsdjsRERGdlhEd01ozceJEjjrqKDIzMwFp8wOpsLCQBx/8\n//buPaSpv48D+FvdNFeOeUnRkdeZFzCVsH8ihZD8R7oQKcMU1KIY/RVUlE+aifqHCEFBgS4KLXL+\nI4E3KFByKKSYNixKDC+Z4N3pNnW4548fHdqjPU/xbPOo7xcMOd99xc/5cNC353x3zr+wvr6Offv2\n4caNGwgJCRF+8bLnjqXX6zE6OorKyspN7/E4d47o6GhoNBqEhIRgYWEBjY2NKCkpQXV1tct7vucC\nCtFuUltbi4mJCbtrxOQ8SqUSVVVVMJlM6OnpwaNHj1BaWrrdZe1Ks7OzePbsGe7evQuJhH+qXOXX\nRd+hoaFQqVTQaDTo7u6GUql0aS177hKPj48P3N3dsbi4aDe+uLgIhUKxTVXtXj97+t/6rVAoYLVa\nhUsVW82hzbRaLfr7+3Hv3j34+voK4+y583h4eCAoKAgRERFQq9UICwtDS0sLe+4EIyMjWFpawq1b\nt6BWq6FWqzE0NISWlhao1Wrhv3j23LlkMhmCg4MxNTXl8uN8zwUUiUSCyMhIfPz4URiz2WwwGAyI\niYnZxsp2p8DAQCgUCrt+m0wmfP36Veh3ZGQkPDw8YDAYhDmTk5OYmZnB4cOHXV7zTqDVatHb24uS\nkhIEBATYvceeu47NZsP6+jp77gQJCQmorq5GVVWV8IqMjMSJEydQVVWFoKAg9twFLBYLpqam4Ovr\n6/LjfE8+zdjb2xs6nQ7+/v6QSqV49eoVRkdHcfXqVXh5eW13eTuOxWLBxMQEFhYW8ObNG6hUKnh6\nesJqtUImk2FjYwNNTU1QKpWwWq14+vQprFYrCgoK4O7uDqlUivn5ebS1tSE8PBzLy8uoqalBQEAA\nzp8/v927Jzq1tbXQ6/W4fv06FAoFLBYLLBYL3N3d4eHhAQDsuRO8fPlSuNQwOzuL5uZmdHV1ITc3\nF4GBgey5g0kkEsjlcruXXq9HUFAQUlNTAfA4d4a6ujpIpVIAwMTEBGpqamA0GnH58mV4eXm5tOd7\n9mnG7e3teP36tXCjtoKCAkRFRW13WTvS0NDQltfh09LSoNFoAAA6nQ5v377FysoK4uLiUFhYuOnG\nPnV1ddDr9VhfX0dSUhIKCwt5M6UtZGdnbzmu0WiQlpYmbLPnjvXkyRMYDAbMz89DJpMhLCwMZ8+e\ntfu0AnvuXKWlpQgPD7e7URt77lgPHjzA58+fYTQaIZfLERsbC7VajcDAQGGOq3q+ZwMKERERidee\nW4NCRERE4seAQkRERKLDgEJERESiw4BCREREosOAQkRERKLDgEJERESiw4BCREREosOAQkRERKLD\ngEJERESiw4BCRLtWR0cHsrOzMTIyst2lENFfkmx3AUS0s3V0dODx48e/fb+8vBwqlcqFFRHRbsCA\nQkQOkZ2dbfdAsZ9+fYgYEdGfYkAhIodISkpCZGTkdpdBRLsEAwoROd309DSuXbuG3NxcuLm5oaWl\nBYuLi1CpVCgsLMShQ4fs5hsMBuh0Onz79g0SiQRxcXHIycmBUqm0mzc3N4eGhgZ8+PABy8vL8PX1\nRVJSEvLz8+Hh4SHMs1qteP78Od69e4fV1VUkJibiypUr8PHxccn+E9Hf4yJZInIIk8kEo9Fo91pe\nXrab09nZiba2NmRkZODcuXMYHx/H/fv3sbS0JMwZHBxEeXk5jEYjsrKykJmZiS9fvqC4uBgzMzPC\nvPn5edy+fRvd3d04fvw48vPzkZqaik+fPmF1ddXu52q1WoyNjeHChQvIyMhAX18ftFqtcxtCRP8X\nnkEhIocoKyvbNCaVSlFfXy9sT01N4eHDh1AoFACAxMREFBUVoampCXl5eQCA+vp6+Pj4oLy8HDKZ\nDACQkpKCmzdvQqfTQaPRAABevHiBpaUlVFRUICIiQvgZWVlZm+qQy+UoKioStjc2NtDa2gqz2Qxv\nb28H7D0RORoDChE5xKVLlxAcHGw35u5uf5L22LFjQjgBAJVKBZVKhf7+fuTl5WFhYQGjo6M4c+aM\nEE4AIDQ0FEeOHEF/fz8AwGazobe3F0ePHrULJ7+Tnp5utx0bG4vm5mZMT08jNDT0r/eViJyPAYWI\nHCIqKup/LpLd6hM9wcHB6OnpAfDPWhUACAkJ2TRPqVRiYGAAa2trMJvNMJvNm9au/I6/v7/d9oED\nBwAAKysrf/T9ROR6XINCRLvef57J+clms7m4EiL6UzyDQkQu8+PHjy3HDh48CADC18nJyU3zJicn\nIZfL4enpCalUCm9vb4yPjzu3YCLaNjyDQkQu8/79e8zNzQnbw8PDGB4eRnJyMgBAoVAgPDwcnZ2d\nMJlMwryxsTEMDAwI89zc3JCSkoK+vj7exp5ol+IZFCJyiP7+fnz//n3TeExMDNzc3AD8swaluLgY\np06dwtraGlpbWyGXy3H69Glh/sWLF1FZWYmioiKcPHkSq6uraG9vx/79+3HhwgVhnlqtxuDgIEpK\nSpCeng6lUon5+Xn09PSgrKzMbpEtEe08DChE5BA6nW7LcY1Gg/j4eABAWlqa3Y3aoqOjkZ+fb/fJ\nnoSEBNy5cweNjY3Q6XSQSCSIj49HTk6OcAkIAPz8/FBRUYGGhgZ0dXXBbDbDz88PycnJ8PLycu7O\nEpHTudm4SoyInOzXO8lmZmZudzlEtANwDQoRERGJDgMKERERiQ4DChEREYkO16AQERGR6PAMChER\nEYkOAwoRERGJDgMKERERiQ4DChEREYkOAwoRERGJDgMKERERiQ4DChEREYkOAwoRERGJDgMKERER\nic6/AWRCoSgz+7JLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d3dbe4f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'], label = 'Validation loss')\n",
    "plt.plot(history.history['loss'], label = 'Training loss')\n",
    "\n",
    "plt.ylabel(\"Squared error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "plt.ylim([0,50])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! I say, at the level of trusting their data, these results are reproducible!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
